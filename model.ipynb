{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Boy': 0,\n",
       " 'Can': 1,\n",
       " 'Eat': 2,\n",
       " 'Fine': 3,\n",
       " 'Girl': 4,\n",
       " 'Help': 5,\n",
       " 'How': 6,\n",
       " 'Hungry': 7,\n",
       " 'I': 8,\n",
       " 'Mother': 9,\n",
       " 'Namaste': 10,\n",
       " 'Name': 11,\n",
       " 'Parents': 12,\n",
       " 'Sister': 13,\n",
       " 'Sleep': 14,\n",
       " 'This': 15,\n",
       " 'You': 16}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('data.json', 'r') as f:\n",
    "    labels = json.load(f)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('landmarks.json', 'r') as f:\n",
    "    landmarks = json.load(f)\n",
    "landmarks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4356"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks['0'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640', '641', '642', '643', '644', '645', '646', '647', '648', '649', '650', '651', '652', '653', '654', '655', '656', '657', '658', '659', '660', '661', '662', '663', '664', '665', '666', '667', '668', '669', '670', '671', '672', '673', '674', '675', '676', '677', '678', '679', '680', '681', '682', '683', '684', '685', '686', '687', '688', '689', '690', '691', '692', '693', '694', '695', '696', '697', '698', '699', '700', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('length.json', 'r') as f:\n",
    "    length = json.load(f)\n",
    "length.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5940"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length=max(length.values())\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class Label\n",
       "717           16\n",
       "718           16\n",
       "719           16\n",
       "720           16\n",
       "721           16"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=pd.read_csv('labels.csv')\n",
    "Y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Boy',\n",
       " 'Can',\n",
       " 'Eat',\n",
       " 'Fine',\n",
       " 'Girl',\n",
       " 'Help',\n",
       " 'How',\n",
       " 'Hungry',\n",
       " 'I',\n",
       " 'Mother',\n",
       " 'Namaste',\n",
       " 'Name',\n",
       " 'Parents',\n",
       " 'Sister',\n",
       " 'Sleep',\n",
       " 'This',\n",
       " 'You',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=open('words.txt','r')\n",
    "words=f.read().split('\\n')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.DataFrame(columns=['Landmarks'])\n",
    "X=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data():\n",
    "    for i in landmarks:\n",
    "        landmarks[i][0].extend([1]*(max_length-len(landmarks[i][0])))\n",
    "        X.append(np.array(landmarks[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.2904878 , -0.16641041, -0.09852826, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.14277988, -1.14277988, -1.14277988, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.06837073, -1.06837073, -1.06837073, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22918894, -0.11131902, -0.05098939, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.87611416, -0.80004271, -0.7496262 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.12677718, -1.12677718, -1.12677718, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.13677586, -1.13677586, -1.13677586, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.73616662, -0.6641765 , -0.61268805, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17041456, -0.12579402, -0.10721782, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.10825992, -1.10825992, -1.10825992, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.09939659, -1.09939659, -1.09939659, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.24053451, -0.15635459, -0.0870754 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.32472385, -0.22424643, -0.18032464, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.11235824, -1.11235824, -1.11235824, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.09967764, -1.09967764, -1.09967764, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22258412, -0.10252207, -0.05166316, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.30041499, -0.2408402 , -0.21108628, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.10924411, -1.10924411, -1.10924411, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.11145059, -1.11145059, -1.11145059, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.20445789, -1.20445789, -1.20445789, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-2.30712838, -2.30712838, -2.30712838, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.16660536, -1.16660536, -1.16660536, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.14530286, -1.14530286, -1.14530286, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.13333451, -1.13333451, -1.13333451, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.09022976, 0.24648839, 0.35241758, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.08301756, 0.23596729, 0.33965335, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.5954399, -1.5954399, -1.5954399, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-1.24046016, -1.24046016, -1.24046016, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.22942558, -1.22942558, -1.22942558, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.55076786, -0.47397514, -0.42280078, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.19948965, -1.19948965, -1.19948965, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.20572479, -1.20572479, -1.20572479, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.55992169, -0.5140187 , -0.49645108, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.36599347, 0.46944593, 0.59280474, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.36280392, 0.46393485, 0.58452541, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.49861421, -1.49861421, -1.49861421, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17668196, -0.04200831,  0.04080855, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.62665331, -1.62665331, -1.62665331, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.40631223, -1.40631223, -1.40631223, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18496337, -0.01943594,  0.06599814, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-2.61402105, -2.61402105, -2.61402105, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.28608685, -0.22968344, -0.22843421, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.29157319, -0.23510232, -0.2338516 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.16647587, -1.16647587, -1.16647587, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.0509047 , 0.18934428, 0.28143359, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.66254353, -1.66254353, -1.66254353, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.44696748, -1.44696748, -1.44696748, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.30365499, -1.30365499, -1.30365499, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.03176593,  0.09654773,  0.16653509, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.68081468, -1.68081468, -1.68081468, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.3941027, -1.3941027, -1.3941027, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.23439314, -0.08494797, -0.01939837, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.27029735, -1.27029735, -1.27029735, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.20844912, -1.20844912, -1.20844912, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02275672,  0.1079959 ,  0.16329024, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17299539, -0.06772584, -0.01008386, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.18469768, -1.18469768, -1.18469768, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16974969, -0.09568983, -0.05629136, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.21079593, -0.11557485, -0.06730952, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.21630579, -0.13701641, -0.11421857, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.18361243, -1.18361243, -1.18361243, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17963021, -0.12457331, -0.11418073, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.58768944, -1.58768944, -1.58768944, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22319402, -0.14002603, -0.10715184, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.17018866, -1.17018866, -1.17018866, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20056541, -0.12732152, -0.08162074, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18953213, -0.10641474, -0.07459131, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.24198044, -0.14455868, -0.09088194, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.22855159, -1.22855159, -1.22855159, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23541604, -0.10784149, -0.02310904, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.5980865, -1.5980865, -1.5980865, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-3.581426, -3.581426, -3.581426, ...,  0.      ,  0.      ,\n",
       "          0.      ]]),\n",
       " array([[-0.15416771, -0.01662149,  0.06588535, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17640608, -0.0274388 ,  0.05500577, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.78311294, -1.78311294, -1.78311294, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-5.62260906, -5.62260906, -5.62260906, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.26269926, -0.12811993, -0.06232204, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.1734263 , -0.03113211,  0.02953443, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.65316996, -1.65316996, -1.65316996, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20975323, -0.08235086, -0.01914659, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.14114343, -0.00370972,  0.05959486, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23879439, -0.23554096, -0.2453992 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13296572, -0.0057139 ,  0.05234535, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.03242207,  0.09624031,  0.1517958 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.74817917, -1.74817917, -1.74817917, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.43015554, -1.43015554, -1.43015554, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.36778641, -1.36778641, -1.36778641, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.28400206, -0.13706831, -0.05294117, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.47289666, -1.47289666, -1.47289666, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.43758723, -1.43758723, -1.43758723, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.06610148,  0.08065994,  0.15175338, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23860608, -0.09729921, -0.05067177, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.53681479, -1.53681479, -1.53681479, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.32687899, -1.32687899, -1.32687899, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.181095  , -0.06378939, -0.02004882, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.04111137,  0.1189959 ,  0.18352733, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.34510066, -1.34510066, -1.34510066, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.21821526, -1.21821526, -1.21821526, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.023019  ,  0.10717254,  0.16222959, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.02434353, -3.02434353, -3.02434353, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.03123224, -1.03123224, -1.03123224, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17335053, -0.10584249, -0.08887848, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.60402067, -1.60402067, -1.60402067, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.36738097, -0.37526678, -0.36945115, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.98855638, -0.98855638, -0.98855638, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15286366, -0.09282138, -0.08399356, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.32813834, -0.29928972, -0.27161415, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.27682694, -0.16479203, -0.08280928, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23123223, -0.1529576 , -0.13063318, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.1723511 , -0.09585793, -0.0740416 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13587672, -0.05100453, -0.01266563, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23452454, -0.13495357, -0.09967442, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.92416523, -0.92416523, -0.92416523, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.89068834, -0.89068834, -0.89068834, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18723215, -0.10522484, -0.07286602, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.32235815, -0.28531482, -0.26707138, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.85030976, -0.85030976, -0.85030976, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.14150899, -0.02117135,  0.04292939, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20506589, -0.16540869, -0.15602208, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.34931787, -0.30240137, -0.2926492 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.98908705, -0.98908705, -0.98908705, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.03250851,  0.10928413,  0.17671734, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.8156297, -1.8156297, -1.8156297, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[0.02836105, 0.17059937, 0.25723878, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.06833123,  0.06236486,  0.12440112, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.32318075, -0.25733879, -0.23623887, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.99157873, -0.99157873, -0.99157873, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.00439889, -1.00439889, -1.00439889, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.28735171, -0.22696174, -0.20180223, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.24757545, -1.24757545, -1.24757545, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.18292998, -1.18292998, -1.18292998, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.31143359, 1.29685345, 1.29556454, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.23412133, -1.23412133, -1.23412133, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23209373, -0.19349558, -0.19403163, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10097379,  0.04074942,  0.09758328, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.00729551,  0.06946417,  0.141926  , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.12573508, -1.12573508, -1.12573508, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.16542014, -1.16542014, -1.16542014, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.04345744, 0.18561677, 0.24040505, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.065227  , 0.2176717 , 0.32566954, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.21743303, -0.14592271, -0.13035474, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18411413, -0.1228472 , -0.11266152, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.01840988,  0.11495747,  0.21907915, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10197389,  0.03309391,  0.08489614, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20675461, -0.12794494, -0.0984759 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.21545093, -0.1429453 , -0.11079409, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13119793, -0.0240806 ,  0.0203406 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.25624104, -0.12558916, -0.06953093, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20022991, -0.14030808, -0.12957841, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20292951, -0.14387862, -0.12767878, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.14907655, -0.0541812 , -0.01084725, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22708078, -0.11736959, -0.0737379 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17095089, -0.09037269, -0.05727585, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17895161, -0.11026485, -0.08915491, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18115575, -0.07718882, -0.03653551, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.31226733, -0.24885807, -0.23593746, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.01768019, 0.17570732, 0.26474969, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.01292711,  0.14751322,  0.23285637, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.29838246, -0.23491509, -0.22046456, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.35288278, -0.26675106, -0.23981509, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.03245465, -1.03245465, -1.03245465, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11063427,  0.02240512,  0.07143026, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.31336413, -0.23035624, -0.20219204, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.0629114 ,  0.07501489,  0.14513095, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.0542066 ,  0.08043373,  0.14143445, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.82638887, -1.82638887, -1.82638887, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.06854312,  0.07129928,  0.13545105, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.07033712,  0.06538056,  0.1167883 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.8484818, -1.8484818, -1.8484818, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-1.41757418, -1.41757418, -1.41757418, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.33130184, -1.33130184, -1.33130184, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.13027963, 0.31266152, 0.40954816, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.31746154, -1.31746154, -1.31746154, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.20156987, -1.20156987, -1.20156987, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.14413619, 0.3125404 , 0.40529048, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.03865525, 0.15176564, 0.19489531, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.2627244, -1.2627244, -1.2627244, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.23035402, -0.18886101, -0.17521909, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.00720185, 0.14658577, 0.20749404, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.02209906, 0.11297374, 0.15251291, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.26631356, -0.1995099 , -0.17657178, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.2594023 , -0.1864083 , -0.16231351, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.00575909, 0.14412365, 0.20505193, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-4.00720121, -4.00720121, -4.00720121, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05216151,  0.01914174,  0.0418323 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.07300866,  0.00721683,  0.03486742, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20305515, -0.12953702, -0.10335515, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.10886579, -3.10886579, -3.10886579, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.07655454,  0.00757747,  0.04275117, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.06626489,  0.01455469,  0.04909327, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20543174, -0.12553104, -0.10175611, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.38439549, -3.38439549, -3.38439549, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.33919602, -0.2509559 , -0.21115019, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.25296722, -0.16069004, -0.11906319, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15383005, -0.02677047,  0.0272542 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.08372577, 0.21484985, 0.27534612, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-2.19360412, -2.19360412, -2.19360412, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-2.05826053, -2.05826053, -2.05826053, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10844529,  0.02923767,  0.08732768, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.18150352, -3.18150352, -3.18150352, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05178264,  0.0609102 ,  0.11625505, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.06713658,  0.05316958,  0.10910323, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17984875, -0.11196887, -0.10117835, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.81707946, -3.81707946, -3.81707946, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.0963425 ,  0.03507017,  0.09168581, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.09750378,  0.02694266,  0.08162698, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20174508, -0.1635573 , -0.17281772, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05037344,  0.06721225,  0.12488555, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.01411188, 0.13515676, 0.18778478, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.19078698, -0.15088202, -0.15344374, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11984735, -0.00143354,  0.05761621, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08351781,  0.02879866,  0.08237365, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.76150353, -1.76150353, -1.76150353, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.78014425, -1.78014425, -1.78014425, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.41166611, -0.34857368, -0.33249717, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.03218263,  0.09839637,  0.16514647, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.97968464, -1.97968464, -1.97968464, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.9164864, -1.9164864, -1.9164864, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.17436705, -0.08724706, -0.05326181, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-2.84421881, -2.84421881, -2.84421881, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.9048011 , 0.84550681, 0.78611159, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.90228079, 0.8434474 , 0.78451385, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.2143953 , 0.19297164, 0.20237366, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.17157264, -0.09610724, -0.06679943, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.25189722, -0.18137448, -0.15493515, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17711942, -0.10813303, -0.08226969, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08058022, -0.02555291, -0.0140104 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.54449721, -0.43074176, -0.38992821, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.19780283, -1.19780283, -1.19780283, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.14363759, -1.14363759, -1.14363759, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16583095, -0.09435741, -0.06941194, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16559708, -0.07909559, -0.05185157, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18727975, -0.13796091, -0.11820039, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.1028208 , -0.05378556, -0.03413867, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.07926031, -0.027401  , -0.01620662, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.2597935 , -0.19796085, -0.16595163, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.14108627, -1.14108627, -1.14108627, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.09387368, -1.09387368, -1.09387368, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10308732, -0.05049334, -0.02826039, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-6.52782786, -6.52782786, -6.52782786, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.07854256,  0.03886128,  0.08023891, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02482261,  0.03828165,  0.04287683, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.7163929, -1.7163929, -1.7163929, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.13878702, -0.04311573, -0.00574797, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.09878401, -0.00165889,  0.03512496, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.7329535, -1.7329535, -1.7329535, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.16292038, -0.01120233,  0.05016335, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.27348587, 1.24677595, 1.24335196, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.49902201, -0.46644913, -0.4506151 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.39017389, -1.39017389, -1.39017389, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15147189, -0.09558725, -0.08236449, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.02589186, 0.15528177, 0.26051842, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.36074167, -1.36074167, -1.36074167, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.33739976, -1.33739976, -1.33739976, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10461846, -0.01157633,  0.02056888, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19034977, -0.07865039, -0.04389739, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.43123209, -1.43123209, -1.43123209, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.34173873, -1.34173873, -1.34173873, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.27758048, -0.15808066, -0.11983916, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.04119735, 0.18132761, 0.24793923, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.39332297, -1.39332297, -1.39332297, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.28134365, -1.28134365, -1.28134365, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.03052717,  0.10079021,  0.16547787, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.25369592, -0.07133598,  0.0382003 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.17320658, -1.17320658, -1.17320658, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.11318037, -1.11318037, -1.11318037, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.10059114, 1.08576283, 1.09153663, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.33590619, -0.15918219, -0.08808924, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.00109211, -1.00109211, -1.00109211, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18405838, -0.15371396, -0.15772865, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19454893, -0.09273928, -0.04924556, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17313795, -0.05251044,  0.00136405, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19939027, -0.13497177, -0.11408763, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20791008, -0.14436859, -0.13013782, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12422666, -0.01132606,  0.04116764, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19063663, -0.11020324, -0.07958027, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15853385, -0.0915676 , -0.0863662 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16451812, -0.08197059, -0.0485023 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.35048815, -0.2872386 , -0.26879555, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.16313975, -1.16313975, -1.16313975, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.01943406,  0.11709827,  0.18522866, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.3286064 , -0.26318479, -0.24104485, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.42489211, -0.31633261, -0.26997056, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.07861212, -1.07861212, -1.07861212, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02610581,  0.11086076,  0.18927465, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.37569015, -0.27497156, -0.19569736, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.3548862 , -0.29140021, -0.26882486, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.12335719, -1.12335719, -1.12335719, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08298899,  0.05865889,  0.14076065, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.33384148, -0.27173772, -0.25243894, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.33311377, -0.27376657, -0.26060832, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.19767933, -1.19767933, -1.19767933, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.04132749,  0.11158653,  0.19121772, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.26730021, -0.21373894, -0.1993828 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.10020415, 0.28038212, 0.42526782, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.42677087, -1.42677087, -1.42677087, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.31558847, -1.31558847, -1.31558847, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.1293673 , 0.31180064, 0.42760315, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.23834412, 0.45601461, 0.56416195, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.57235652, -1.57235652, -1.57235652, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.41138806, -1.41138806, -1.41138806, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.12037957, 0.28406477, 0.36669564, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.136062  ,  0.09918918,  0.19952617, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.4904695, -1.4904695, -1.4904695, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-1.20345335, -1.20345335, -1.20345335, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02065292,  0.12938013,  0.19770153, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05183322,  0.10253635,  0.17273007, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.31339895, -1.31339895, -1.31339895, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.16591832, -1.16591832, -1.16591832, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.00114308,  0.13245791,  0.19715866, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.25259138, -0.20316633, -0.11910261, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.94400341, -0.94400341, -0.94400341, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.94865578, -0.94865578, -0.94865578, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.44509946, -1.44509946, -1.44509946, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.42584013, -0.24271183, -0.16624637, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.99779618, -0.99779618, -0.99779618, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15386693, -0.10800146, -0.08977194, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15354386, -0.04182693,  0.00648746, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16381242, -0.055543  , -0.01674269, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.92974517, -0.92974517, -0.92974517, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.90863689, -0.90863689, -0.90863689, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15407574, -0.04907336, -0.01424947, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.42814979, -0.26131215, -0.21447007, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.99771843, -0.99771843, -0.99771843, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20363305, -0.11165442, -0.0913536 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17938783, -0.07861636, -0.04197029, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.28862722, -0.22239116, -0.21522337, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.05663836, -1.05663836, -1.05663836, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15655675, -0.02272428,  0.0351077 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22777094, -0.15342051, -0.1362503 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.40808222, -0.34106648, -0.3273274 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13297521, -0.01078517,  0.04373433, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08622979,  0.03639779,  0.09111252, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.28036484, -0.21433946, -0.19981045, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.9631632, -0.9631632, -0.9631632, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.97079568, -0.97079568, -0.97079568, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.2682152 , -0.2243874 , -0.22023578, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.0345069 ,  0.1254408 ,  0.22646223, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.09164147,  0.06088307,  0.13283074, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.78331614, -1.78331614, -1.78331614, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.0020711, -1.0020711, -1.0020711, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.99651017, -0.99651017, -0.99651017, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.07283297,  0.05228856,  0.10787629, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.00672979, -1.00672979, -1.00672979, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.00111091, -1.00111091, -1.00111091, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.17050322, 0.19715611, 0.31069508, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.60592006, -0.37626524, -0.28241576, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.0331447, -1.0331447, -1.0331447, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.9819119, -0.9819119, -0.9819119, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.15926881, -0.04141756, -0.00185202, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17340622, -0.16410709, -0.12284875, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.10523666, -1.10523666, -1.10523666, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.0051066, -1.0051066, -1.0051066, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.10091419,  0.02854163,  0.08208637, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.37020348, -3.37020348, -3.37020348, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.26055868, -0.15652049, -0.12414294, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11198224, -0.02807475, -0.01312295, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08790983, -0.00795902,  0.01135573, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20011032, -0.09923245, -0.06593376, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10810584, -0.02100557,  0.00137623, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.09376811, -0.00304652,  0.02331422, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20199308, -0.12261749, -0.09716105, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.03742701,  0.1181653 ,  0.20221974, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.07015346, 0.23406809, 0.30979692, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.73380183, -1.73380183, -1.73380183, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.21024094, -0.18864802, -0.21520153, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12368731, -0.10967083, -0.13736314, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.2160262 , -0.08146829, -0.02622621, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15427046, -0.06799305, -0.03894966, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16549784, -0.07706701, -0.05118462, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20033476, -0.13366995, -0.12046902, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20987719, -0.13735268, -0.12543675, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13995948, -0.03196165,  0.02158767, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10227404,  0.00278202,  0.04259732, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16031075, -0.09023585, -0.08027259, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.86843128, -1.01397683, -1.11845297, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.56935995, 0.82934784, 0.94764377, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.41274054, 0.69522657, 0.82757529, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.04166569, -1.21813873, -1.32346937, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15212064,  0.19991478,  0.40922665, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-4.1897561, -4.1897561, -4.1897561, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-3.55171372, -3.55171372, -3.55171372, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.31373336, 0.57888256, 0.72534699, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.0250523 ,  0.09411815,  0.14584571, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.30025657, -1.30025657, -1.30025657, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13544508, -0.08453834, -0.07640866, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15208668, -0.02234348,  0.04854995, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.3098335 , 1.29838654, 1.33548654, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.02281074,  0.11376895,  0.1761785 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.70951545, -1.70951545, -1.70951545, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.54106959, -0.44545651, -0.37010385, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13041327, -0.03810099, -0.00759082, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08629338,  0.00247893,  0.0250588 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22979989, -0.17725694, -0.1380923 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.35287855, -3.35287855, -3.35287855, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02436768,  0.07476439,  0.11535418, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.01553092,  0.0845386 ,  0.13093715, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23137693, -0.16018865, -0.14347574, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.2632536, -3.2632536, -3.2632536, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.03920591,  0.06963526,  0.12529638, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.0039864 , 0.10666856, 0.14850402, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.33689283, -0.29246447, -0.27924123, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.06328736, 0.20443946, 0.27861742, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.19813594, -0.15032307, -0.14935643, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12422034, -0.06895731, -0.06373521, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18402886, -0.03604239,  0.03033949, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.05623428, 0.19311471, 0.25781727, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.94841128, -1.94841128, -1.94841128, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19912305, -0.13832183, -0.1283398 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11357056,  0.01617871,  0.08445883, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.14075104, 0.30475828, 0.37731536, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.28795575, -0.29732378, -0.33077988, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15270194, -0.17676578, -0.21544645, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.24413906, 1.26072679, 1.28432162, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.16338966, -0.08815022, -0.06267494, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16658608, -0.08854663, -0.05628266, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11822448,  0.0232274 ,  0.087342  , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10958245, -0.02330688,  0.00689397, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.06221262,  0.02871878,  0.06096237, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12264895, -0.03503486, -0.00383696, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08744433,  0.02082956,  0.07024914, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.04879595,  0.06121106,  0.11749351, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15942363, -0.09374875, -0.08135605, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.1011902 , 0.22991706, 0.29699333, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.04962881, 0.17931997, 0.25502303, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.27285523, -0.22476156, -0.22243454, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.26994729, -0.21631139, -0.21232906, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.03829195,  0.0796856 ,  0.14298071, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.0401233 ,  0.0788314 ,  0.14799256, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.77883103, -1.77883103, -1.77883103, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.40836552, 0.41565032, 0.42878839, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.23472751, -1.23472751, -1.23472751, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.10424187, -1.10424187, -1.10424187, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.31018172, 0.40297338, 0.4321582 , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.16098763, -0.07291735, -0.01921535, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18664876, -0.11323513, -0.08668896, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17511185, -0.10162467, -0.07961422, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12023582, -0.0324132 ,  0.00785244, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18280425, -0.09574367, -0.0407257 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.00124339, -1.00124339, -1.00124339, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.93118863, -0.93118863, -0.93118863, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11985069, -0.04174287,  0.00887867, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15494503, -0.04839103, -0.00352722, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.93545926, -0.93545926, -0.93545926, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.92883844, -0.92883844, -0.92883844, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20073123, -0.09869348, -0.0575073 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.52549997, -0.49970273, -0.50033473, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.20363425, 1.1853911 , 1.19798389, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.94094148, -0.94094148, -0.94094148, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22631973, -0.19280783, -0.18344917, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.2780941 , -0.23373014, -0.23162471, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.08978446, 0.21390915, 0.33696322, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.11304777, 0.24218286, 0.37020411, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.32532797, -0.3235609 , -0.33700887, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-2.60025185, -2.60025185, -2.60025185, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-2.13323076, -2.13323076, -2.13323076, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.23502939, 0.4316334 , 0.57518673, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.23898616, -1.23898616, -1.23898616, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.1872498, -1.1872498, -1.1872498, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.07044178,  0.06340334,  0.12645372, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.01993217,  0.04921182,  0.10088361, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02050314,  0.04077426,  0.06817122, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10024165, -0.0022596 ,  0.04067232, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.72728331, -1.72728331, -1.72728331, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.25696419, -3.25696419, -3.25696419, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11648274, -0.0421512 , -0.00279079, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08111712, -0.00882532,  0.02441665, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16544237, -0.10235997, -0.08993059, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.21607872, -0.14673203, -0.11846878, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.1143607 , -0.03825936,  0.01808109, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.07686611,  0.00251182,  0.05546506, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22418982, -0.15717812, -0.1298999 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19103128, -0.10515161, -0.05843195, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13062293, -0.03082584,  0.0158017 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10339367, -0.00534934,  0.03953575, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18981122, -0.1031402 , -0.05316423, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08560871,  0.05045547,  0.11439249, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-2.12872447, -2.12872447, -2.12872447, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.26270495, -0.15424099, -0.0922077 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11807167,  0.01067086,  0.076185  , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.11126494, 0.26318816, 0.3730546 , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-2.2237319, -2.2237319, -2.2237319, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.21317086, -0.1743796 , -0.16987306, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08613508,  0.07867105,  0.15777244, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.15020208, -0.11105441, -0.10061034, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20957822, -0.17001751, -0.1634138 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.14982536, -0.00611339,  0.04699038, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.21886518, -0.16161888, -0.15039613, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.29896305, -0.23983568, -0.22152348, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.14185645, -0.03130844,  0.00665079, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05387541,  0.07579258,  0.14396655, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.00945235,  0.11648899,  0.18327156, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19433389, -0.13601732, -0.12190342, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.01457952,  0.11656518,  0.19076752, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.08348629, 0.21884651, 0.29123264, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.31601438, -0.23078447, -0.2058069 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.9723215, -3.9723215, -3.9723215, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[0.06154151, 0.18160932, 0.2403344 , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.06117371, 0.1916971 , 0.25887712, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.37591311, -0.29465402, -0.26402447, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.75942696, -3.75942696, -3.75942696, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.0903157 , 0.20149556, 0.25780701, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.05912471, 0.18697425, 0.25627393, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.32967553, -0.26914601, -0.24143221, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-2.36273914, -2.36273914, -2.36273914, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20236023, -0.09620669, -0.0397602 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.1471418 , -0.03962605,  0.00255251, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.21213636, -1.21213636, -1.21213636, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-2.46714272, -2.46714272, -2.46714272, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.20365028, -0.10697472, -0.06022493, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13581812, -0.05146843, -0.02008032, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.15529744, -1.15529744, -1.15529744, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.25812569, -0.18127309, -0.15502322, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19562199, -0.10368248, -0.05777916, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13235149, -0.04493425, -0.01382705, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.27570475, -0.19921488, -0.17326865, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.27704325, -0.1998189 , -0.17768244, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16234679, -0.07545229, -0.02835537, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.07894668, -0.00145766,  0.03404281, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.21703149, -1.21703149, -1.21703149, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.41736458, -0.39828271, -0.40628632, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.2426201 , 0.41986363, 0.50876487, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.11046183, 0.24191124, 0.31021222, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.38278686, -0.36002825, -0.36964845, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.35366901, -0.32222118, -0.32355789, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.01639996,  0.10101321,  0.17123312, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02102771,  0.09594225,  0.15400579, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.29924646, -1.29924646, -1.29924646, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.04050119, 0.15629916, 0.2116706 , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.05923398, 0.18216787, 0.23823053, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.38643778, -0.34215929, -0.33775201, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.01966596, 0.16904232, 0.24115142, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.0085923 ,  0.13129952,  0.19981236, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.56043273, -0.50497668, -0.48279433, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.25084149, -0.20094593, -0.19648257, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.24005819, -0.19702957, -0.19371119, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10383375,  0.0552388 ,  0.13601046, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.21565083, -0.17675471, -0.16023979, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19721993, -0.15045279, -0.12837678, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10419074,  0.05031555,  0.12257828, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.06444618,  0.07035473,  0.1411287 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.52074349, -1.52074349, -1.52074349, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.25347197, -0.23002003, -0.21261443, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.01825803,  0.15801995,  0.25194507, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02692037,  0.11819462,  0.18851647, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.46757425, -1.46757425, -1.46757425, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22039311, -0.18412574, -0.17244503, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11593934,  0.03404426,  0.09706654, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.21080384, -0.08078031, -0.01830172, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.1737461, -1.1737461, -1.1737461, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.11074935, -0.04033897, -0.02826777, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.2238977 , -0.15823649, -0.13242454, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.28417735, -0.16013106, -0.09269697, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.18020121, -1.18020121, -1.18020121, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.10703088, -0.02640433, -0.00330351, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23858926, -0.12344351, -0.07763006, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.32145164, -0.27279566, -0.27039379, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11418445, -0.02867027,  0.00294365, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12796125, -0.04277911, -0.0209648 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.27628743, -0.22393374, -0.21971695, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.25477243, -0.19431681, -0.17654711, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.15539061, -1.15539061, -1.15539061, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23458474, -0.133293  , -0.08277459, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22614235, -0.17072146, -0.15772127, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02126869,  0.07199552,  0.12692613, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.98042759, 0.90110849, 0.85983007, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.93887315, -0.93887315, -0.93887315, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.68912045, -1.68912045, -1.68912045, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.12995445, 1.12312132, 1.10750398, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.96525415, -0.96525415, -0.96525415, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.95550578, -0.95550578, -0.95550578, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16829906, -0.07914111, -0.03852352, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.76393723, -0.69958891, -0.68655902, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.08975651, 0.24138683, 0.3357513 , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.07923255,  0.05787777,  0.12305773, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22947265, -0.19074261, -0.18813802, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.30805036, -3.30805036, -3.30805036, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.21408926, 1.20116105, 1.18808644, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[1.23428558, 1.20848729, 1.19144403, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.76147586, -1.76147586, -1.76147586, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.27006079, -0.20692845, -0.18146834, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13024389, -0.01832588,  0.02734874, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.17543556, -0.06332142, -0.01388507, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.24406347, -0.18597016, -0.16232357, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.34437943, -0.24769077, -0.1827713 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.93642565, -0.93642565, -0.93642565, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12680927, -0.0037643 ,  0.05909398, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.1897765 , -0.10671036, -0.07036003, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.09457578,  0.05176138,  0.12772543, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11886742,  0.03223187,  0.12132263, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.32828876, -0.28829458, -0.28073827, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.33251567, -1.33251567, -1.33251567, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.21837388, -1.21837388, -1.21837388, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.0648427 , 0.24301552, 0.33031388, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.15297093, -1.15297093, -1.15297093, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.09874541, -1.09874541, -1.09874541, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.01404185, 0.17240419, 0.24630115, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.17512181, -1.17512181, -1.17512181, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.09212804, -1.09212804, -1.09212804, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.0646494 , 0.23014038, 0.303014  , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.85678336, 0.92252325, 1.01644484, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.10177635, 0.12619308, 0.12129183, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.13129939, 0.15402513, 0.14946332, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-2.05618332, -2.05618332, -2.05618332, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23893316, -0.1658671 , -0.13358288, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16968478, -0.08303743, -0.04466462, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.18579557, -0.11149181, -0.08144917, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13747606, -0.07184534, -0.04640942, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11325265, -0.18364739, -0.1751079 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.16081809, -1.16081809, -1.16081809, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.18030225, -1.18030225, -1.18030225, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12840391, -0.16764807, -0.16576638, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.14010265, -0.05666857, -0.02099615, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.1566731, -1.1566731, -1.1566731, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-1.14372198, -1.14372198, -1.14372198, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22929604, -0.12410908, -0.08243955, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.36451538, -0.3211155 , -0.3154378 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.24825811, 1.27793386, 1.27333695, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[1.24467428, 1.27458457, 1.26995133, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.28759666, -0.33348412, -0.31596107, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.30606581, -0.2517416 , -0.2375325 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.14800214, -1.14800214, -1.14800214, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.11714001, -1.11714001, -1.11714001, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.412932  , -0.46583839, -0.43789791, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.06167715,  0.08210765,  0.17071844, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.4088157, -1.4088157, -1.4088157, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-1.44430971, -1.44430971, -1.44430971, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.0419649 ,  0.10329916,  0.19344529, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.18678191, 0.34505071, 0.45702728, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.81231554, -1.81231554, -1.81231554, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.49981843, -1.49981843, -1.49981843, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.0088934 ,  0.14679643,  0.25722283, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.06159591, 0.01238168, 0.03943638, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.1720211 , -0.12036869, -0.10194937, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.27196119, -1.27196119, -1.27196119, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.06035859, 0.13062194, 0.18764397, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.05219287, 0.12290838, 0.18029738, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.19626517, -1.19626517, -1.19626517, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.06312424, 0.16163292, 0.23239515, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.05641992, 0.15624986, 0.2279612 , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.21497687, -1.21497687, -1.21497687, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.09463923, 0.21009131, 0.29425507, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.07934829, 0.19675622, 0.28234579, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.23646031, -1.23646031, -1.23646031, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-3.01643531, -3.01643531, -3.01643531, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.24582901, 0.38518012, 0.49099303, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.250893  , 0.38785625, 0.49185599, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.6104415, -1.6104415, -1.6104415, ...,  0.       ,  0.       ,\n",
       "          0.       ]]),\n",
       " array([[-0.20100165, -0.0706606 , -0.01127805, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.44938759, -1.44938759, -1.44938759, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.44408969, -1.44408969, -1.44408969, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[1.24598939, 1.34685652, 1.4133162 , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-2.59695117, -2.59695117, -2.59695117, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08978642, -0.12714002, -0.11073664, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.09052236, -0.12776072, -0.11140795, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.22989305, -1.22989305, -1.22989305, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.1328682 , -0.06685936, -0.04169063, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.24887238, -0.18770974, -0.17567077, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.20403545, -1.20403545, -1.20403545, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.17558985, -1.17558985, -1.17558985, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23385699, -0.13114563, -0.10332399, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13409013, -0.0456462 ,  0.0024028 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.09348008, -0.00969858,  0.02967436, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.18746076, -1.18746076, -1.18746076, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.33009799, -0.26251678, -0.25370849, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05589078,  0.03247794,  0.07291749, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.01164838,  0.07839334,  0.10604666, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.11579457, -1.11579457, -1.11579457, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.46465208, -0.36500509, -0.32337792, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.08043871, 0.24041568, 0.32724024, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[0.08818878, 0.26642127, 0.33275506, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-1.54528342, -1.54528342, -1.54528342, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.11300911,  0.02392661,  0.0971495 , ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.13718346, -0.063565  , -0.03930214, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.09818238, -0.03383117, -0.01955067, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12062876,  0.01373647,  0.07291599, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05284486,  0.06883958,  0.17680006, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.1052139 , -0.03078072,  0.00406944, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.07717552,  0.01255773,  0.03762299, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.18883054, -1.18883054, -1.18883054, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.16891222, -0.06243435, -0.01646536, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08716514,  0.03346455,  0.07863208, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.19293255, -0.11607086, -0.09224641, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.00487362,  0.13358581,  0.18951739, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02181731,  0.10992969,  0.16272069, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.48957198, -1.48957198, -1.48957198, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12348094,  0.01040764,  0.09083182, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05238879,  0.09416214,  0.17251454, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.27484802, -0.16765314, -0.13127355, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08914349,  0.04594687,  0.12658558, ..., -0.12408679,\n",
       "         -0.48376578,  0.04043917]]),\n",
       " array([[ 0.0146533 ,  0.15222951,  0.2467443 , ..., -0.12246901,\n",
       "         -0.48365796,  0.04444503]]),\n",
       " array([[-0.29164603, -0.194961  , -0.16258025, ..., -0.31345508,\n",
       "         -0.15447561, -0.0485801 ]]),\n",
       " array([[-0.32197325, -0.22511606, -0.18955412, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.04223157,  0.10385736,  0.17585994, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.03434985,  0.11763116,  0.19242188, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.28378351, -0.18895897, -0.15233284, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22915584, -0.10828978, -0.05567972, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08597531,  0.02743204,  0.06327219, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08061436,  0.03134931,  0.07023153, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.24574356, -0.12135053, -0.06807015, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.08512712, 0.27643293, 0.3808446 , ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-2.27187734, -2.27187734, -2.27187734, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.78406829, -1.78406829, -1.78406829, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.14876814,  0.03380124,  0.11140584, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05361093,  0.12771053,  0.21582424, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-1.54841328, -1.54841328, -1.54841328, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.2002465 , -0.16421419, -0.18265341, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[0.01495133, 0.18173284, 0.25209795, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[-0.30576247, -0.22416509, -0.20083956, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02649781,  0.10492092,  0.16658443, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.0153182 ,  0.1126987 ,  0.17218775, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.22440831, -0.13461902, -0.10871972, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.32890635, -0.26494581, -0.25192806, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[ 0.15345271,  0.29455108,  0.37893776, ..., -0.13637291,\n",
       "         -0.48301166,  0.03279569]]),\n",
       " array([[ 0.12708507,  0.27059775,  0.35515336, ..., -0.11058631,\n",
       "         -0.46196708,  0.03462558]]),\n",
       " array([[-0.32907524, -0.26906365, -0.25289829, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.05633323,  0.06743673,  0.11304994, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.02751827,  0.10758721,  0.15973978, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.30862421, -0.18891818, -0.14127012, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.08535735, -0.04579855, -0.03633291, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.12314709,  0.00899578,  0.06183509, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " array([[-0.23017974, -0.11893753, -0.07379715, ...,  0.        ,\n",
       "          0.        ,  0.        ]])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 1, 5940)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=to_categorical(Y).astype(int)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 1, 5940)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X has to be of Series\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577, 1, 5940)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 1, 5940)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577, 1, 5940)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577, 17)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "log_dir=os.path.join('logs')\n",
    "tb_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(62, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(words)-1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "19/19 [==============================] - 8s 64ms/step - loss: 6.9366 - categorical_accuracy: 0.0728 - val_loss: 4.9213 - val_categorical_accuracy: 0.0414\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 8.4592 - categorical_accuracy: 0.0624 - val_loss: 3.9288 - val_categorical_accuracy: 0.0414\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 8.4880 - categorical_accuracy: 0.0797 - val_loss: 4.4489 - val_categorical_accuracy: 0.0897\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 5.3072 - categorical_accuracy: 0.0849 - val_loss: 4.7212 - val_categorical_accuracy: 0.0138\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 5.2485 - categorical_accuracy: 0.1057 - val_loss: 3.8629 - val_categorical_accuracy: 0.0552\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 4.6319 - categorical_accuracy: 0.0971 - val_loss: 4.1185 - val_categorical_accuracy: 0.0207\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4.5576 - categorical_accuracy: 0.0780 - val_loss: 3.5638 - val_categorical_accuracy: 0.0414\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 4.0215 - categorical_accuracy: 0.0936 - val_loss: 4.9734 - val_categorical_accuracy: 0.0207\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4.8056 - categorical_accuracy: 0.1231 - val_loss: 3.8853 - val_categorical_accuracy: 0.0414\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 3.5629 - categorical_accuracy: 0.1421 - val_loss: 3.5161 - val_categorical_accuracy: 0.0483\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3.3100 - categorical_accuracy: 0.1646 - val_loss: 4.1720 - val_categorical_accuracy: 0.0966\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3.5231 - categorical_accuracy: 0.1421 - val_loss: 4.5400 - val_categorical_accuracy: 0.0759\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 3.5354 - categorical_accuracy: 0.1421 - val_loss: 4.2440 - val_categorical_accuracy: 0.0621\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 3.4421 - categorical_accuracy: 0.1508 - val_loss: 5.0995 - val_categorical_accuracy: 0.0690\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 3.0441 - categorical_accuracy: 0.1629 - val_loss: 4.6700 - val_categorical_accuracy: 0.0828\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.8664 - categorical_accuracy: 0.1958 - val_loss: 3.9543 - val_categorical_accuracy: 0.0828\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 3.0977 - categorical_accuracy: 0.1906 - val_loss: 4.1051 - val_categorical_accuracy: 0.0621\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3.6547 - categorical_accuracy: 0.1976 - val_loss: 4.1669 - val_categorical_accuracy: 0.0621\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 3.6739 - categorical_accuracy: 0.2149 - val_loss: 3.9520 - val_categorical_accuracy: 0.0552\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 3.4939 - categorical_accuracy: 0.1993 - val_loss: 4.0295 - val_categorical_accuracy: 0.0759\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.9396 - categorical_accuracy: 0.1889 - val_loss: 4.5114 - val_categorical_accuracy: 0.0621\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.9489 - categorical_accuracy: 0.2201 - val_loss: 3.9873 - val_categorical_accuracy: 0.0828\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 2.9039 - categorical_accuracy: 0.2374 - val_loss: 4.2156 - val_categorical_accuracy: 0.1103\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 3.2787 - categorical_accuracy: 0.2530 - val_loss: 4.0768 - val_categorical_accuracy: 0.1241\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.7150 - categorical_accuracy: 0.2565 - val_loss: 4.2503 - val_categorical_accuracy: 0.1034\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.7453 - categorical_accuracy: 0.2808 - val_loss: 4.0836 - val_categorical_accuracy: 0.1310\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.8450 - categorical_accuracy: 0.2877 - val_loss: 4.2929 - val_categorical_accuracy: 0.1172\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.8134 - categorical_accuracy: 0.2600 - val_loss: 4.6796 - val_categorical_accuracy: 0.0966\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 3.3315 - categorical_accuracy: 0.2669 - val_loss: 4.1318 - val_categorical_accuracy: 0.0897\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.6850 - categorical_accuracy: 0.2790 - val_loss: 4.1976 - val_categorical_accuracy: 0.0759\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.6608 - categorical_accuracy: 0.2704 - val_loss: 4.4150 - val_categorical_accuracy: 0.0759\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.8166 - categorical_accuracy: 0.2877 - val_loss: 4.2570 - val_categorical_accuracy: 0.1241\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.7253 - categorical_accuracy: 0.2825 - val_loss: 4.2468 - val_categorical_accuracy: 0.1379\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.8294 - categorical_accuracy: 0.2790 - val_loss: 4.3133 - val_categorical_accuracy: 0.1448\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.6796 - categorical_accuracy: 0.2756 - val_loss: 4.2302 - val_categorical_accuracy: 0.1241\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.7913 - categorical_accuracy: 0.2652 - val_loss: 4.8042 - val_categorical_accuracy: 0.1241\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.8304 - categorical_accuracy: 0.2704 - val_loss: 4.8145 - val_categorical_accuracy: 0.1379\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.6039 - categorical_accuracy: 0.2842 - val_loss: 4.8572 - val_categorical_accuracy: 0.1034\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.6302 - categorical_accuracy: 0.2617 - val_loss: 4.3730 - val_categorical_accuracy: 0.1379\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.5713 - categorical_accuracy: 0.2565 - val_loss: 4.4271 - val_categorical_accuracy: 0.1241\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.7573 - categorical_accuracy: 0.2704 - val_loss: 3.8878 - val_categorical_accuracy: 0.0828\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 3.1233 - categorical_accuracy: 0.3016 - val_loss: 4.1680 - val_categorical_accuracy: 0.1172\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 3.2118 - categorical_accuracy: 0.2964 - val_loss: 4.0970 - val_categorical_accuracy: 0.1448\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.8470 - categorical_accuracy: 0.3033 - val_loss: 5.0498 - val_categorical_accuracy: 0.1379\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 2.6890 - categorical_accuracy: 0.2929 - val_loss: 5.3141 - val_categorical_accuracy: 0.1379\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.6238 - categorical_accuracy: 0.3224 - val_loss: 5.2729 - val_categorical_accuracy: 0.1448\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.8060 - categorical_accuracy: 0.3310 - val_loss: 4.4763 - val_categorical_accuracy: 0.1241\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.4797 - categorical_accuracy: 0.3120 - val_loss: 4.2838 - val_categorical_accuracy: 0.1517\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 3.1263 - categorical_accuracy: 0.3085 - val_loss: 4.5970 - val_categorical_accuracy: 0.1655\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.8358 - categorical_accuracy: 0.3154 - val_loss: 3.3989 - val_categorical_accuracy: 0.1862\n",
      "Epoch 51/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.9826 - categorical_accuracy: 0.3501 - val_loss: 3.6309 - val_categorical_accuracy: 0.1448\n",
      "Epoch 52/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 3.3014 - categorical_accuracy: 0.3432 - val_loss: 5.1956 - val_categorical_accuracy: 0.1379\n",
      "Epoch 53/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.3950 - categorical_accuracy: 0.3380 - val_loss: 3.3737 - val_categorical_accuracy: 0.1862\n",
      "Epoch 54/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 2.4170 - categorical_accuracy: 0.3345 - val_loss: 3.2968 - val_categorical_accuracy: 0.1448\n",
      "Epoch 55/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 2.8885 - categorical_accuracy: 0.3050 - val_loss: 4.2776 - val_categorical_accuracy: 0.1862\n",
      "Epoch 56/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 2.5840 - categorical_accuracy: 0.3241 - val_loss: 3.9163 - val_categorical_accuracy: 0.1241\n",
      "Epoch 57/1000\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 2.9140 - categorical_accuracy: 0.3224 - val_loss: 4.0325 - val_categorical_accuracy: 0.1241\n",
      "Epoch 58/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 3.0539 - categorical_accuracy: 0.3362 - val_loss: 3.7094 - val_categorical_accuracy: 0.1241\n",
      "Epoch 59/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 3.8710 - categorical_accuracy: 0.3293 - val_loss: 3.5715 - val_categorical_accuracy: 0.1172\n",
      "Epoch 60/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 3.3122 - categorical_accuracy: 0.2894 - val_loss: 3.6109 - val_categorical_accuracy: 0.1448\n",
      "Epoch 61/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.8051 - categorical_accuracy: 0.2894 - val_loss: 3.1571 - val_categorical_accuracy: 0.1448\n",
      "Epoch 62/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.7149 - categorical_accuracy: 0.2912 - val_loss: 3.1531 - val_categorical_accuracy: 0.1793\n",
      "Epoch 63/1000\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 2.5476 - categorical_accuracy: 0.2929 - val_loss: 3.9414 - val_categorical_accuracy: 0.0966\n",
      "Epoch 64/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 3.2551 - categorical_accuracy: 0.2669 - val_loss: 3.7710 - val_categorical_accuracy: 0.1172\n",
      "Epoch 65/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 2.7833 - categorical_accuracy: 0.2842 - val_loss: 3.7536 - val_categorical_accuracy: 0.1034\n",
      "Epoch 66/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.4289 - categorical_accuracy: 0.3102 - val_loss: 3.8472 - val_categorical_accuracy: 0.1172\n",
      "Epoch 67/1000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 2.7229 - categorical_accuracy: 0.3484 - val_loss: 3.4451 - val_categorical_accuracy: 0.1379\n",
      "Epoch 68/1000\n",
      "19/19 [==============================] - 0s 25ms/step - loss: 2.4246 - categorical_accuracy: 0.3518 - val_loss: 3.9575 - val_categorical_accuracy: 0.0897\n",
      "Epoch 69/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 2.2863 - categorical_accuracy: 0.3761 - val_loss: 4.3498 - val_categorical_accuracy: 0.1241\n",
      "Epoch 70/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 2.3945 - categorical_accuracy: 0.3778 - val_loss: 4.5905 - val_categorical_accuracy: 0.1310\n",
      "Epoch 71/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 2.4831 - categorical_accuracy: 0.3917 - val_loss: 4.5814 - val_categorical_accuracy: 0.1379\n",
      "Epoch 72/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.3378 - categorical_accuracy: 0.3969 - val_loss: 4.4670 - val_categorical_accuracy: 0.1517\n",
      "Epoch 73/1000\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 2.1204 - categorical_accuracy: 0.4194 - val_loss: 4.5829 - val_categorical_accuracy: 0.1517\n",
      "Epoch 74/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.0267 - categorical_accuracy: 0.4090 - val_loss: 4.7153 - val_categorical_accuracy: 0.1310\n",
      "Epoch 75/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.0721 - categorical_accuracy: 0.4107 - val_loss: 4.5285 - val_categorical_accuracy: 0.1379\n",
      "Epoch 76/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.1416 - categorical_accuracy: 0.4194 - val_loss: 4.7597 - val_categorical_accuracy: 0.1655\n",
      "Epoch 77/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.0259 - categorical_accuracy: 0.4107 - val_loss: 4.7520 - val_categorical_accuracy: 0.1517\n",
      "Epoch 78/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 2.1864 - categorical_accuracy: 0.4281 - val_loss: 4.6663 - val_categorical_accuracy: 0.1517\n",
      "Epoch 79/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.1015 - categorical_accuracy: 0.4211 - val_loss: 5.2823 - val_categorical_accuracy: 0.1448\n",
      "Epoch 80/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.0043 - categorical_accuracy: 0.4090 - val_loss: 3.9106 - val_categorical_accuracy: 0.1655\n",
      "Epoch 81/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.0086 - categorical_accuracy: 0.3986 - val_loss: 3.7218 - val_categorical_accuracy: 0.1931\n",
      "Epoch 82/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.0456 - categorical_accuracy: 0.3865 - val_loss: 5.2782 - val_categorical_accuracy: 0.1241\n",
      "Epoch 83/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.0486 - categorical_accuracy: 0.4298 - val_loss: 5.0793 - val_categorical_accuracy: 0.1241\n",
      "Epoch 84/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.9346 - categorical_accuracy: 0.4402 - val_loss: 4.4961 - val_categorical_accuracy: 0.1310\n",
      "Epoch 85/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.8934 - categorical_accuracy: 0.4367 - val_loss: 4.5084 - val_categorical_accuracy: 0.1517\n",
      "Epoch 86/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.9343 - categorical_accuracy: 0.4333 - val_loss: 5.3892 - val_categorical_accuracy: 0.1379\n",
      "Epoch 87/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8508 - categorical_accuracy: 0.4593 - val_loss: 5.2738 - val_categorical_accuracy: 0.1586\n",
      "Epoch 88/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8856 - categorical_accuracy: 0.4610 - val_loss: 5.3946 - val_categorical_accuracy: 0.1862\n",
      "Epoch 89/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8656 - categorical_accuracy: 0.4801 - val_loss: 6.5341 - val_categorical_accuracy: 0.1793\n",
      "Epoch 90/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.9926 - categorical_accuracy: 0.4489 - val_loss: 4.9928 - val_categorical_accuracy: 0.1448\n",
      "Epoch 91/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8438 - categorical_accuracy: 0.4454 - val_loss: 4.6790 - val_categorical_accuracy: 0.1586\n",
      "Epoch 92/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8703 - categorical_accuracy: 0.4645 - val_loss: 5.3819 - val_categorical_accuracy: 0.1724\n",
      "Epoch 93/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.5391 - categorical_accuracy: 0.4714 - val_loss: 5.4852 - val_categorical_accuracy: 0.1586\n",
      "Epoch 94/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.0962 - categorical_accuracy: 0.4523 - val_loss: 5.1534 - val_categorical_accuracy: 0.1793\n",
      "Epoch 95/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.8484 - categorical_accuracy: 0.4801 - val_loss: 5.7411 - val_categorical_accuracy: 0.1655\n",
      "Epoch 96/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.8796 - categorical_accuracy: 0.4905 - val_loss: 4.6917 - val_categorical_accuracy: 0.1586\n",
      "Epoch 97/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.7904 - categorical_accuracy: 0.5043 - val_loss: 5.7175 - val_categorical_accuracy: 0.1172\n",
      "Epoch 98/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6848 - categorical_accuracy: 0.4939 - val_loss: 4.9840 - val_categorical_accuracy: 0.1241\n",
      "Epoch 99/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8381 - categorical_accuracy: 0.5026 - val_loss: 4.4501 - val_categorical_accuracy: 0.1517\n",
      "Epoch 100/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.9291 - categorical_accuracy: 0.5182 - val_loss: 4.5656 - val_categorical_accuracy: 0.1172\n",
      "Epoch 101/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.0351 - categorical_accuracy: 0.4818 - val_loss: 5.3273 - val_categorical_accuracy: 0.1103\n",
      "Epoch 102/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.2094 - categorical_accuracy: 0.4731 - val_loss: 5.2604 - val_categorical_accuracy: 0.1448\n",
      "Epoch 103/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.9134 - categorical_accuracy: 0.4489 - val_loss: 5.4496 - val_categorical_accuracy: 0.1379\n",
      "Epoch 104/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.3907 - categorical_accuracy: 0.4489 - val_loss: 5.3312 - val_categorical_accuracy: 0.1448\n",
      "Epoch 105/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.0814 - categorical_accuracy: 0.4766 - val_loss: 5.2588 - val_categorical_accuracy: 0.1241\n",
      "Epoch 106/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.0991 - categorical_accuracy: 0.4506 - val_loss: 4.7483 - val_categorical_accuracy: 0.1448\n",
      "Epoch 107/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.9645 - categorical_accuracy: 0.4333 - val_loss: 5.0859 - val_categorical_accuracy: 0.1517\n",
      "Epoch 108/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.1019 - categorical_accuracy: 0.3934 - val_loss: 7.0326 - val_categorical_accuracy: 0.1379\n",
      "Epoch 109/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.1428 - categorical_accuracy: 0.4281 - val_loss: 6.7799 - val_categorical_accuracy: 0.0966\n",
      "Epoch 110/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.1145 - categorical_accuracy: 0.3761 - val_loss: 6.5390 - val_categorical_accuracy: 0.1034\n",
      "Epoch 111/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.5397 - categorical_accuracy: 0.3917 - val_loss: 5.3477 - val_categorical_accuracy: 0.1310\n",
      "Epoch 112/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.9526 - categorical_accuracy: 0.4021 - val_loss: 5.2475 - val_categorical_accuracy: 0.1103\n",
      "Epoch 113/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.1318 - categorical_accuracy: 0.4350 - val_loss: 5.5650 - val_categorical_accuracy: 0.1586\n",
      "Epoch 114/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.9732 - categorical_accuracy: 0.4333 - val_loss: 5.6374 - val_categorical_accuracy: 0.1172\n",
      "Epoch 115/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 2.1591 - categorical_accuracy: 0.4211 - val_loss: 5.3767 - val_categorical_accuracy: 0.1103\n",
      "Epoch 116/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.1915 - categorical_accuracy: 0.4367 - val_loss: 5.0739 - val_categorical_accuracy: 0.1379\n",
      "Epoch 117/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.1119 - categorical_accuracy: 0.4073 - val_loss: 4.2435 - val_categorical_accuracy: 0.1586\n",
      "Epoch 118/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8457 - categorical_accuracy: 0.4506 - val_loss: 4.0249 - val_categorical_accuracy: 0.1586\n",
      "Epoch 119/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.8226 - categorical_accuracy: 0.4419 - val_loss: 4.4203 - val_categorical_accuracy: 0.1586\n",
      "Epoch 120/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.8096 - categorical_accuracy: 0.4610 - val_loss: 4.7723 - val_categorical_accuracy: 0.1310\n",
      "Epoch 121/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.9000 - categorical_accuracy: 0.4402 - val_loss: 4.3612 - val_categorical_accuracy: 0.1517\n",
      "Epoch 122/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.9934 - categorical_accuracy: 0.4263 - val_loss: 4.2418 - val_categorical_accuracy: 0.1379\n",
      "Epoch 123/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.0232 - categorical_accuracy: 0.4298 - val_loss: 4.1877 - val_categorical_accuracy: 0.1655\n",
      "Epoch 124/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8638 - categorical_accuracy: 0.4177 - val_loss: 4.5025 - val_categorical_accuracy: 0.1379\n",
      "Epoch 125/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.8900 - categorical_accuracy: 0.4177 - val_loss: 4.1945 - val_categorical_accuracy: 0.1655\n",
      "Epoch 126/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.8306 - categorical_accuracy: 0.4367 - val_loss: 4.2978 - val_categorical_accuracy: 0.1586\n",
      "Epoch 127/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.9058 - categorical_accuracy: 0.4471 - val_loss: 3.9715 - val_categorical_accuracy: 0.1172\n",
      "Epoch 128/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8797 - categorical_accuracy: 0.4315 - val_loss: 4.0745 - val_categorical_accuracy: 0.1655\n",
      "Epoch 129/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.9332 - categorical_accuracy: 0.4298 - val_loss: 4.7314 - val_categorical_accuracy: 0.1241\n",
      "Epoch 130/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.8808 - categorical_accuracy: 0.4229 - val_loss: 5.0642 - val_categorical_accuracy: 0.1517\n",
      "Epoch 131/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 2.1349 - categorical_accuracy: 0.4090 - val_loss: 5.6766 - val_categorical_accuracy: 0.1310\n",
      "Epoch 132/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 2.2423 - categorical_accuracy: 0.3761 - val_loss: 5.0850 - val_categorical_accuracy: 0.1241\n",
      "Epoch 133/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.1099 - categorical_accuracy: 0.4021 - val_loss: 5.6222 - val_categorical_accuracy: 0.1310\n",
      "Epoch 134/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.1578 - categorical_accuracy: 0.4107 - val_loss: 5.6066 - val_categorical_accuracy: 0.1241\n",
      "Epoch 135/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 2.1532 - categorical_accuracy: 0.4073 - val_loss: 5.7120 - val_categorical_accuracy: 0.1172\n",
      "Epoch 136/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.9966 - categorical_accuracy: 0.4281 - val_loss: 4.8826 - val_categorical_accuracy: 0.1517\n",
      "Epoch 137/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.8431 - categorical_accuracy: 0.4437 - val_loss: 5.8677 - val_categorical_accuracy: 0.1655\n",
      "Epoch 138/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.7862 - categorical_accuracy: 0.4419 - val_loss: 6.6356 - val_categorical_accuracy: 0.1724\n",
      "Epoch 139/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7506 - categorical_accuracy: 0.4731 - val_loss: 5.7821 - val_categorical_accuracy: 0.1586\n",
      "Epoch 140/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7026 - categorical_accuracy: 0.4957 - val_loss: 7.3347 - val_categorical_accuracy: 0.2000\n",
      "Epoch 141/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.6843 - categorical_accuracy: 0.4939 - val_loss: 5.5063 - val_categorical_accuracy: 0.2138\n",
      "Epoch 142/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.7526 - categorical_accuracy: 0.4801 - val_loss: 5.6342 - val_categorical_accuracy: 0.1931\n",
      "Epoch 143/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7813 - categorical_accuracy: 0.4679 - val_loss: 5.3245 - val_categorical_accuracy: 0.1862\n",
      "Epoch 144/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7686 - categorical_accuracy: 0.4662 - val_loss: 5.8187 - val_categorical_accuracy: 0.2207\n",
      "Epoch 145/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.6998 - categorical_accuracy: 0.4749 - val_loss: 5.9325 - val_categorical_accuracy: 0.2069\n",
      "Epoch 146/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.8309 - categorical_accuracy: 0.4957 - val_loss: 5.2580 - val_categorical_accuracy: 0.2000\n",
      "Epoch 147/1000\n",
      "19/19 [==============================] - 1s 26ms/step - loss: 1.7143 - categorical_accuracy: 0.4991 - val_loss: 4.9563 - val_categorical_accuracy: 0.1724\n",
      "Epoch 148/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 3.1058 - categorical_accuracy: 0.5026 - val_loss: 6.3595 - val_categorical_accuracy: 0.1931\n",
      "Epoch 149/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 1.7776 - categorical_accuracy: 0.4697 - val_loss: 5.9917 - val_categorical_accuracy: 0.1862\n",
      "Epoch 150/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.7250 - categorical_accuracy: 0.4835 - val_loss: 6.2153 - val_categorical_accuracy: 0.1931\n",
      "Epoch 151/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7976 - categorical_accuracy: 0.4853 - val_loss: 6.0041 - val_categorical_accuracy: 0.1931\n",
      "Epoch 152/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.8462 - categorical_accuracy: 0.4350 - val_loss: 5.9247 - val_categorical_accuracy: 0.2069\n",
      "Epoch 153/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7853 - categorical_accuracy: 0.4610 - val_loss: 5.7201 - val_categorical_accuracy: 0.2069\n",
      "Epoch 154/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 1.7601 - categorical_accuracy: 0.4766 - val_loss: 5.7636 - val_categorical_accuracy: 0.2069\n",
      "Epoch 155/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7167 - categorical_accuracy: 0.4835 - val_loss: 5.9528 - val_categorical_accuracy: 0.2069\n",
      "Epoch 156/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6344 - categorical_accuracy: 0.5147 - val_loss: 6.2254 - val_categorical_accuracy: 0.2000\n",
      "Epoch 157/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.5148 - categorical_accuracy: 0.5095 - val_loss: 6.3605 - val_categorical_accuracy: 0.1862\n",
      "Epoch 158/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.4925 - categorical_accuracy: 0.5269 - val_loss: 5.0301 - val_categorical_accuracy: 0.1862\n",
      "Epoch 159/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 1.5980 - categorical_accuracy: 0.5147 - val_loss: 4.4622 - val_categorical_accuracy: 0.2276\n",
      "Epoch 160/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 1.5881 - categorical_accuracy: 0.4905 - val_loss: 4.9243 - val_categorical_accuracy: 0.2000\n",
      "Epoch 161/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5487 - categorical_accuracy: 0.5078 - val_loss: 4.6557 - val_categorical_accuracy: 0.2000\n",
      "Epoch 162/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5997 - categorical_accuracy: 0.5078 - val_loss: 5.1679 - val_categorical_accuracy: 0.2621\n",
      "Epoch 163/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.6313 - categorical_accuracy: 0.5078 - val_loss: 5.0465 - val_categorical_accuracy: 0.2345\n",
      "Epoch 164/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.5575 - categorical_accuracy: 0.5321 - val_loss: 4.6866 - val_categorical_accuracy: 0.2000\n",
      "Epoch 165/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 1.5028 - categorical_accuracy: 0.5425 - val_loss: 4.3444 - val_categorical_accuracy: 0.2069\n",
      "Epoch 166/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 1.5089 - categorical_accuracy: 0.5581 - val_loss: 4.5135 - val_categorical_accuracy: 0.1724\n",
      "Epoch 167/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 1.4801 - categorical_accuracy: 0.5355 - val_loss: 5.3016 - val_categorical_accuracy: 0.2276\n",
      "Epoch 168/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 1.6265 - categorical_accuracy: 0.5286 - val_loss: 6.2331 - val_categorical_accuracy: 0.2207\n",
      "Epoch 169/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.9350 - categorical_accuracy: 0.5095 - val_loss: 4.3967 - val_categorical_accuracy: 0.1931\n",
      "Epoch 170/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7427 - categorical_accuracy: 0.5061 - val_loss: 6.7325 - val_categorical_accuracy: 0.2207\n",
      "Epoch 171/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7273 - categorical_accuracy: 0.4922 - val_loss: 5.9692 - val_categorical_accuracy: 0.1862\n",
      "Epoch 172/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7305 - categorical_accuracy: 0.4818 - val_loss: 5.9784 - val_categorical_accuracy: 0.1931\n",
      "Epoch 173/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6294 - categorical_accuracy: 0.5009 - val_loss: 6.9951 - val_categorical_accuracy: 0.2276\n",
      "Epoch 174/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.6904 - categorical_accuracy: 0.5095 - val_loss: 8.1400 - val_categorical_accuracy: 0.2138\n",
      "Epoch 175/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5682 - categorical_accuracy: 0.5043 - val_loss: 7.9846 - val_categorical_accuracy: 0.1931\n",
      "Epoch 176/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5077 - categorical_accuracy: 0.5355 - val_loss: 7.2821 - val_categorical_accuracy: 0.1862\n",
      "Epoch 177/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.3889 - categorical_accuracy: 0.5581 - val_loss: 7.7120 - val_categorical_accuracy: 0.2276\n",
      "Epoch 178/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.3981 - categorical_accuracy: 0.5581 - val_loss: 7.3308 - val_categorical_accuracy: 0.2000\n",
      "Epoch 179/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3618 - categorical_accuracy: 0.5511 - val_loss: 7.5699 - val_categorical_accuracy: 0.2138\n",
      "Epoch 180/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3948 - categorical_accuracy: 0.5771 - val_loss: 8.6448 - val_categorical_accuracy: 0.2207\n",
      "Epoch 181/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.7593 - categorical_accuracy: 0.5303 - val_loss: 7.2789 - val_categorical_accuracy: 0.2483\n",
      "Epoch 182/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6009 - categorical_accuracy: 0.5511 - val_loss: 8.1097 - val_categorical_accuracy: 0.1931\n",
      "Epoch 183/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.7035 - categorical_accuracy: 0.5373 - val_loss: 7.2433 - val_categorical_accuracy: 0.2000\n",
      "Epoch 184/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4545 - categorical_accuracy: 0.5511 - val_loss: 7.1525 - val_categorical_accuracy: 0.2069\n",
      "Epoch 185/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4711 - categorical_accuracy: 0.5546 - val_loss: 7.9579 - val_categorical_accuracy: 0.2690\n",
      "Epoch 186/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.3826 - categorical_accuracy: 0.5737 - val_loss: 7.3714 - val_categorical_accuracy: 0.2552\n",
      "Epoch 187/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.4234 - categorical_accuracy: 0.5997 - val_loss: 7.8414 - val_categorical_accuracy: 0.2621\n",
      "Epoch 188/1000\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 1.3014 - categorical_accuracy: 0.6049 - val_loss: 7.7637 - val_categorical_accuracy: 0.2138\n",
      "Epoch 189/1000\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 1.2546 - categorical_accuracy: 0.6135 - val_loss: 8.0174 - val_categorical_accuracy: 0.2414\n",
      "Epoch 190/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.3046 - categorical_accuracy: 0.6205 - val_loss: 8.0592 - val_categorical_accuracy: 0.2207\n",
      "Epoch 191/1000\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 1.2795 - categorical_accuracy: 0.6170 - val_loss: 8.0107 - val_categorical_accuracy: 0.2276\n",
      "Epoch 192/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.4383 - categorical_accuracy: 0.6066 - val_loss: 8.0966 - val_categorical_accuracy: 0.2621\n",
      "Epoch 193/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3398 - categorical_accuracy: 0.6170 - val_loss: 8.3845 - val_categorical_accuracy: 0.2690\n",
      "Epoch 194/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.2045 - categorical_accuracy: 0.6291 - val_loss: 8.9681 - val_categorical_accuracy: 0.2690\n",
      "Epoch 195/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.1512 - categorical_accuracy: 0.6464 - val_loss: 9.1241 - val_categorical_accuracy: 0.2759\n",
      "Epoch 196/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.1640 - categorical_accuracy: 0.6343 - val_loss: 8.8284 - val_categorical_accuracy: 0.2966\n",
      "Epoch 197/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.2303 - categorical_accuracy: 0.6499 - val_loss: 8.5635 - val_categorical_accuracy: 0.2759\n",
      "Epoch 198/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.1946 - categorical_accuracy: 0.6412 - val_loss: 8.5818 - val_categorical_accuracy: 0.2897\n",
      "Epoch 199/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.1359 - categorical_accuracy: 0.6586 - val_loss: 7.3713 - val_categorical_accuracy: 0.2897\n",
      "Epoch 200/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.1696 - categorical_accuracy: 0.6412 - val_loss: 7.7197 - val_categorical_accuracy: 0.2759\n",
      "Epoch 201/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.2309 - categorical_accuracy: 0.6343 - val_loss: 8.2991 - val_categorical_accuracy: 0.2690\n",
      "Epoch 202/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.4243 - categorical_accuracy: 0.6153 - val_loss: 7.9980 - val_categorical_accuracy: 0.2552\n",
      "Epoch 203/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3659 - categorical_accuracy: 0.6066 - val_loss: 8.5735 - val_categorical_accuracy: 0.2828\n",
      "Epoch 204/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.2969 - categorical_accuracy: 0.6118 - val_loss: 7.1747 - val_categorical_accuracy: 0.2897\n",
      "Epoch 205/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.2753 - categorical_accuracy: 0.6101 - val_loss: 6.1228 - val_categorical_accuracy: 0.2690\n",
      "Epoch 206/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5617 - categorical_accuracy: 0.5563 - val_loss: 5.5651 - val_categorical_accuracy: 0.2000\n",
      "Epoch 207/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.6452 - categorical_accuracy: 0.5615 - val_loss: 6.2949 - val_categorical_accuracy: 0.2000\n",
      "Epoch 208/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7644 - categorical_accuracy: 0.5130 - val_loss: 4.9403 - val_categorical_accuracy: 0.2345\n",
      "Epoch 209/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.9613 - categorical_accuracy: 0.5078 - val_loss: 4.4600 - val_categorical_accuracy: 0.2552\n",
      "Epoch 210/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6270 - categorical_accuracy: 0.5234 - val_loss: 4.3423 - val_categorical_accuracy: 0.2207\n",
      "Epoch 211/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6967 - categorical_accuracy: 0.5043 - val_loss: 4.6154 - val_categorical_accuracy: 0.2345\n",
      "Epoch 212/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.5997 - categorical_accuracy: 0.5147 - val_loss: 4.7587 - val_categorical_accuracy: 0.2414\n",
      "Epoch 213/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5981 - categorical_accuracy: 0.5355 - val_loss: 4.9286 - val_categorical_accuracy: 0.2414\n",
      "Epoch 214/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.7188 - categorical_accuracy: 0.5373 - val_loss: 5.1611 - val_categorical_accuracy: 0.2207\n",
      "Epoch 215/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.9027 - categorical_accuracy: 0.5234 - val_loss: 5.2419 - val_categorical_accuracy: 0.2207\n",
      "Epoch 216/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 2.0089 - categorical_accuracy: 0.4645 - val_loss: 6.4288 - val_categorical_accuracy: 0.1586\n",
      "Epoch 217/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8809 - categorical_accuracy: 0.4523 - val_loss: 6.8544 - val_categorical_accuracy: 0.1793\n",
      "Epoch 218/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.6966 - categorical_accuracy: 0.4593 - val_loss: 4.6639 - val_categorical_accuracy: 0.1655\n",
      "Epoch 219/1000\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 1.6618 - categorical_accuracy: 0.4870 - val_loss: 6.0730 - val_categorical_accuracy: 0.1724\n",
      "Epoch 220/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 1.6467 - categorical_accuracy: 0.4801 - val_loss: 6.2761 - val_categorical_accuracy: 0.1862\n",
      "Epoch 221/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.7485 - categorical_accuracy: 0.4489 - val_loss: 7.6954 - val_categorical_accuracy: 0.1655\n",
      "Epoch 222/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7424 - categorical_accuracy: 0.4402 - val_loss: 7.3026 - val_categorical_accuracy: 0.2000\n",
      "Epoch 223/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6175 - categorical_accuracy: 0.4801 - val_loss: 7.5128 - val_categorical_accuracy: 0.2138\n",
      "Epoch 224/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6359 - categorical_accuracy: 0.4835 - val_loss: 7.8425 - val_categorical_accuracy: 0.1793\n",
      "Epoch 225/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5925 - categorical_accuracy: 0.4905 - val_loss: 7.2457 - val_categorical_accuracy: 0.1793\n",
      "Epoch 226/1000\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 1.5562 - categorical_accuracy: 0.5095 - val_loss: 6.6810 - val_categorical_accuracy: 0.2138\n",
      "Epoch 227/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.5286 - categorical_accuracy: 0.5269 - val_loss: 6.1539 - val_categorical_accuracy: 0.1655\n",
      "Epoch 228/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5146 - categorical_accuracy: 0.5251 - val_loss: 6.8528 - val_categorical_accuracy: 0.1931\n",
      "Epoch 229/1000\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 1.6529 - categorical_accuracy: 0.5061 - val_loss: 5.9942 - val_categorical_accuracy: 0.2345\n",
      "Epoch 230/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3.0619 - categorical_accuracy: 0.4523 - val_loss: 4.9202 - val_categorical_accuracy: 0.1931\n",
      "Epoch 231/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.9519 - categorical_accuracy: 0.4350 - val_loss: 5.2965 - val_categorical_accuracy: 0.2138\n",
      "Epoch 232/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7460 - categorical_accuracy: 0.4887 - val_loss: 5.2150 - val_categorical_accuracy: 0.1517\n",
      "Epoch 233/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7782 - categorical_accuracy: 0.5095 - val_loss: 6.3646 - val_categorical_accuracy: 0.1655\n",
      "Epoch 234/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.9580 - categorical_accuracy: 0.4957 - val_loss: 4.9442 - val_categorical_accuracy: 0.1586\n",
      "Epoch 235/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6895 - categorical_accuracy: 0.4957 - val_loss: 5.3343 - val_categorical_accuracy: 0.1379\n",
      "Epoch 236/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5970 - categorical_accuracy: 0.5165 - val_loss: 4.8151 - val_categorical_accuracy: 0.1517\n",
      "Epoch 237/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6149 - categorical_accuracy: 0.5269 - val_loss: 3.7320 - val_categorical_accuracy: 0.1724\n",
      "Epoch 238/1000\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 1.9522 - categorical_accuracy: 0.5477 - val_loss: 4.6034 - val_categorical_accuracy: 0.1655\n",
      "Epoch 239/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5076 - categorical_accuracy: 0.5425 - val_loss: 5.2614 - val_categorical_accuracy: 0.1586\n",
      "Epoch 240/1000\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 1.8739 - categorical_accuracy: 0.5234 - val_loss: 4.5771 - val_categorical_accuracy: 0.1724\n",
      "Epoch 241/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.8844 - categorical_accuracy: 0.4870 - val_loss: 4.2511 - val_categorical_accuracy: 0.1793\n",
      "Epoch 242/1000\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 1.6804 - categorical_accuracy: 0.5269 - val_loss: 5.4108 - val_categorical_accuracy: 0.2000\n",
      "Epoch 243/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.7009 - categorical_accuracy: 0.5251 - val_loss: 4.6069 - val_categorical_accuracy: 0.2207\n",
      "Epoch 244/1000\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 1.7652 - categorical_accuracy: 0.4714 - val_loss: 4.6622 - val_categorical_accuracy: 0.1862\n",
      "Epoch 245/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6970 - categorical_accuracy: 0.5009 - val_loss: 4.2287 - val_categorical_accuracy: 0.1931\n",
      "Epoch 246/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.6375 - categorical_accuracy: 0.5165 - val_loss: 4.4116 - val_categorical_accuracy: 0.1862\n",
      "Epoch 247/1000\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 1.5566 - categorical_accuracy: 0.5147 - val_loss: 5.3401 - val_categorical_accuracy: 0.2414\n",
      "Epoch 248/1000\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 1.6943 - categorical_accuracy: 0.5321 - val_loss: 4.6483 - val_categorical_accuracy: 0.2207\n",
      "Epoch 249/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.5410 - categorical_accuracy: 0.5407 - val_loss: 3.8823 - val_categorical_accuracy: 0.2069\n",
      "Epoch 250/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.4550 - categorical_accuracy: 0.5546 - val_loss: 3.2328 - val_categorical_accuracy: 0.2138\n",
      "Epoch 251/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5067 - categorical_accuracy: 0.5702 - val_loss: 3.6492 - val_categorical_accuracy: 0.2000\n",
      "Epoch 252/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4212 - categorical_accuracy: 0.5702 - val_loss: 4.5982 - val_categorical_accuracy: 0.1655\n",
      "Epoch 253/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.4022 - categorical_accuracy: 0.5667 - val_loss: 4.5964 - val_categorical_accuracy: 0.2069\n",
      "Epoch 254/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.4661 - categorical_accuracy: 0.5546 - val_loss: 3.9088 - val_categorical_accuracy: 0.1931\n",
      "Epoch 255/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.3175 - categorical_accuracy: 0.5719 - val_loss: 3.9605 - val_categorical_accuracy: 0.1724\n",
      "Epoch 256/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3658 - categorical_accuracy: 0.5650 - val_loss: 4.0189 - val_categorical_accuracy: 0.2069\n",
      "Epoch 257/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.3661 - categorical_accuracy: 0.5823 - val_loss: 4.1432 - val_categorical_accuracy: 0.1586\n",
      "Epoch 258/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.3125 - categorical_accuracy: 0.5789 - val_loss: 4.2734 - val_categorical_accuracy: 0.2000\n",
      "Epoch 259/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3979 - categorical_accuracy: 0.5771 - val_loss: 3.9062 - val_categorical_accuracy: 0.1724\n",
      "Epoch 260/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3320 - categorical_accuracy: 0.5945 - val_loss: 3.8453 - val_categorical_accuracy: 0.1862\n",
      "Epoch 261/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.3666 - categorical_accuracy: 0.6014 - val_loss: 4.3923 - val_categorical_accuracy: 0.2207\n",
      "Epoch 262/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.3295 - categorical_accuracy: 0.5893 - val_loss: 5.1172 - val_categorical_accuracy: 0.2207\n",
      "Epoch 263/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.6887 - categorical_accuracy: 0.6031 - val_loss: 5.5825 - val_categorical_accuracy: 0.2069\n",
      "Epoch 264/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4366 - categorical_accuracy: 0.5789 - val_loss: 5.3204 - val_categorical_accuracy: 0.2552\n",
      "Epoch 265/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3382 - categorical_accuracy: 0.5979 - val_loss: 5.4744 - val_categorical_accuracy: 0.2621\n",
      "Epoch 266/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3178 - categorical_accuracy: 0.5945 - val_loss: 5.5426 - val_categorical_accuracy: 0.2552\n",
      "Epoch 267/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.2962 - categorical_accuracy: 0.5962 - val_loss: 5.5366 - val_categorical_accuracy: 0.2345\n",
      "Epoch 268/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3113 - categorical_accuracy: 0.5979 - val_loss: 6.0678 - val_categorical_accuracy: 0.2552\n",
      "Epoch 269/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6797 - categorical_accuracy: 0.5511 - val_loss: 5.3480 - val_categorical_accuracy: 0.2276\n",
      "Epoch 270/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7334 - categorical_accuracy: 0.5338 - val_loss: 4.4944 - val_categorical_accuracy: 0.2207\n",
      "Epoch 271/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6739 - categorical_accuracy: 0.5182 - val_loss: 4.7769 - val_categorical_accuracy: 0.2276\n",
      "Epoch 272/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5755 - categorical_accuracy: 0.5459 - val_loss: 5.0066 - val_categorical_accuracy: 0.2621\n",
      "Epoch 273/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5092 - categorical_accuracy: 0.5459 - val_loss: 4.1947 - val_categorical_accuracy: 0.2690\n",
      "Epoch 274/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6284 - categorical_accuracy: 0.5251 - val_loss: 5.1757 - val_categorical_accuracy: 0.2552\n",
      "Epoch 275/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5160 - categorical_accuracy: 0.5425 - val_loss: 5.7410 - val_categorical_accuracy: 0.2483\n",
      "Epoch 276/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.4459 - categorical_accuracy: 0.5494 - val_loss: 5.9768 - val_categorical_accuracy: 0.2414\n",
      "Epoch 277/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4268 - categorical_accuracy: 0.5754 - val_loss: 5.5982 - val_categorical_accuracy: 0.2621\n",
      "Epoch 278/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5769 - categorical_accuracy: 0.5529 - val_loss: 5.6410 - val_categorical_accuracy: 0.2414\n",
      "Epoch 279/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6181 - categorical_accuracy: 0.5581 - val_loss: 7.7845 - val_categorical_accuracy: 0.2345\n",
      "Epoch 280/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.4798 - categorical_accuracy: 0.5529 - val_loss: 7.5640 - val_categorical_accuracy: 0.2345\n",
      "Epoch 281/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3675 - categorical_accuracy: 0.5823 - val_loss: 7.6308 - val_categorical_accuracy: 0.2483\n",
      "Epoch 282/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4523 - categorical_accuracy: 0.5771 - val_loss: 8.2553 - val_categorical_accuracy: 0.2276\n",
      "Epoch 283/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7593 - categorical_accuracy: 0.4766 - val_loss: 7.1213 - val_categorical_accuracy: 0.1793\n",
      "Epoch 284/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.9751 - categorical_accuracy: 0.5026 - val_loss: 6.2405 - val_categorical_accuracy: 0.1724\n",
      "Epoch 285/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5708 - categorical_accuracy: 0.5269 - val_loss: 5.6392 - val_categorical_accuracy: 0.2207\n",
      "Epoch 286/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4801 - categorical_accuracy: 0.5407 - val_loss: 6.2032 - val_categorical_accuracy: 0.2138\n",
      "Epoch 287/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5144 - categorical_accuracy: 0.5407 - val_loss: 5.5655 - val_categorical_accuracy: 0.2000\n",
      "Epoch 288/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8001 - categorical_accuracy: 0.5598 - val_loss: 5.7596 - val_categorical_accuracy: 0.2207\n",
      "Epoch 289/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5117 - categorical_accuracy: 0.5546 - val_loss: 5.0264 - val_categorical_accuracy: 0.2069\n",
      "Epoch 290/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6602 - categorical_accuracy: 0.5095 - val_loss: 4.6638 - val_categorical_accuracy: 0.1517\n",
      "Epoch 291/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6469 - categorical_accuracy: 0.4974 - val_loss: 6.0494 - val_categorical_accuracy: 0.1862\n",
      "Epoch 292/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6266 - categorical_accuracy: 0.5390 - val_loss: 5.0008 - val_categorical_accuracy: 0.2276\n",
      "Epoch 293/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.4943 - categorical_accuracy: 0.5425 - val_loss: 5.9406 - val_categorical_accuracy: 0.2000\n",
      "Epoch 294/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4976 - categorical_accuracy: 0.5407 - val_loss: 6.1931 - val_categorical_accuracy: 0.1862\n",
      "Epoch 295/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5219 - categorical_accuracy: 0.5477 - val_loss: 5.8469 - val_categorical_accuracy: 0.2000\n",
      "Epoch 296/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4537 - categorical_accuracy: 0.5546 - val_loss: 5.9342 - val_categorical_accuracy: 0.2000\n",
      "Epoch 297/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5001 - categorical_accuracy: 0.5581 - val_loss: 6.9170 - val_categorical_accuracy: 0.2000\n",
      "Epoch 298/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7398 - categorical_accuracy: 0.4922 - val_loss: 6.9352 - val_categorical_accuracy: 0.1586\n",
      "Epoch 299/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7230 - categorical_accuracy: 0.5026 - val_loss: 8.8609 - val_categorical_accuracy: 0.1379\n",
      "Epoch 300/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7255 - categorical_accuracy: 0.4870 - val_loss: 8.6317 - val_categorical_accuracy: 0.1448\n",
      "Epoch 301/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5661 - categorical_accuracy: 0.5095 - val_loss: 8.6137 - val_categorical_accuracy: 0.2000\n",
      "Epoch 302/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.5102 - categorical_accuracy: 0.5442 - val_loss: 7.5222 - val_categorical_accuracy: 0.1724\n",
      "Epoch 303/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.4686 - categorical_accuracy: 0.5251 - val_loss: 7.5986 - val_categorical_accuracy: 0.1586\n",
      "Epoch 304/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4748 - categorical_accuracy: 0.5442 - val_loss: 6.3346 - val_categorical_accuracy: 0.1724\n",
      "Epoch 305/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3285 - categorical_accuracy: 0.5754 - val_loss: 4.8863 - val_categorical_accuracy: 0.2000\n",
      "Epoch 306/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.2916 - categorical_accuracy: 0.5945 - val_loss: 8.7660 - val_categorical_accuracy: 0.1862\n",
      "Epoch 307/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3388 - categorical_accuracy: 0.5806 - val_loss: 8.0167 - val_categorical_accuracy: 0.1862\n",
      "Epoch 308/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5477 - categorical_accuracy: 0.5546 - val_loss: 7.8538 - val_categorical_accuracy: 0.2207\n",
      "Epoch 309/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.3947 - categorical_accuracy: 0.5737 - val_loss: 8.1126 - val_categorical_accuracy: 0.2345\n",
      "Epoch 310/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.3495 - categorical_accuracy: 0.5910 - val_loss: 9.6352 - val_categorical_accuracy: 0.2069\n",
      "Epoch 311/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.2795 - categorical_accuracy: 0.5997 - val_loss: 10.3196 - val_categorical_accuracy: 0.2138\n",
      "Epoch 312/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3629 - categorical_accuracy: 0.5858 - val_loss: 9.7197 - val_categorical_accuracy: 0.2138\n",
      "Epoch 313/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5074 - categorical_accuracy: 0.5806 - val_loss: 9.7652 - val_categorical_accuracy: 0.2069\n",
      "Epoch 314/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4900 - categorical_accuracy: 0.5806 - val_loss: 6.3515 - val_categorical_accuracy: 0.2000\n",
      "Epoch 315/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5531 - categorical_accuracy: 0.5806 - val_loss: 4.9879 - val_categorical_accuracy: 0.1862\n",
      "Epoch 316/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4665 - categorical_accuracy: 0.5546 - val_loss: 4.4998 - val_categorical_accuracy: 0.1931\n",
      "Epoch 317/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5181 - categorical_accuracy: 0.5546 - val_loss: 4.9968 - val_categorical_accuracy: 0.2276\n",
      "Epoch 318/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4645 - categorical_accuracy: 0.5667 - val_loss: 5.1548 - val_categorical_accuracy: 0.2621\n",
      "Epoch 319/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4138 - categorical_accuracy: 0.5754 - val_loss: 5.4220 - val_categorical_accuracy: 0.2621\n",
      "Epoch 320/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.3623 - categorical_accuracy: 0.5806 - val_loss: 5.2747 - val_categorical_accuracy: 0.3034\n",
      "Epoch 321/1000\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 1.3314 - categorical_accuracy: 0.5893 - val_loss: 5.6207 - val_categorical_accuracy: 0.2483\n",
      "Epoch 322/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.2798 - categorical_accuracy: 0.5910 - val_loss: 5.7848 - val_categorical_accuracy: 0.2483\n",
      "Epoch 323/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.5265 - categorical_accuracy: 0.5737 - val_loss: 5.6045 - val_categorical_accuracy: 0.2690\n",
      "Epoch 324/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.3366 - categorical_accuracy: 0.5841 - val_loss: 5.6278 - val_categorical_accuracy: 0.2552\n",
      "Epoch 325/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3002 - categorical_accuracy: 0.5893 - val_loss: 5.4636 - val_categorical_accuracy: 0.2345\n",
      "Epoch 326/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3344 - categorical_accuracy: 0.5841 - val_loss: 5.7440 - val_categorical_accuracy: 0.2276\n",
      "Epoch 327/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3217 - categorical_accuracy: 0.5771 - val_loss: 5.6010 - val_categorical_accuracy: 0.2345\n",
      "Epoch 328/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.3169 - categorical_accuracy: 0.5719 - val_loss: 6.1688 - val_categorical_accuracy: 0.2069\n",
      "Epoch 329/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.2742 - categorical_accuracy: 0.5841 - val_loss: 6.2239 - val_categorical_accuracy: 0.2138\n",
      "Epoch 330/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3757 - categorical_accuracy: 0.5789 - val_loss: 5.5106 - val_categorical_accuracy: 0.2345\n",
      "Epoch 331/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.2709 - categorical_accuracy: 0.5910 - val_loss: 5.9206 - val_categorical_accuracy: 0.2483\n",
      "Epoch 332/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.2863 - categorical_accuracy: 0.5927 - val_loss: 6.2076 - val_categorical_accuracy: 0.2552\n",
      "Epoch 333/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6352 - categorical_accuracy: 0.5979 - val_loss: 6.2182 - val_categorical_accuracy: 0.2483\n",
      "Epoch 334/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3531 - categorical_accuracy: 0.5719 - val_loss: 5.9979 - val_categorical_accuracy: 0.2414\n",
      "Epoch 335/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.4557 - categorical_accuracy: 0.5511 - val_loss: 5.4856 - val_categorical_accuracy: 0.2414\n",
      "Epoch 336/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5191 - categorical_accuracy: 0.5581 - val_loss: 4.2382 - val_categorical_accuracy: 0.2552\n",
      "Epoch 337/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5075 - categorical_accuracy: 0.5459 - val_loss: 4.3392 - val_categorical_accuracy: 0.2414\n",
      "Epoch 338/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4450 - categorical_accuracy: 0.5390 - val_loss: 5.6211 - val_categorical_accuracy: 0.2414\n",
      "Epoch 339/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4566 - categorical_accuracy: 0.5754 - val_loss: 8.2347 - val_categorical_accuracy: 0.2345\n",
      "Epoch 340/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3706 - categorical_accuracy: 0.5719 - val_loss: 6.9581 - val_categorical_accuracy: 0.2069\n",
      "Epoch 341/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4061 - categorical_accuracy: 0.5754 - val_loss: 7.2341 - val_categorical_accuracy: 0.2552\n",
      "Epoch 342/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.3914 - categorical_accuracy: 0.5789 - val_loss: 6.6831 - val_categorical_accuracy: 0.2552\n",
      "Epoch 343/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3299 - categorical_accuracy: 0.5685 - val_loss: 7.3676 - val_categorical_accuracy: 0.2621\n",
      "Epoch 344/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4364 - categorical_accuracy: 0.5407 - val_loss: 6.8522 - val_categorical_accuracy: 0.2621\n",
      "Epoch 345/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5236 - categorical_accuracy: 0.5373 - val_loss: 6.7133 - val_categorical_accuracy: 0.2483\n",
      "Epoch 346/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.4322 - categorical_accuracy: 0.5581 - val_loss: 5.6397 - val_categorical_accuracy: 0.2897\n",
      "Epoch 347/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7561 - categorical_accuracy: 0.5546 - val_loss: 5.2220 - val_categorical_accuracy: 0.2690\n",
      "Epoch 348/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.3957 - categorical_accuracy: 0.5407 - val_loss: 5.0225 - val_categorical_accuracy: 0.2069\n",
      "Epoch 349/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3683 - categorical_accuracy: 0.5702 - val_loss: 4.9365 - val_categorical_accuracy: 0.1931\n",
      "Epoch 350/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.3843 - categorical_accuracy: 0.5702 - val_loss: 4.7287 - val_categorical_accuracy: 0.1931\n",
      "Epoch 351/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4431 - categorical_accuracy: 0.5754 - val_loss: 4.5876 - val_categorical_accuracy: 0.2552\n",
      "Epoch 352/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5491 - categorical_accuracy: 0.5806 - val_loss: 4.6796 - val_categorical_accuracy: 0.2759\n",
      "Epoch 353/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3507 - categorical_accuracy: 0.5875 - val_loss: 5.1860 - val_categorical_accuracy: 0.2759\n",
      "Epoch 354/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.3001 - categorical_accuracy: 0.5962 - val_loss: 5.1487 - val_categorical_accuracy: 0.2828\n",
      "Epoch 355/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.2797 - categorical_accuracy: 0.5945 - val_loss: 5.0936 - val_categorical_accuracy: 0.2759\n",
      "Epoch 356/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.2602 - categorical_accuracy: 0.5962 - val_loss: 5.4539 - val_categorical_accuracy: 0.2828\n",
      "Epoch 357/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5045 - categorical_accuracy: 0.5910 - val_loss: 5.9148 - val_categorical_accuracy: 0.2759\n",
      "Epoch 358/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.4925 - categorical_accuracy: 0.5789 - val_loss: 6.0002 - val_categorical_accuracy: 0.2690\n",
      "Epoch 359/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3551 - categorical_accuracy: 0.5806 - val_loss: 6.4768 - val_categorical_accuracy: 0.2552\n",
      "Epoch 360/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3624 - categorical_accuracy: 0.5789 - val_loss: 6.2115 - val_categorical_accuracy: 0.2759\n",
      "Epoch 361/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3495 - categorical_accuracy: 0.5754 - val_loss: 8.3706 - val_categorical_accuracy: 0.2897\n",
      "Epoch 362/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.3489 - categorical_accuracy: 0.5823 - val_loss: 7.9419 - val_categorical_accuracy: 0.2759\n",
      "Epoch 363/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3573 - categorical_accuracy: 0.5754 - val_loss: 7.4776 - val_categorical_accuracy: 0.2828\n",
      "Epoch 364/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.2993 - categorical_accuracy: 0.5841 - val_loss: 8.0545 - val_categorical_accuracy: 0.2690\n",
      "Epoch 365/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.2848 - categorical_accuracy: 0.5927 - val_loss: 8.1727 - val_categorical_accuracy: 0.2621\n",
      "Epoch 366/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4755 - categorical_accuracy: 0.5667 - val_loss: 7.8608 - val_categorical_accuracy: 0.2552\n",
      "Epoch 367/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3931 - categorical_accuracy: 0.5633 - val_loss: 7.0081 - val_categorical_accuracy: 0.2276\n",
      "Epoch 368/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4808 - categorical_accuracy: 0.5442 - val_loss: 7.6039 - val_categorical_accuracy: 0.2345\n",
      "Epoch 369/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.4028 - categorical_accuracy: 0.5615 - val_loss: 7.9525 - val_categorical_accuracy: 0.2276\n",
      "Epoch 370/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4503 - categorical_accuracy: 0.5442 - val_loss: 7.0293 - val_categorical_accuracy: 0.2000\n",
      "Epoch 371/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5049 - categorical_accuracy: 0.5459 - val_loss: 6.6998 - val_categorical_accuracy: 0.2414\n",
      "Epoch 372/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5135 - categorical_accuracy: 0.5407 - val_loss: 5.4046 - val_categorical_accuracy: 0.2690\n",
      "Epoch 373/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5186 - categorical_accuracy: 0.5355 - val_loss: 5.2707 - val_categorical_accuracy: 0.2207\n",
      "Epoch 374/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8246 - categorical_accuracy: 0.4801 - val_loss: 4.9228 - val_categorical_accuracy: 0.2138\n",
      "Epoch 375/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.7686 - categorical_accuracy: 0.4714 - val_loss: 4.7298 - val_categorical_accuracy: 0.2138\n",
      "Epoch 376/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.8635 - categorical_accuracy: 0.4853 - val_loss: 4.5629 - val_categorical_accuracy: 0.2345\n",
      "Epoch 377/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.7373 - categorical_accuracy: 0.4558 - val_loss: 8.6212 - val_categorical_accuracy: 0.2345\n",
      "Epoch 378/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6452 - categorical_accuracy: 0.4783 - val_loss: 8.7165 - val_categorical_accuracy: 0.2276\n",
      "Epoch 379/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6234 - categorical_accuracy: 0.4922 - val_loss: 9.1811 - val_categorical_accuracy: 0.2690\n",
      "Epoch 380/1000\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 1.8729 - categorical_accuracy: 0.5269 - val_loss: 9.5206 - val_categorical_accuracy: 0.2552\n",
      "Epoch 381/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.7003 - categorical_accuracy: 0.5130 - val_loss: 10.9232 - val_categorical_accuracy: 0.2207\n",
      "Epoch 382/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.7086 - categorical_accuracy: 0.5113 - val_loss: 11.9806 - val_categorical_accuracy: 0.2621\n",
      "Epoch 383/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.7178 - categorical_accuracy: 0.5095 - val_loss: 14.0856 - val_categorical_accuracy: 0.2345\n",
      "Epoch 384/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8387 - categorical_accuracy: 0.4818 - val_loss: 10.6576 - val_categorical_accuracy: 0.2621\n",
      "Epoch 385/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.8317 - categorical_accuracy: 0.4593 - val_loss: 4.3204 - val_categorical_accuracy: 0.2276\n",
      "Epoch 386/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.1598 - categorical_accuracy: 0.4541 - val_loss: 4.3988 - val_categorical_accuracy: 0.2621\n",
      "Epoch 387/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8834 - categorical_accuracy: 0.4627 - val_loss: 4.4300 - val_categorical_accuracy: 0.2621\n",
      "Epoch 388/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4.5979 - categorical_accuracy: 0.4835 - val_loss: 4.3871 - val_categorical_accuracy: 0.2000\n",
      "Epoch 389/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.2075 - categorical_accuracy: 0.3276 - val_loss: 3.5021 - val_categorical_accuracy: 0.1655\n",
      "Epoch 390/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.1359 - categorical_accuracy: 0.3276 - val_loss: 3.6266 - val_categorical_accuracy: 0.2000\n",
      "Epoch 391/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.9954 - categorical_accuracy: 0.3640 - val_loss: 3.2647 - val_categorical_accuracy: 0.2000\n",
      "Epoch 392/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.0269 - categorical_accuracy: 0.3570 - val_loss: 3.9384 - val_categorical_accuracy: 0.1931\n",
      "Epoch 393/1000\n",
      "19/19 [==============================] - 1s 35ms/step - loss: 2.0503 - categorical_accuracy: 0.3570 - val_loss: 4.3106 - val_categorical_accuracy: 0.2000\n",
      "Epoch 394/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.0286 - categorical_accuracy: 0.3778 - val_loss: 4.0967 - val_categorical_accuracy: 0.2207\n",
      "Epoch 395/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.0222 - categorical_accuracy: 0.4159 - val_loss: 3.4591 - val_categorical_accuracy: 0.2483\n",
      "Epoch 396/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.0341 - categorical_accuracy: 0.4385 - val_loss: 3.7061 - val_categorical_accuracy: 0.2483\n",
      "Epoch 397/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8595 - categorical_accuracy: 0.4211 - val_loss: 3.3186 - val_categorical_accuracy: 0.2483\n",
      "Epoch 398/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7754 - categorical_accuracy: 0.4402 - val_loss: 4.2257 - val_categorical_accuracy: 0.2276\n",
      "Epoch 399/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.6847 - categorical_accuracy: 0.4645 - val_loss: 4.1975 - val_categorical_accuracy: 0.2276\n",
      "Epoch 400/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6810 - categorical_accuracy: 0.4558 - val_loss: 4.1591 - val_categorical_accuracy: 0.2414\n",
      "Epoch 401/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6322 - categorical_accuracy: 0.4853 - val_loss: 4.0455 - val_categorical_accuracy: 0.2414\n",
      "Epoch 402/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5852 - categorical_accuracy: 0.4974 - val_loss: 4.2404 - val_categorical_accuracy: 0.2552\n",
      "Epoch 403/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5590 - categorical_accuracy: 0.5043 - val_loss: 4.4517 - val_categorical_accuracy: 0.2897\n",
      "Epoch 404/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5853 - categorical_accuracy: 0.5026 - val_loss: 5.2163 - val_categorical_accuracy: 0.2414\n",
      "Epoch 405/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5984 - categorical_accuracy: 0.5061 - val_loss: 5.8371 - val_categorical_accuracy: 0.2552\n",
      "Epoch 406/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.6017 - categorical_accuracy: 0.5061 - val_loss: 5.0327 - val_categorical_accuracy: 0.2621\n",
      "Epoch 407/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6037 - categorical_accuracy: 0.5009 - val_loss: 4.2107 - val_categorical_accuracy: 0.2483\n",
      "Epoch 408/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5788 - categorical_accuracy: 0.5026 - val_loss: 4.2340 - val_categorical_accuracy: 0.2552\n",
      "Epoch 409/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5604 - categorical_accuracy: 0.5095 - val_loss: 4.3363 - val_categorical_accuracy: 0.2690\n",
      "Epoch 410/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5327 - categorical_accuracy: 0.5147 - val_loss: 3.7112 - val_categorical_accuracy: 0.2552\n",
      "Epoch 411/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5769 - categorical_accuracy: 0.5095 - val_loss: 3.7980 - val_categorical_accuracy: 0.2621\n",
      "Epoch 412/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.5449 - categorical_accuracy: 0.5113 - val_loss: 3.9037 - val_categorical_accuracy: 0.2552\n",
      "Epoch 413/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6314 - categorical_accuracy: 0.5009 - val_loss: 3.2241 - val_categorical_accuracy: 0.2483\n",
      "Epoch 414/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5481 - categorical_accuracy: 0.5113 - val_loss: 3.2135 - val_categorical_accuracy: 0.2483\n",
      "Epoch 415/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5200 - categorical_accuracy: 0.5095 - val_loss: 3.3816 - val_categorical_accuracy: 0.2759\n",
      "Epoch 416/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5505 - categorical_accuracy: 0.5078 - val_loss: 3.5655 - val_categorical_accuracy: 0.3034\n",
      "Epoch 417/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5156 - categorical_accuracy: 0.5251 - val_loss: 3.4895 - val_categorical_accuracy: 0.2966\n",
      "Epoch 418/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5215 - categorical_accuracy: 0.5251 - val_loss: 3.8197 - val_categorical_accuracy: 0.2690\n",
      "Epoch 419/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5031 - categorical_accuracy: 0.5269 - val_loss: 3.8022 - val_categorical_accuracy: 0.2690\n",
      "Epoch 420/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4924 - categorical_accuracy: 0.5338 - val_loss: 3.8765 - val_categorical_accuracy: 0.2759\n",
      "Epoch 421/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.4865 - categorical_accuracy: 0.5355 - val_loss: 4.2129 - val_categorical_accuracy: 0.2897\n",
      "Epoch 422/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4508 - categorical_accuracy: 0.5269 - val_loss: 4.0671 - val_categorical_accuracy: 0.2966\n",
      "Epoch 423/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5077 - categorical_accuracy: 0.5355 - val_loss: 4.2618 - val_categorical_accuracy: 0.2966\n",
      "Epoch 424/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8795 - categorical_accuracy: 0.5078 - val_loss: 5.0214 - val_categorical_accuracy: 0.2690\n",
      "Epoch 425/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6270 - categorical_accuracy: 0.4957 - val_loss: 4.4546 - val_categorical_accuracy: 0.3034\n",
      "Epoch 426/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5562 - categorical_accuracy: 0.5043 - val_loss: 4.5556 - val_categorical_accuracy: 0.2759\n",
      "Epoch 427/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5417 - categorical_accuracy: 0.5165 - val_loss: 4.4359 - val_categorical_accuracy: 0.2690\n",
      "Epoch 428/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6104 - categorical_accuracy: 0.5078 - val_loss: 5.2303 - val_categorical_accuracy: 0.2690\n",
      "Epoch 429/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.5899 - categorical_accuracy: 0.5078 - val_loss: 4.1710 - val_categorical_accuracy: 0.2966\n",
      "Epoch 430/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6336 - categorical_accuracy: 0.5095 - val_loss: 4.1344 - val_categorical_accuracy: 0.2897\n",
      "Epoch 431/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5535 - categorical_accuracy: 0.5130 - val_loss: 4.9881 - val_categorical_accuracy: 0.2621\n",
      "Epoch 432/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5095 - categorical_accuracy: 0.5251 - val_loss: 4.7326 - val_categorical_accuracy: 0.2552\n",
      "Epoch 433/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4885 - categorical_accuracy: 0.5338 - val_loss: 5.5566 - val_categorical_accuracy: 0.2690\n",
      "Epoch 434/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4664 - categorical_accuracy: 0.5321 - val_loss: 5.6198 - val_categorical_accuracy: 0.2759\n",
      "Epoch 435/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.4558 - categorical_accuracy: 0.5373 - val_loss: 5.6182 - val_categorical_accuracy: 0.2828\n",
      "Epoch 436/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.4266 - categorical_accuracy: 0.5425 - val_loss: 5.6442 - val_categorical_accuracy: 0.2690\n",
      "Epoch 437/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.4121 - categorical_accuracy: 0.5511 - val_loss: 5.5782 - val_categorical_accuracy: 0.3103\n",
      "Epoch 438/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.7367 - categorical_accuracy: 0.5494 - val_loss: 5.8341 - val_categorical_accuracy: 0.2828\n",
      "Epoch 439/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4374 - categorical_accuracy: 0.5442 - val_loss: 5.3166 - val_categorical_accuracy: 0.2759\n",
      "Epoch 440/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.4069 - categorical_accuracy: 0.5494 - val_loss: 6.1907 - val_categorical_accuracy: 0.2759\n",
      "Epoch 441/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4740 - categorical_accuracy: 0.5425 - val_loss: 4.9391 - val_categorical_accuracy: 0.2828\n",
      "Epoch 442/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4512 - categorical_accuracy: 0.5407 - val_loss: 5.1236 - val_categorical_accuracy: 0.2552\n",
      "Epoch 443/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.4334 - categorical_accuracy: 0.5511 - val_loss: 5.3807 - val_categorical_accuracy: 0.2621\n",
      "Epoch 444/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5106 - categorical_accuracy: 0.5373 - val_loss: 8.8119 - val_categorical_accuracy: 0.2828\n",
      "Epoch 445/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4997 - categorical_accuracy: 0.5286 - val_loss: 6.3814 - val_categorical_accuracy: 0.2759\n",
      "Epoch 446/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5845 - categorical_accuracy: 0.5182 - val_loss: 9.0803 - val_categorical_accuracy: 0.2759\n",
      "Epoch 447/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5091 - categorical_accuracy: 0.5251 - val_loss: 5.3932 - val_categorical_accuracy: 0.2690\n",
      "Epoch 448/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4663 - categorical_accuracy: 0.5355 - val_loss: 5.9896 - val_categorical_accuracy: 0.2897\n",
      "Epoch 449/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4830 - categorical_accuracy: 0.5338 - val_loss: 11.8473 - val_categorical_accuracy: 0.3034\n",
      "Epoch 450/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.9816 - categorical_accuracy: 0.5373 - val_loss: 7.9153 - val_categorical_accuracy: 0.2690\n",
      "Epoch 451/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.5242 - categorical_accuracy: 0.5303 - val_loss: 6.8886 - val_categorical_accuracy: 0.2483\n",
      "Epoch 452/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5324 - categorical_accuracy: 0.5269 - val_loss: 7.2037 - val_categorical_accuracy: 0.2690\n",
      "Epoch 453/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5541 - categorical_accuracy: 0.5321 - val_loss: 8.2929 - val_categorical_accuracy: 0.2828\n",
      "Epoch 454/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5697 - categorical_accuracy: 0.5113 - val_loss: 10.0687 - val_categorical_accuracy: 0.2552\n",
      "Epoch 455/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5731 - categorical_accuracy: 0.5217 - val_loss: 11.0091 - val_categorical_accuracy: 0.2828\n",
      "Epoch 456/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.0931 - categorical_accuracy: 0.5078 - val_loss: 9.3033 - val_categorical_accuracy: 0.2483\n",
      "Epoch 457/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5141 - categorical_accuracy: 0.5390 - val_loss: 11.3444 - val_categorical_accuracy: 0.2552\n",
      "Epoch 458/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5471 - categorical_accuracy: 0.5321 - val_loss: 11.0582 - val_categorical_accuracy: 0.2897\n",
      "Epoch 459/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.8601 - categorical_accuracy: 0.5407 - val_loss: 5.4914 - val_categorical_accuracy: 0.2828\n",
      "Epoch 460/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.0083 - categorical_accuracy: 0.5425 - val_loss: 4.6311 - val_categorical_accuracy: 0.2828\n",
      "Epoch 461/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4246 - categorical_accuracy: 0.5477 - val_loss: 5.1096 - val_categorical_accuracy: 0.2483\n",
      "Epoch 462/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.3986 - categorical_accuracy: 0.5529 - val_loss: 5.1259 - val_categorical_accuracy: 0.2759\n",
      "Epoch 463/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5296 - categorical_accuracy: 0.5546 - val_loss: 4.2120 - val_categorical_accuracy: 0.2966\n",
      "Epoch 464/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4418 - categorical_accuracy: 0.5477 - val_loss: 3.8356 - val_categorical_accuracy: 0.2897\n",
      "Epoch 465/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.4113 - categorical_accuracy: 0.5494 - val_loss: 3.7522 - val_categorical_accuracy: 0.2828\n",
      "Epoch 466/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3960 - categorical_accuracy: 0.5546 - val_loss: 3.7800 - val_categorical_accuracy: 0.2897\n",
      "Epoch 467/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3944 - categorical_accuracy: 0.5546 - val_loss: 3.9551 - val_categorical_accuracy: 0.2828\n",
      "Epoch 468/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3908 - categorical_accuracy: 0.5529 - val_loss: 4.8786 - val_categorical_accuracy: 0.2897\n",
      "Epoch 469/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3967 - categorical_accuracy: 0.5511 - val_loss: 4.2530 - val_categorical_accuracy: 0.3034\n",
      "Epoch 470/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4481 - categorical_accuracy: 0.5442 - val_loss: 6.4387 - val_categorical_accuracy: 0.3034\n",
      "Epoch 471/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6202 - categorical_accuracy: 0.5217 - val_loss: 4.9372 - val_categorical_accuracy: 0.3103\n",
      "Epoch 472/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5410 - categorical_accuracy: 0.5217 - val_loss: 5.4373 - val_categorical_accuracy: 0.2897\n",
      "Epoch 473/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.6217 - categorical_accuracy: 0.5199 - val_loss: 5.3996 - val_categorical_accuracy: 0.2966\n",
      "Epoch 474/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5451 - categorical_accuracy: 0.5199 - val_loss: 4.5305 - val_categorical_accuracy: 0.2828\n",
      "Epoch 475/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5494 - categorical_accuracy: 0.5147 - val_loss: 4.3097 - val_categorical_accuracy: 0.2828\n",
      "Epoch 476/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5255 - categorical_accuracy: 0.5269 - val_loss: 4.2783 - val_categorical_accuracy: 0.3103\n",
      "Epoch 477/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.4851 - categorical_accuracy: 0.5182 - val_loss: 4.1623 - val_categorical_accuracy: 0.3103\n",
      "Epoch 478/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4467 - categorical_accuracy: 0.5390 - val_loss: 4.2038 - val_categorical_accuracy: 0.3103\n",
      "Epoch 479/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4107 - categorical_accuracy: 0.5407 - val_loss: 4.6611 - val_categorical_accuracy: 0.3034\n",
      "Epoch 480/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.3945 - categorical_accuracy: 0.5494 - val_loss: 4.7979 - val_categorical_accuracy: 0.2966\n",
      "Epoch 481/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.3867 - categorical_accuracy: 0.5529 - val_loss: 4.6875 - val_categorical_accuracy: 0.2897\n",
      "Epoch 482/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.3671 - categorical_accuracy: 0.5529 - val_loss: 4.4092 - val_categorical_accuracy: 0.2966\n",
      "Epoch 483/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.3631 - categorical_accuracy: 0.5633 - val_loss: 5.6300 - val_categorical_accuracy: 0.3034\n",
      "Epoch 484/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5204 - categorical_accuracy: 0.5563 - val_loss: 5.4807 - val_categorical_accuracy: 0.2690\n",
      "Epoch 485/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4766 - categorical_accuracy: 0.5511 - val_loss: 5.4053 - val_categorical_accuracy: 0.2897\n",
      "Epoch 486/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4047 - categorical_accuracy: 0.5581 - val_loss: 5.7216 - val_categorical_accuracy: 0.2690\n",
      "Epoch 487/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.3586 - categorical_accuracy: 0.5685 - val_loss: 5.5011 - val_categorical_accuracy: 0.2690\n",
      "Epoch 488/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4641 - categorical_accuracy: 0.5546 - val_loss: 4.9791 - val_categorical_accuracy: 0.2759\n",
      "Epoch 489/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5134 - categorical_accuracy: 0.5442 - val_loss: 4.5575 - val_categorical_accuracy: 0.3034\n",
      "Epoch 490/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.7138 - categorical_accuracy: 0.5286 - val_loss: 4.2806 - val_categorical_accuracy: 0.2897\n",
      "Epoch 491/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5553 - categorical_accuracy: 0.5147 - val_loss: 4.7552 - val_categorical_accuracy: 0.2966\n",
      "Epoch 492/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5255 - categorical_accuracy: 0.5147 - val_loss: 4.0703 - val_categorical_accuracy: 0.2690\n",
      "Epoch 493/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5292 - categorical_accuracy: 0.5217 - val_loss: 4.4354 - val_categorical_accuracy: 0.2897\n",
      "Epoch 494/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5596 - categorical_accuracy: 0.5095 - val_loss: 5.2297 - val_categorical_accuracy: 0.2759\n",
      "Epoch 495/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7286 - categorical_accuracy: 0.5095 - val_loss: 6.4589 - val_categorical_accuracy: 0.2552\n",
      "Epoch 496/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.6302 - categorical_accuracy: 0.5078 - val_loss: 5.3409 - val_categorical_accuracy: 0.2828\n",
      "Epoch 497/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.5570 - categorical_accuracy: 0.5130 - val_loss: 8.6218 - val_categorical_accuracy: 0.2621\n",
      "Epoch 498/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.4969 - categorical_accuracy: 0.5147 - val_loss: 6.3227 - val_categorical_accuracy: 0.2483\n",
      "Epoch 499/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4395 - categorical_accuracy: 0.5355 - val_loss: 5.7209 - val_categorical_accuracy: 0.2897\n",
      "Epoch 500/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5936 - categorical_accuracy: 0.5303 - val_loss: 6.1806 - val_categorical_accuracy: 0.2828\n",
      "Epoch 501/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.4798 - categorical_accuracy: 0.5199 - val_loss: 7.2270 - val_categorical_accuracy: 0.2966\n",
      "Epoch 502/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.5439 - categorical_accuracy: 0.5234 - val_loss: 6.4420 - val_categorical_accuracy: 0.2966\n",
      "Epoch 503/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5604 - categorical_accuracy: 0.5251 - val_loss: 6.2548 - val_categorical_accuracy: 0.2621\n",
      "Epoch 504/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6173 - categorical_accuracy: 0.4818 - val_loss: 7.2693 - val_categorical_accuracy: 0.2552\n",
      "Epoch 505/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.8049 - categorical_accuracy: 0.4575 - val_loss: 7.4814 - val_categorical_accuracy: 0.2483\n",
      "Epoch 506/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.9021 - categorical_accuracy: 0.4645 - val_loss: 6.4184 - val_categorical_accuracy: 0.2759\n",
      "Epoch 507/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.9121 - categorical_accuracy: 0.4679 - val_loss: 3.3980 - val_categorical_accuracy: 0.2828\n",
      "Epoch 508/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.6678 - categorical_accuracy: 0.4835 - val_loss: 3.8731 - val_categorical_accuracy: 0.2828\n",
      "Epoch 509/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.7467 - categorical_accuracy: 0.4575 - val_loss: 3.8338 - val_categorical_accuracy: 0.2897\n",
      "Epoch 510/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7550 - categorical_accuracy: 0.4575 - val_loss: 3.8948 - val_categorical_accuracy: 0.2966\n",
      "Epoch 511/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.6962 - categorical_accuracy: 0.4610 - val_loss: 4.6712 - val_categorical_accuracy: 0.2897\n",
      "Epoch 512/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7852 - categorical_accuracy: 0.4714 - val_loss: 6.5384 - val_categorical_accuracy: 0.3034\n",
      "Epoch 513/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7547 - categorical_accuracy: 0.4697 - val_loss: 7.0775 - val_categorical_accuracy: 0.2621\n",
      "Epoch 514/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.7106 - categorical_accuracy: 0.4627 - val_loss: 4.7786 - val_categorical_accuracy: 0.2621\n",
      "Epoch 515/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8452 - categorical_accuracy: 0.4575 - val_loss: 4.7563 - val_categorical_accuracy: 0.2759\n",
      "Epoch 516/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6904 - categorical_accuracy: 0.4627 - val_loss: 4.7215 - val_categorical_accuracy: 0.2897\n",
      "Epoch 517/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.7197 - categorical_accuracy: 0.4610 - val_loss: 4.4615 - val_categorical_accuracy: 0.3034\n",
      "Epoch 518/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6589 - categorical_accuracy: 0.4749 - val_loss: 4.3162 - val_categorical_accuracy: 0.3034\n",
      "Epoch 519/1000\n",
      "19/19 [==============================] - 1s 27ms/step - loss: 1.6892 - categorical_accuracy: 0.4679 - val_loss: 4.1924 - val_categorical_accuracy: 0.2966\n",
      "Epoch 520/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6759 - categorical_accuracy: 0.4627 - val_loss: 4.6446 - val_categorical_accuracy: 0.2966\n",
      "Epoch 521/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.6819 - categorical_accuracy: 0.4697 - val_loss: 4.4795 - val_categorical_accuracy: 0.3103\n",
      "Epoch 522/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.6529 - categorical_accuracy: 0.4679 - val_loss: 8.5447 - val_categorical_accuracy: 0.2966\n",
      "Epoch 523/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6387 - categorical_accuracy: 0.4766 - val_loss: 8.9271 - val_categorical_accuracy: 0.2897\n",
      "Epoch 524/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6302 - categorical_accuracy: 0.4714 - val_loss: 9.3326 - val_categorical_accuracy: 0.3034\n",
      "Epoch 525/1000\n",
      "19/19 [==============================] - 0s 27ms/step - loss: 1.6123 - categorical_accuracy: 0.4835 - val_loss: 9.8886 - val_categorical_accuracy: 0.3034\n",
      "Epoch 526/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.6126 - categorical_accuracy: 0.4887 - val_loss: 10.1717 - val_categorical_accuracy: 0.3034\n",
      "Epoch 527/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6017 - categorical_accuracy: 0.4818 - val_loss: 10.1904 - val_categorical_accuracy: 0.3103\n",
      "Epoch 528/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.5892 - categorical_accuracy: 0.4905 - val_loss: 10.0787 - val_categorical_accuracy: 0.3034\n",
      "Epoch 529/1000\n",
      "19/19 [==============================] - 1s 38ms/step - loss: 1.5814 - categorical_accuracy: 0.4939 - val_loss: 10.4899 - val_categorical_accuracy: 0.3034\n",
      "Epoch 530/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.5791 - categorical_accuracy: 0.4939 - val_loss: 11.2550 - val_categorical_accuracy: 0.2966\n",
      "Epoch 531/1000\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 1.5736 - categorical_accuracy: 0.4957 - val_loss: 11.3874 - val_categorical_accuracy: 0.3034\n",
      "Epoch 532/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.5764 - categorical_accuracy: 0.4922 - val_loss: 11.6673 - val_categorical_accuracy: 0.3103\n",
      "Epoch 533/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.5635 - categorical_accuracy: 0.4957 - val_loss: 11.8306 - val_categorical_accuracy: 0.3034\n",
      "Epoch 534/1000\n",
      "19/19 [==============================] - 1s 37ms/step - loss: 1.5503 - categorical_accuracy: 0.5061 - val_loss: 12.1683 - val_categorical_accuracy: 0.2966\n",
      "Epoch 535/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.5672 - categorical_accuracy: 0.5043 - val_loss: 11.6654 - val_categorical_accuracy: 0.2966\n",
      "Epoch 536/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.6472 - categorical_accuracy: 0.5043 - val_loss: 11.3739 - val_categorical_accuracy: 0.3103\n",
      "Epoch 537/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.6127 - categorical_accuracy: 0.4887 - val_loss: 11.8866 - val_categorical_accuracy: 0.2966\n",
      "Epoch 538/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.5876 - categorical_accuracy: 0.4905 - val_loss: 10.2246 - val_categorical_accuracy: 0.3103\n",
      "Epoch 539/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6084 - categorical_accuracy: 0.5009 - val_loss: 11.2428 - val_categorical_accuracy: 0.3310\n",
      "Epoch 540/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.5691 - categorical_accuracy: 0.4991 - val_loss: 11.3519 - val_categorical_accuracy: 0.3034\n",
      "Epoch 541/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6014 - categorical_accuracy: 0.5043 - val_loss: 10.0179 - val_categorical_accuracy: 0.3517\n",
      "Epoch 542/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7611 - categorical_accuracy: 0.5113 - val_loss: 9.0824 - val_categorical_accuracy: 0.3172\n",
      "Epoch 543/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6632 - categorical_accuracy: 0.4991 - val_loss: 9.4383 - val_categorical_accuracy: 0.3172\n",
      "Epoch 544/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.7784 - categorical_accuracy: 0.4957 - val_loss: 8.4800 - val_categorical_accuracy: 0.2897\n",
      "Epoch 545/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7728 - categorical_accuracy: 0.4679 - val_loss: 6.8477 - val_categorical_accuracy: 0.2897\n",
      "Epoch 546/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.2402 - categorical_accuracy: 0.4402 - val_loss: 3.5728 - val_categorical_accuracy: 0.2759\n",
      "Epoch 547/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 2.1081 - categorical_accuracy: 0.4090 - val_loss: 4.6418 - val_categorical_accuracy: 0.2828\n",
      "Epoch 548/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.9842 - categorical_accuracy: 0.3830 - val_loss: 4.1804 - val_categorical_accuracy: 0.2552\n",
      "Epoch 549/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.0644 - categorical_accuracy: 0.4281 - val_loss: 6.9916 - val_categorical_accuracy: 0.2552\n",
      "Epoch 550/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.7290 - categorical_accuracy: 0.4177 - val_loss: 5.2598 - val_categorical_accuracy: 0.2138\n",
      "Epoch 551/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.0636 - categorical_accuracy: 0.3622 - val_loss: 5.0899 - val_categorical_accuracy: 0.2276\n",
      "Epoch 552/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.9589 - categorical_accuracy: 0.3969 - val_loss: 4.0981 - val_categorical_accuracy: 0.2621\n",
      "Epoch 553/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.9408 - categorical_accuracy: 0.4055 - val_loss: 5.1329 - val_categorical_accuracy: 0.2345\n",
      "Epoch 554/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.8563 - categorical_accuracy: 0.4125 - val_loss: 5.2402 - val_categorical_accuracy: 0.2621\n",
      "Epoch 555/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7878 - categorical_accuracy: 0.4333 - val_loss: 5.6842 - val_categorical_accuracy: 0.2690\n",
      "Epoch 556/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7490 - categorical_accuracy: 0.4489 - val_loss: 5.5269 - val_categorical_accuracy: 0.2690\n",
      "Epoch 557/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6978 - categorical_accuracy: 0.4575 - val_loss: 5.6433 - val_categorical_accuracy: 0.2483\n",
      "Epoch 558/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6636 - categorical_accuracy: 0.4662 - val_loss: 6.1878 - val_categorical_accuracy: 0.2552\n",
      "Epoch 559/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6335 - categorical_accuracy: 0.4818 - val_loss: 6.3594 - val_categorical_accuracy: 0.2621\n",
      "Epoch 560/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6393 - categorical_accuracy: 0.4853 - val_loss: 7.0688 - val_categorical_accuracy: 0.2552\n",
      "Epoch 561/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6456 - categorical_accuracy: 0.4853 - val_loss: 6.9697 - val_categorical_accuracy: 0.2552\n",
      "Epoch 562/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6514 - categorical_accuracy: 0.4905 - val_loss: 7.7479 - val_categorical_accuracy: 0.2483\n",
      "Epoch 563/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7533 - categorical_accuracy: 0.4783 - val_loss: 4.3953 - val_categorical_accuracy: 0.2483\n",
      "Epoch 564/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.6882 - categorical_accuracy: 0.4645 - val_loss: 4.5013 - val_categorical_accuracy: 0.2138\n",
      "Epoch 565/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6785 - categorical_accuracy: 0.4627 - val_loss: 5.7087 - val_categorical_accuracy: 0.2621\n",
      "Epoch 566/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6657 - categorical_accuracy: 0.4697 - val_loss: 5.6093 - val_categorical_accuracy: 0.2621\n",
      "Epoch 567/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.6734 - categorical_accuracy: 0.4766 - val_loss: 5.2518 - val_categorical_accuracy: 0.2621\n",
      "Epoch 568/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8516 - categorical_accuracy: 0.4714 - val_loss: 4.5248 - val_categorical_accuracy: 0.2828\n",
      "Epoch 569/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7823 - categorical_accuracy: 0.4645 - val_loss: 4.1128 - val_categorical_accuracy: 0.2552\n",
      "Epoch 570/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6960 - categorical_accuracy: 0.4679 - val_loss: 4.4008 - val_categorical_accuracy: 0.2552\n",
      "Epoch 571/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6615 - categorical_accuracy: 0.4853 - val_loss: 5.1565 - val_categorical_accuracy: 0.2759\n",
      "Epoch 572/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.5514 - categorical_accuracy: 0.4766 - val_loss: 4.6539 - val_categorical_accuracy: 0.2690\n",
      "Epoch 573/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.7036 - categorical_accuracy: 0.4575 - val_loss: 4.5128 - val_categorical_accuracy: 0.2414\n",
      "Epoch 574/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.9175 - categorical_accuracy: 0.4541 - val_loss: 3.3312 - val_categorical_accuracy: 0.2552\n",
      "Epoch 575/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7549 - categorical_accuracy: 0.4575 - val_loss: 4.2997 - val_categorical_accuracy: 0.2828\n",
      "Epoch 576/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.9655 - categorical_accuracy: 0.4437 - val_loss: 3.9536 - val_categorical_accuracy: 0.2897\n",
      "Epoch 577/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8318 - categorical_accuracy: 0.4454 - val_loss: 3.5849 - val_categorical_accuracy: 0.2897\n",
      "Epoch 578/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7668 - categorical_accuracy: 0.4454 - val_loss: 3.8606 - val_categorical_accuracy: 0.2828\n",
      "Epoch 579/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7482 - categorical_accuracy: 0.4541 - val_loss: 4.2959 - val_categorical_accuracy: 0.2966\n",
      "Epoch 580/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7196 - categorical_accuracy: 0.4593 - val_loss: 4.7197 - val_categorical_accuracy: 0.3103\n",
      "Epoch 581/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7513 - categorical_accuracy: 0.4541 - val_loss: 5.0952 - val_categorical_accuracy: 0.2690\n",
      "Epoch 582/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7505 - categorical_accuracy: 0.4402 - val_loss: 5.9676 - val_categorical_accuracy: 0.2897\n",
      "Epoch 583/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.7118 - categorical_accuracy: 0.4506 - val_loss: 6.2104 - val_categorical_accuracy: 0.2966\n",
      "Epoch 584/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6978 - categorical_accuracy: 0.4575 - val_loss: 5.8679 - val_categorical_accuracy: 0.3034\n",
      "Epoch 585/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.7021 - categorical_accuracy: 0.4575 - val_loss: 5.6045 - val_categorical_accuracy: 0.2897\n",
      "Epoch 586/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.5117 - categorical_accuracy: 0.4627 - val_loss: 4.3023 - val_categorical_accuracy: 0.3034\n",
      "Epoch 587/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7033 - categorical_accuracy: 0.4558 - val_loss: 5.4331 - val_categorical_accuracy: 0.3103\n",
      "Epoch 588/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6878 - categorical_accuracy: 0.4610 - val_loss: 5.6366 - val_categorical_accuracy: 0.3103\n",
      "Epoch 589/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6836 - categorical_accuracy: 0.4662 - val_loss: 5.6107 - val_categorical_accuracy: 0.2966\n",
      "Epoch 590/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6830 - categorical_accuracy: 0.4593 - val_loss: 4.6094 - val_categorical_accuracy: 0.2897\n",
      "Epoch 591/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7240 - categorical_accuracy: 0.4610 - val_loss: 5.9938 - val_categorical_accuracy: 0.2966\n",
      "Epoch 592/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8073 - categorical_accuracy: 0.4489 - val_loss: 4.9726 - val_categorical_accuracy: 0.2897\n",
      "Epoch 593/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.6903 - categorical_accuracy: 0.4610 - val_loss: 5.4576 - val_categorical_accuracy: 0.2897\n",
      "Epoch 594/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6844 - categorical_accuracy: 0.4645 - val_loss: 5.1339 - val_categorical_accuracy: 0.2897\n",
      "Epoch 595/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7055 - categorical_accuracy: 0.4541 - val_loss: 5.9344 - val_categorical_accuracy: 0.3103\n",
      "Epoch 596/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.7426 - categorical_accuracy: 0.4558 - val_loss: 5.5420 - val_categorical_accuracy: 0.2897\n",
      "Epoch 597/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7620 - categorical_accuracy: 0.4315 - val_loss: 6.6900 - val_categorical_accuracy: 0.2828\n",
      "Epoch 598/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.7939 - categorical_accuracy: 0.4489 - val_loss: 7.3418 - val_categorical_accuracy: 0.2690\n",
      "Epoch 599/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7497 - categorical_accuracy: 0.4437 - val_loss: 7.1132 - val_categorical_accuracy: 0.2759\n",
      "Epoch 600/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8210 - categorical_accuracy: 0.4315 - val_loss: 5.2424 - val_categorical_accuracy: 0.2552\n",
      "Epoch 601/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.7501 - categorical_accuracy: 0.4419 - val_loss: 6.2496 - val_categorical_accuracy: 0.2966\n",
      "Epoch 602/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7504 - categorical_accuracy: 0.4437 - val_loss: 5.4986 - val_categorical_accuracy: 0.2828\n",
      "Epoch 603/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.7525 - categorical_accuracy: 0.4419 - val_loss: 5.7879 - val_categorical_accuracy: 0.2897\n",
      "Epoch 604/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.6915 - categorical_accuracy: 0.4523 - val_loss: 6.0386 - val_categorical_accuracy: 0.2966\n",
      "Epoch 605/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.6747 - categorical_accuracy: 0.4575 - val_loss: 6.2006 - val_categorical_accuracy: 0.2966\n",
      "Epoch 606/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.6760 - categorical_accuracy: 0.4593 - val_loss: 6.3085 - val_categorical_accuracy: 0.2828\n",
      "Epoch 607/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7979 - categorical_accuracy: 0.4645 - val_loss: 6.4082 - val_categorical_accuracy: 0.3241\n",
      "Epoch 608/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8548 - categorical_accuracy: 0.4593 - val_loss: 6.0034 - val_categorical_accuracy: 0.2828\n",
      "Epoch 609/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8027 - categorical_accuracy: 0.4298 - val_loss: 6.0212 - val_categorical_accuracy: 0.2828\n",
      "Epoch 610/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.7700 - categorical_accuracy: 0.4506 - val_loss: 6.1129 - val_categorical_accuracy: 0.2690\n",
      "Epoch 611/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8182 - categorical_accuracy: 0.4662 - val_loss: 6.0439 - val_categorical_accuracy: 0.2345\n",
      "Epoch 612/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.2023 - categorical_accuracy: 0.4263 - val_loss: 5.7518 - val_categorical_accuracy: 0.2621\n",
      "Epoch 613/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.8222 - categorical_accuracy: 0.4229 - val_loss: 5.6623 - val_categorical_accuracy: 0.2138\n",
      "Epoch 614/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.9959 - categorical_accuracy: 0.4142 - val_loss: 5.2730 - val_categorical_accuracy: 0.2276\n",
      "Epoch 615/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.8055 - categorical_accuracy: 0.4211 - val_loss: 5.4117 - val_categorical_accuracy: 0.2414\n",
      "Epoch 616/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7916 - categorical_accuracy: 0.4211 - val_loss: 5.8768 - val_categorical_accuracy: 0.2276\n",
      "Epoch 617/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8472 - categorical_accuracy: 0.4177 - val_loss: 5.8996 - val_categorical_accuracy: 0.2414\n",
      "Epoch 618/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.8782 - categorical_accuracy: 0.4367 - val_loss: 4.7361 - val_categorical_accuracy: 0.2414\n",
      "Epoch 619/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8949 - categorical_accuracy: 0.4142 - val_loss: 5.2727 - val_categorical_accuracy: 0.2759\n",
      "Epoch 620/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.9120 - categorical_accuracy: 0.3847 - val_loss: 5.4510 - val_categorical_accuracy: 0.2552\n",
      "Epoch 621/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.9872 - categorical_accuracy: 0.3917 - val_loss: 5.0346 - val_categorical_accuracy: 0.2621\n",
      "Epoch 622/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.9677 - categorical_accuracy: 0.4107 - val_loss: 4.6039 - val_categorical_accuracy: 0.2414\n",
      "Epoch 623/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1.9426 - categorical_accuracy: 0.4003 - val_loss: 4.3701 - val_categorical_accuracy: 0.2483\n",
      "Epoch 624/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8633 - categorical_accuracy: 0.4090 - val_loss: 4.9210 - val_categorical_accuracy: 0.2483\n",
      "Epoch 625/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.9676 - categorical_accuracy: 0.4281 - val_loss: 5.0014 - val_categorical_accuracy: 0.2552\n",
      "Epoch 626/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.9131 - categorical_accuracy: 0.4177 - val_loss: 4.5143 - val_categorical_accuracy: 0.2690\n",
      "Epoch 627/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8687 - categorical_accuracy: 0.4229 - val_loss: 4.7524 - val_categorical_accuracy: 0.2828\n",
      "Epoch 628/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.0059 - categorical_accuracy: 0.4419 - val_loss: 4.8331 - val_categorical_accuracy: 0.2207\n",
      "Epoch 629/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7822 - categorical_accuracy: 0.4419 - val_loss: 4.5029 - val_categorical_accuracy: 0.2345\n",
      "Epoch 630/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.4831 - categorical_accuracy: 0.4593 - val_loss: 3.8596 - val_categorical_accuracy: 0.2828\n",
      "Epoch 631/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.8718 - categorical_accuracy: 0.4003 - val_loss: 3.8631 - val_categorical_accuracy: 0.2897\n",
      "Epoch 632/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.9298 - categorical_accuracy: 0.3917 - val_loss: 3.7109 - val_categorical_accuracy: 0.2828\n",
      "Epoch 633/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8698 - categorical_accuracy: 0.4298 - val_loss: 3.9543 - val_categorical_accuracy: 0.2690\n",
      "Epoch 634/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.9194 - categorical_accuracy: 0.3986 - val_loss: 4.0802 - val_categorical_accuracy: 0.2552\n",
      "Epoch 635/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8621 - categorical_accuracy: 0.4211 - val_loss: 4.2537 - val_categorical_accuracy: 0.2276\n",
      "Epoch 636/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8004 - categorical_accuracy: 0.4298 - val_loss: 3.9895 - val_categorical_accuracy: 0.2414\n",
      "Epoch 637/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7648 - categorical_accuracy: 0.4419 - val_loss: 3.9659 - val_categorical_accuracy: 0.2621\n",
      "Epoch 638/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7931 - categorical_accuracy: 0.4558 - val_loss: 3.8442 - val_categorical_accuracy: 0.2966\n",
      "Epoch 639/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.7455 - categorical_accuracy: 0.4523 - val_loss: 4.0937 - val_categorical_accuracy: 0.3103\n",
      "Epoch 640/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7947 - categorical_accuracy: 0.4627 - val_loss: 3.5484 - val_categorical_accuracy: 0.2759\n",
      "Epoch 641/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8858 - categorical_accuracy: 0.4367 - val_loss: 3.8465 - val_categorical_accuracy: 0.2759\n",
      "Epoch 642/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8576 - categorical_accuracy: 0.4159 - val_loss: 3.6964 - val_categorical_accuracy: 0.2552\n",
      "Epoch 643/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2.5792 - categorical_accuracy: 0.4021 - val_loss: 3.6345 - val_categorical_accuracy: 0.2483\n",
      "Epoch 644/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8963 - categorical_accuracy: 0.4055 - val_loss: 4.1612 - val_categorical_accuracy: 0.2345\n",
      "Epoch 645/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8666 - categorical_accuracy: 0.4038 - val_loss: 4.1786 - val_categorical_accuracy: 0.2276\n",
      "Epoch 646/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.2117 - categorical_accuracy: 0.3536 - val_loss: 3.7396 - val_categorical_accuracy: 0.2207\n",
      "Epoch 647/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2.0928 - categorical_accuracy: 0.3345 - val_loss: 3.8611 - val_categorical_accuracy: 0.1793\n",
      "Epoch 648/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.0043 - categorical_accuracy: 0.3692 - val_loss: 3.8430 - val_categorical_accuracy: 0.2069\n",
      "Epoch 649/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.9199 - categorical_accuracy: 0.3709 - val_loss: 3.6848 - val_categorical_accuracy: 0.2000\n",
      "Epoch 650/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8721 - categorical_accuracy: 0.3847 - val_loss: 3.9320 - val_categorical_accuracy: 0.2000\n",
      "Epoch 651/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8326 - categorical_accuracy: 0.4090 - val_loss: 4.1880 - val_categorical_accuracy: 0.2069\n",
      "Epoch 652/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8320 - categorical_accuracy: 0.4125 - val_loss: 4.1515 - val_categorical_accuracy: 0.2069\n",
      "Epoch 653/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.8311 - categorical_accuracy: 0.4159 - val_loss: 4.4388 - val_categorical_accuracy: 0.2069\n",
      "Epoch 654/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8248 - categorical_accuracy: 0.4107 - val_loss: 4.7547 - val_categorical_accuracy: 0.2276\n",
      "Epoch 655/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.2047 - categorical_accuracy: 0.3882 - val_loss: 4.3563 - val_categorical_accuracy: 0.1931\n",
      "Epoch 656/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.9661 - categorical_accuracy: 0.3830 - val_loss: 4.7217 - val_categorical_accuracy: 0.2000\n",
      "Epoch 657/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1.9048 - categorical_accuracy: 0.3917 - val_loss: 4.8740 - val_categorical_accuracy: 0.1793\n",
      "Epoch 658/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8444 - categorical_accuracy: 0.3951 - val_loss: 4.3860 - val_categorical_accuracy: 0.1931\n",
      "Epoch 659/1000\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 1.7667 - categorical_accuracy: 0.4211 - val_loss: 5.4660 - val_categorical_accuracy: 0.2207\n",
      "Epoch 660/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7965 - categorical_accuracy: 0.4350 - val_loss: 5.0444 - val_categorical_accuracy: 0.2000\n",
      "Epoch 661/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7361 - categorical_accuracy: 0.4367 - val_loss: 4.9893 - val_categorical_accuracy: 0.2276\n",
      "Epoch 662/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7086 - categorical_accuracy: 0.4298 - val_loss: 5.1938 - val_categorical_accuracy: 0.2207\n",
      "Epoch 663/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7319 - categorical_accuracy: 0.4385 - val_loss: 5.2112 - val_categorical_accuracy: 0.2207\n",
      "Epoch 664/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8849 - categorical_accuracy: 0.4263 - val_loss: 5.1023 - val_categorical_accuracy: 0.2207\n",
      "Epoch 665/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7888 - categorical_accuracy: 0.4298 - val_loss: 5.0397 - val_categorical_accuracy: 0.2207\n",
      "Epoch 666/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7684 - categorical_accuracy: 0.4350 - val_loss: 5.3434 - val_categorical_accuracy: 0.2207\n",
      "Epoch 667/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8196 - categorical_accuracy: 0.4107 - val_loss: 5.3831 - val_categorical_accuracy: 0.2276\n",
      "Epoch 668/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.7395 - categorical_accuracy: 0.4350 - val_loss: 5.2779 - val_categorical_accuracy: 0.2483\n",
      "Epoch 669/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8397 - categorical_accuracy: 0.4298 - val_loss: 5.7741 - val_categorical_accuracy: 0.2621\n",
      "Epoch 670/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8380 - categorical_accuracy: 0.4090 - val_loss: 5.9212 - val_categorical_accuracy: 0.2621\n",
      "Epoch 671/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8126 - categorical_accuracy: 0.4055 - val_loss: 5.9457 - val_categorical_accuracy: 0.2345\n",
      "Epoch 672/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8469 - categorical_accuracy: 0.4246 - val_loss: 5.7720 - val_categorical_accuracy: 0.2276\n",
      "Epoch 673/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8569 - categorical_accuracy: 0.4194 - val_loss: 4.2284 - val_categorical_accuracy: 0.2276\n",
      "Epoch 674/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8253 - categorical_accuracy: 0.4454 - val_loss: 4.4151 - val_categorical_accuracy: 0.2345\n",
      "Epoch 675/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8005 - categorical_accuracy: 0.4367 - val_loss: 5.2478 - val_categorical_accuracy: 0.2069\n",
      "Epoch 676/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.7829 - categorical_accuracy: 0.4211 - val_loss: 6.0989 - val_categorical_accuracy: 0.2276\n",
      "Epoch 677/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.8892 - categorical_accuracy: 0.4246 - val_loss: 6.0789 - val_categorical_accuracy: 0.2000\n",
      "Epoch 678/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8780 - categorical_accuracy: 0.3951 - val_loss: 5.2724 - val_categorical_accuracy: 0.1862\n",
      "Epoch 679/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.8316 - categorical_accuracy: 0.4194 - val_loss: 5.8139 - val_categorical_accuracy: 0.2138\n",
      "Epoch 680/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2.0201 - categorical_accuracy: 0.4003 - val_loss: 5.6768 - val_categorical_accuracy: 0.1862\n",
      "Epoch 681/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2.0743 - categorical_accuracy: 0.3847 - val_loss: 5.2634 - val_categorical_accuracy: 0.2138\n",
      "Epoch 682/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1.8625 - categorical_accuracy: 0.4177 - val_loss: 5.2151 - val_categorical_accuracy: 0.2138\n",
      "Epoch 683/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.8448 - categorical_accuracy: 0.4090 - val_loss: 4.3705 - val_categorical_accuracy: 0.2345\n",
      "Epoch 684/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1.8082 - categorical_accuracy: 0.4229 - val_loss: 5.1270 - val_categorical_accuracy: 0.2207\n",
      "Epoch 685/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1.7477 - categorical_accuracy: 0.4385 - val_loss: 6.2808 - val_categorical_accuracy: 0.2345\n",
      "Epoch 686/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 4.0909 - categorical_accuracy: 0.4333 - val_loss: 6.8003 - val_categorical_accuracy: 0.2345\n",
      "Epoch 687/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1.7499 - categorical_accuracy: 0.4402 - val_loss: 7.3505 - val_categorical_accuracy: 0.2414\n",
      "Epoch 688/1000\n",
      " 7/19 [==========>...................] - ETA: 0s - loss: 1.8939 - categorical_accuracy: 0.3929"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=1000, batch_size=32, validation_data=(x_test, y_test), callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 1, 64)             1537280   \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 1, 128)            98816     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 62)                4030      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2016      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 18)                594       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1692144 (6.46 MB)\n",
      "Trainable params: 1692144 (6.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv1d_2. Consider increasing the input size. Received input shape [None, 1, 5940] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m=\u001b[39mSequential()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# model.add(MaxPooling1D())\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[0;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    349\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters]\n\u001b[0;32m    350\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :])\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv1d_2. Consider increasing the input size. Received input shape [None, 1, 5940] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv1D(16, kernel_size=3, activation='relu',input_shape=(X.shape[1], X.shape[2])))\n",
    "# model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(words)-1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"max_pooling1d\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d/ExpandDims)' with input shapes: [?,1,1,16].\n\nCall arguments received by layer \"max_pooling1d\" (type MaxPooling1D):\n   inputs=tf.Tensor(shape=(None, 1, 16), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(\u001b[38;5;241m16\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMaxPooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling1D())\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6626\u001b[0m, in \u001b[0;36mpool2d\u001b[1;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[0;32m   6623\u001b[0m     pool_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m pool_size\n\u001b[0;32m   6625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pool_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6626\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_data_format\u001b[49m\n\u001b[0;32m   6628\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6629\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pool_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   6630\u001b[0m     x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mavg_pool(\n\u001b[0;32m   6631\u001b[0m         x, pool_size, strides, padding\u001b[38;5;241m=\u001b[39mpadding, data_format\u001b[38;5;241m=\u001b[39mtf_data_format\n\u001b[0;32m   6632\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling1d\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d/ExpandDims)' with input shapes: [?,1,1,16].\n\nCall arguments received by layer \"max_pooling1d\" (type MaxPooling1D):\n   inputs=tf.Tensor(shape=(None, 1, 16), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(16, kernel_size=3, activation='relu', padding='same', input_shape=(X.shape[1], X.shape[2])))\n",
    "# model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "# model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(words) - 1, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test), callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(X.shape[1], X.shape[2], 1)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(words), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=model.predict(x_test)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model=tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[np.argmax(model.predict(x_test)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=np.argmax(y_test, axis=1).tolist()\n",
    "y_pred=np.argmax(y_pred, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
