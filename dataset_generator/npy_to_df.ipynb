{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frame</th>\n",
       "      <th>X00</th>\n",
       "      <th>Y00</th>\n",
       "      <th>Z00</th>\n",
       "      <th>X01</th>\n",
       "      <th>Y01</th>\n",
       "      <th>Z01</th>\n",
       "      <th>X02</th>\n",
       "      <th>Y02</th>\n",
       "      <th>...</th>\n",
       "      <th>Z23</th>\n",
       "      <th>X24</th>\n",
       "      <th>Y24</th>\n",
       "      <th>Z24</th>\n",
       "      <th>X25</th>\n",
       "      <th>Y25</th>\n",
       "      <th>Z25</th>\n",
       "      <th>X26</th>\n",
       "      <th>Y26</th>\n",
       "      <th>Z26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boy</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>0.223574</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>0.223574</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530313</td>\n",
       "      <td>0.585678</td>\n",
       "      <td>-0.365724</td>\n",
       "      <td>0.393299</td>\n",
       "      <td>0.607514</td>\n",
       "      <td>0.130718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boy</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.441575</td>\n",
       "      <td>-10.572632</td>\n",
       "      <td>0.370819</td>\n",
       "      <td>-0.500577</td>\n",
       "      <td>-12.161836</td>\n",
       "      <td>0.379360</td>\n",
       "      <td>-0.622653</td>\n",
       "      <td>-11.623393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531883</td>\n",
       "      <td>0.588693</td>\n",
       "      <td>-0.381889</td>\n",
       "      <td>0.385701</td>\n",
       "      <td>0.626965</td>\n",
       "      <td>0.241074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boy</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.754394</td>\n",
       "      <td>-7.421648</td>\n",
       "      <td>0.392176</td>\n",
       "      <td>-0.842538</td>\n",
       "      <td>-8.545950</td>\n",
       "      <td>0.401212</td>\n",
       "      <td>-0.967975</td>\n",
       "      <td>-8.040165</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534591</td>\n",
       "      <td>0.574829</td>\n",
       "      <td>-0.470731</td>\n",
       "      <td>0.376408</td>\n",
       "      <td>0.645435</td>\n",
       "      <td>0.216554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boy</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.678109</td>\n",
       "      <td>-8.186996</td>\n",
       "      <td>0.441856</td>\n",
       "      <td>-0.814776</td>\n",
       "      <td>-9.373079</td>\n",
       "      <td>0.455979</td>\n",
       "      <td>-0.910327</td>\n",
       "      <td>-8.907041</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484453</td>\n",
       "      <td>0.453059</td>\n",
       "      <td>-0.516997</td>\n",
       "      <td>0.365139</td>\n",
       "      <td>0.629331</td>\n",
       "      <td>0.273374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.797789</td>\n",
       "      <td>-10.197847</td>\n",
       "      <td>0.429872</td>\n",
       "      <td>-0.955783</td>\n",
       "      <td>-11.699729</td>\n",
       "      <td>0.451075</td>\n",
       "      <td>-1.066465</td>\n",
       "      <td>-11.020497</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474471</td>\n",
       "      <td>0.342270</td>\n",
       "      <td>-0.453968</td>\n",
       "      <td>0.384628</td>\n",
       "      <td>0.589920</td>\n",
       "      <td>0.266067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112924</th>\n",
       "      <td>You</td>\n",
       "      <td>16</td>\n",
       "      <td>0.587871</td>\n",
       "      <td>9.669083</td>\n",
       "      <td>1.162361</td>\n",
       "      <td>0.726044</td>\n",
       "      <td>11.412089</td>\n",
       "      <td>1.129761</td>\n",
       "      <td>0.655170</td>\n",
       "      <td>10.942098</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574938</td>\n",
       "      <td>0.538055</td>\n",
       "      <td>0.070751</td>\n",
       "      <td>0.395394</td>\n",
       "      <td>0.452951</td>\n",
       "      <td>-0.300268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112925</th>\n",
       "      <td>You</td>\n",
       "      <td>17</td>\n",
       "      <td>0.337344</td>\n",
       "      <td>21.491173</td>\n",
       "      <td>1.587999</td>\n",
       "      <td>0.362523</td>\n",
       "      <td>25.172693</td>\n",
       "      <td>1.563665</td>\n",
       "      <td>0.306954</td>\n",
       "      <td>24.418745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578150</td>\n",
       "      <td>0.539364</td>\n",
       "      <td>0.051295</td>\n",
       "      <td>0.398031</td>\n",
       "      <td>0.515749</td>\n",
       "      <td>-0.181356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112926</th>\n",
       "      <td>You</td>\n",
       "      <td>18</td>\n",
       "      <td>0.215001</td>\n",
       "      <td>30.405003</td>\n",
       "      <td>1.653764</td>\n",
       "      <td>0.260286</td>\n",
       "      <td>35.272096</td>\n",
       "      <td>1.652273</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>34.866246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580092</td>\n",
       "      <td>0.541042</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.398705</td>\n",
       "      <td>0.534306</td>\n",
       "      <td>-0.237497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112927</th>\n",
       "      <td>You</td>\n",
       "      <td>19</td>\n",
       "      <td>0.182174</td>\n",
       "      <td>30.964133</td>\n",
       "      <td>1.847807</td>\n",
       "      <td>0.224303</td>\n",
       "      <td>36.075314</td>\n",
       "      <td>1.835613</td>\n",
       "      <td>0.095749</td>\n",
       "      <td>35.360101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580864</td>\n",
       "      <td>0.542060</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.398723</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>-0.243124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112928</th>\n",
       "      <td>You</td>\n",
       "      <td>20</td>\n",
       "      <td>0.140643</td>\n",
       "      <td>43.708800</td>\n",
       "      <td>2.127749</td>\n",
       "      <td>0.198996</td>\n",
       "      <td>50.094664</td>\n",
       "      <td>2.107137</td>\n",
       "      <td>0.070886</td>\n",
       "      <td>49.969990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585219</td>\n",
       "      <td>0.542360</td>\n",
       "      <td>-0.016540</td>\n",
       "      <td>0.397739</td>\n",
       "      <td>0.534382</td>\n",
       "      <td>-0.228005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112929 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Frame       X00        Y00       Z00       X01        Y01  \\\n",
       "0       Boy      1 -3.320268  12.714561  0.223574 -3.320268  12.714561   \n",
       "1       Boy      2 -0.441575 -10.572632  0.370819 -0.500577 -12.161836   \n",
       "2       Boy      3 -0.754394  -7.421648  0.392176 -0.842538  -8.545950   \n",
       "3       Boy      4 -0.678109  -8.186996  0.441856 -0.814776  -9.373079   \n",
       "4       Boy      5 -0.797789 -10.197847  0.429872 -0.955783 -11.699729   \n",
       "...     ...    ...       ...        ...       ...       ...        ...   \n",
       "112924  You     16  0.587871   9.669083  1.162361  0.726044  11.412089   \n",
       "112925  You     17  0.337344  21.491173  1.587999  0.362523  25.172693   \n",
       "112926  You     18  0.215001  30.405003  1.653764  0.260286  35.272096   \n",
       "112927  You     19  0.182174  30.964133  1.847807  0.224303  36.075314   \n",
       "112928  You     20  0.140643  43.708800  2.127749  0.198996  50.094664   \n",
       "\n",
       "             Z01       X02        Y02  ...  Z23  X24  Y24  Z24       X25  \\\n",
       "0       0.223574 -3.320268  12.714561  ...  1.0  0.0  0.0  0.0  0.530313   \n",
       "1       0.379360 -0.622653 -11.623393  ...  1.0  0.0  0.0  0.0  0.531883   \n",
       "2       0.401212 -0.967975  -8.040165  ...  1.0  0.0  0.0  0.0  0.534591   \n",
       "3       0.455979 -0.910327  -8.907041  ...  1.0  0.0  0.0  0.0  0.484453   \n",
       "4       0.451075 -1.066465 -11.020497  ...  1.0  0.0  0.0  0.0  0.474471   \n",
       "...          ...       ...        ...  ...  ...  ...  ...  ...       ...   \n",
       "112924  1.129761  0.655170  10.942098  ...  1.0  0.0  0.0  0.0  0.574938   \n",
       "112925  1.563665  0.306954  24.418745  ...  1.0  0.0  0.0  0.0  0.578150   \n",
       "112926  1.652273  0.141393  34.866246  ...  1.0  0.0  0.0  0.0  0.580092   \n",
       "112927  1.835613  0.095749  35.360101  ...  1.0  0.0  0.0  0.0  0.580864   \n",
       "112928  2.107137  0.070886  49.969990  ...  1.0  0.0  0.0  0.0  0.585219   \n",
       "\n",
       "             Y25       Z25       X26       Y26       Z26  \n",
       "0       0.585678 -0.365724  0.393299  0.607514  0.130718  \n",
       "1       0.588693 -0.381889  0.385701  0.626965  0.241074  \n",
       "2       0.574829 -0.470731  0.376408  0.645435  0.216554  \n",
       "3       0.453059 -0.516997  0.365139  0.629331  0.273374  \n",
       "4       0.342270 -0.453968  0.384628  0.589920  0.266067  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "112924  0.538055  0.070751  0.395394  0.452951 -0.300268  \n",
       "112925  0.539364  0.051295  0.398031  0.515749 -0.181356  \n",
       "112926  0.541042  0.027703  0.398705  0.534306 -0.237497  \n",
       "112927  0.542060  0.006164  0.398723  0.538843 -0.243124  \n",
       "112928  0.542360 -0.016540  0.397739  0.534382 -0.228005  \n",
       "\n",
       "[112929 rows x 83 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load each .npy file and convert the list of dictionaries to a DataFrame\n",
    "dataframes = []\n",
    "for file in os.listdir('dataset_backup'):\n",
    "    if file.endswith('.npy'):\n",
    "        data = np.load('dataset_backup/' + file, allow_pickle=True)\n",
    "        dataframes.append(pd.DataFrame.from_records(data))\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length = merged_df['Frame'].max()\n",
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frame</th>\n",
       "      <th>X00</th>\n",
       "      <th>Y00</th>\n",
       "      <th>Z00</th>\n",
       "      <th>X01</th>\n",
       "      <th>Y01</th>\n",
       "      <th>Z01</th>\n",
       "      <th>X02</th>\n",
       "      <th>Y02</th>\n",
       "      <th>...</th>\n",
       "      <th>Z23</th>\n",
       "      <th>X24</th>\n",
       "      <th>Y24</th>\n",
       "      <th>Z24</th>\n",
       "      <th>X25</th>\n",
       "      <th>Y25</th>\n",
       "      <th>Z25</th>\n",
       "      <th>X26</th>\n",
       "      <th>Y26</th>\n",
       "      <th>Z26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boy</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>0.223574</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>0.223574</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530313</td>\n",
       "      <td>0.585678</td>\n",
       "      <td>-0.365724</td>\n",
       "      <td>0.393299</td>\n",
       "      <td>0.607514</td>\n",
       "      <td>0.130718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boy</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.441575</td>\n",
       "      <td>-10.572632</td>\n",
       "      <td>0.370819</td>\n",
       "      <td>-0.500577</td>\n",
       "      <td>-12.161836</td>\n",
       "      <td>0.379360</td>\n",
       "      <td>-0.622653</td>\n",
       "      <td>-11.623393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531883</td>\n",
       "      <td>0.588693</td>\n",
       "      <td>-0.381889</td>\n",
       "      <td>0.385701</td>\n",
       "      <td>0.626965</td>\n",
       "      <td>0.241074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boy</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.754394</td>\n",
       "      <td>-7.421648</td>\n",
       "      <td>0.392176</td>\n",
       "      <td>-0.842538</td>\n",
       "      <td>-8.545950</td>\n",
       "      <td>0.401212</td>\n",
       "      <td>-0.967975</td>\n",
       "      <td>-8.040165</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534591</td>\n",
       "      <td>0.574829</td>\n",
       "      <td>-0.470731</td>\n",
       "      <td>0.376408</td>\n",
       "      <td>0.645435</td>\n",
       "      <td>0.216554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boy</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.678109</td>\n",
       "      <td>-8.186996</td>\n",
       "      <td>0.441856</td>\n",
       "      <td>-0.814776</td>\n",
       "      <td>-9.373079</td>\n",
       "      <td>0.455979</td>\n",
       "      <td>-0.910327</td>\n",
       "      <td>-8.907041</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484453</td>\n",
       "      <td>0.453059</td>\n",
       "      <td>-0.516997</td>\n",
       "      <td>0.365139</td>\n",
       "      <td>0.629331</td>\n",
       "      <td>0.273374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.797789</td>\n",
       "      <td>-10.197847</td>\n",
       "      <td>0.429872</td>\n",
       "      <td>-0.955783</td>\n",
       "      <td>-11.699729</td>\n",
       "      <td>0.451075</td>\n",
       "      <td>-1.066465</td>\n",
       "      <td>-11.020497</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474471</td>\n",
       "      <td>0.342270</td>\n",
       "      <td>-0.453968</td>\n",
       "      <td>0.384628</td>\n",
       "      <td>0.589920</td>\n",
       "      <td>0.266067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112923</th>\n",
       "      <td>You</td>\n",
       "      <td>15</td>\n",
       "      <td>0.822056</td>\n",
       "      <td>5.677708</td>\n",
       "      <td>0.710343</td>\n",
       "      <td>1.048670</td>\n",
       "      <td>7.904536</td>\n",
       "      <td>0.604539</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>5.860801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570543</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.108942</td>\n",
       "      <td>0.402942</td>\n",
       "      <td>0.371251</td>\n",
       "      <td>-0.373206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112924</th>\n",
       "      <td>You</td>\n",
       "      <td>16</td>\n",
       "      <td>0.587871</td>\n",
       "      <td>9.669083</td>\n",
       "      <td>1.162361</td>\n",
       "      <td>0.726044</td>\n",
       "      <td>11.412089</td>\n",
       "      <td>1.129761</td>\n",
       "      <td>0.655170</td>\n",
       "      <td>10.942098</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574938</td>\n",
       "      <td>0.538055</td>\n",
       "      <td>0.070751</td>\n",
       "      <td>0.395394</td>\n",
       "      <td>0.452951</td>\n",
       "      <td>-0.300268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112925</th>\n",
       "      <td>You</td>\n",
       "      <td>17</td>\n",
       "      <td>0.337344</td>\n",
       "      <td>21.491173</td>\n",
       "      <td>1.587999</td>\n",
       "      <td>0.362523</td>\n",
       "      <td>25.172693</td>\n",
       "      <td>1.563665</td>\n",
       "      <td>0.306954</td>\n",
       "      <td>24.418745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578150</td>\n",
       "      <td>0.539364</td>\n",
       "      <td>0.051295</td>\n",
       "      <td>0.398031</td>\n",
       "      <td>0.515749</td>\n",
       "      <td>-0.181356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112926</th>\n",
       "      <td>You</td>\n",
       "      <td>18</td>\n",
       "      <td>0.215001</td>\n",
       "      <td>30.405003</td>\n",
       "      <td>1.653764</td>\n",
       "      <td>0.260286</td>\n",
       "      <td>35.272096</td>\n",
       "      <td>1.652273</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>34.866246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580092</td>\n",
       "      <td>0.541042</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.398705</td>\n",
       "      <td>0.534306</td>\n",
       "      <td>-0.237497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112927</th>\n",
       "      <td>You</td>\n",
       "      <td>19</td>\n",
       "      <td>0.182174</td>\n",
       "      <td>30.964133</td>\n",
       "      <td>1.847807</td>\n",
       "      <td>0.224303</td>\n",
       "      <td>36.075314</td>\n",
       "      <td>1.835613</td>\n",
       "      <td>0.095749</td>\n",
       "      <td>35.360101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580864</td>\n",
       "      <td>0.542060</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.398723</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>-0.243124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109440 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Frame       X00        Y00       Z00       X01        Y01  \\\n",
       "0       Boy      1 -3.320268  12.714561  0.223574 -3.320268  12.714561   \n",
       "1       Boy      2 -0.441575 -10.572632  0.370819 -0.500577 -12.161836   \n",
       "2       Boy      3 -0.754394  -7.421648  0.392176 -0.842538  -8.545950   \n",
       "3       Boy      4 -0.678109  -8.186996  0.441856 -0.814776  -9.373079   \n",
       "4       Boy      5 -0.797789 -10.197847  0.429872 -0.955783 -11.699729   \n",
       "...     ...    ...       ...        ...       ...       ...        ...   \n",
       "112923  You     15  0.822056   5.677708  0.710343  1.048670   7.904536   \n",
       "112924  You     16  0.587871   9.669083  1.162361  0.726044  11.412089   \n",
       "112925  You     17  0.337344  21.491173  1.587999  0.362523  25.172693   \n",
       "112926  You     18  0.215001  30.405003  1.653764  0.260286  35.272096   \n",
       "112927  You     19  0.182174  30.964133  1.847807  0.224303  36.075314   \n",
       "\n",
       "             Z01       X02        Y02  ...  Z23  X24  Y24  Z24       X25  \\\n",
       "0       0.223574 -3.320268  12.714561  ...  1.0  0.0  0.0  0.0  0.530313   \n",
       "1       0.379360 -0.622653 -11.623393  ...  1.0  0.0  0.0  0.0  0.531883   \n",
       "2       0.401212 -0.967975  -8.040165  ...  1.0  0.0  0.0  0.0  0.534591   \n",
       "3       0.455979 -0.910327  -8.907041  ...  1.0  0.0  0.0  0.0  0.484453   \n",
       "4       0.451075 -1.066465 -11.020497  ...  1.0  0.0  0.0  0.0  0.474471   \n",
       "...          ...       ...        ...  ...  ...  ...  ...  ...       ...   \n",
       "112923  0.604539  0.998043   5.860801  ...  1.0  0.0  0.0  0.0  0.570543   \n",
       "112924  1.129761  0.655170  10.942098  ...  1.0  0.0  0.0  0.0  0.574938   \n",
       "112925  1.563665  0.306954  24.418745  ...  1.0  0.0  0.0  0.0  0.578150   \n",
       "112926  1.652273  0.141393  34.866246  ...  1.0  0.0  0.0  0.0  0.580092   \n",
       "112927  1.835613  0.095749  35.360101  ...  1.0  0.0  0.0  0.0  0.580864   \n",
       "\n",
       "             Y25       Z25       X26       Y26       Z26  \n",
       "0       0.585678 -0.365724  0.393299  0.607514  0.130718  \n",
       "1       0.588693 -0.381889  0.385701  0.626965  0.241074  \n",
       "2       0.574829 -0.470731  0.376408  0.645435  0.216554  \n",
       "3       0.453059 -0.516997  0.365139  0.629331  0.273374  \n",
       "4       0.342270 -0.453968  0.384628  0.589920  0.266067  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "112923  0.518519  0.108942  0.402942  0.371251 -0.373206  \n",
       "112924  0.538055  0.070751  0.395394  0.452951 -0.300268  \n",
       "112925  0.539364  0.051295  0.398031  0.515749 -0.181356  \n",
       "112926  0.541042  0.027703  0.398705  0.534306 -0.237497  \n",
       "112927  0.542060  0.006164  0.398723  0.538843 -0.243124  \n",
       "\n",
       "[109440 rows x 83 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = merged_df[merged_df['Frame'] != 20]\n",
    "# merged_df = merged_df[merged_df['Word'] != 'Boy']\n",
    "# merged_df = merged_df[merged_df['Word'] != 'Fine']\n",
    "# merged_df = merged_df[merged_df['Word'] != 'Parents']\n",
    "# merged_df = merged_df[merged_df['Word'] != 'Sister']\n",
    "# merged_df = merged_df[merged_df['Word'] != 'Can']\n",
    "merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_df = merged_df[merged_df['Frame'] != 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frame</th>\n",
       "      <th>X00</th>\n",
       "      <th>Y00</th>\n",
       "      <th>Z00</th>\n",
       "      <th>X01</th>\n",
       "      <th>Y01</th>\n",
       "      <th>Z01</th>\n",
       "      <th>X02</th>\n",
       "      <th>Y02</th>\n",
       "      <th>...</th>\n",
       "      <th>Z23</th>\n",
       "      <th>X24</th>\n",
       "      <th>Y24</th>\n",
       "      <th>Z24</th>\n",
       "      <th>X25</th>\n",
       "      <th>Y25</th>\n",
       "      <th>Z25</th>\n",
       "      <th>X26</th>\n",
       "      <th>Y26</th>\n",
       "      <th>Z26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boy</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>0.223574</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>0.223574</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530313</td>\n",
       "      <td>0.585678</td>\n",
       "      <td>-0.365724</td>\n",
       "      <td>0.393299</td>\n",
       "      <td>0.607514</td>\n",
       "      <td>0.130718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boy</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.441575</td>\n",
       "      <td>-10.572632</td>\n",
       "      <td>0.370819</td>\n",
       "      <td>-0.500577</td>\n",
       "      <td>-12.161836</td>\n",
       "      <td>0.379360</td>\n",
       "      <td>-0.622653</td>\n",
       "      <td>-11.623393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531883</td>\n",
       "      <td>0.588693</td>\n",
       "      <td>-0.381889</td>\n",
       "      <td>0.385701</td>\n",
       "      <td>0.626965</td>\n",
       "      <td>0.241074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boy</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.754394</td>\n",
       "      <td>-7.421648</td>\n",
       "      <td>0.392176</td>\n",
       "      <td>-0.842538</td>\n",
       "      <td>-8.545950</td>\n",
       "      <td>0.401212</td>\n",
       "      <td>-0.967975</td>\n",
       "      <td>-8.040165</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534591</td>\n",
       "      <td>0.574829</td>\n",
       "      <td>-0.470731</td>\n",
       "      <td>0.376408</td>\n",
       "      <td>0.645435</td>\n",
       "      <td>0.216554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boy</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.678109</td>\n",
       "      <td>-8.186996</td>\n",
       "      <td>0.441856</td>\n",
       "      <td>-0.814776</td>\n",
       "      <td>-9.373079</td>\n",
       "      <td>0.455979</td>\n",
       "      <td>-0.910327</td>\n",
       "      <td>-8.907041</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484453</td>\n",
       "      <td>0.453059</td>\n",
       "      <td>-0.516997</td>\n",
       "      <td>0.365139</td>\n",
       "      <td>0.629331</td>\n",
       "      <td>0.273374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.797789</td>\n",
       "      <td>-10.197847</td>\n",
       "      <td>0.429872</td>\n",
       "      <td>-0.955783</td>\n",
       "      <td>-11.699729</td>\n",
       "      <td>0.451075</td>\n",
       "      <td>-1.066465</td>\n",
       "      <td>-11.020497</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474471</td>\n",
       "      <td>0.342270</td>\n",
       "      <td>-0.453968</td>\n",
       "      <td>0.384628</td>\n",
       "      <td>0.589920</td>\n",
       "      <td>0.266067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112923</th>\n",
       "      <td>You</td>\n",
       "      <td>15</td>\n",
       "      <td>0.822056</td>\n",
       "      <td>5.677708</td>\n",
       "      <td>0.710343</td>\n",
       "      <td>1.048670</td>\n",
       "      <td>7.904536</td>\n",
       "      <td>0.604539</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>5.860801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570543</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.108942</td>\n",
       "      <td>0.402942</td>\n",
       "      <td>0.371251</td>\n",
       "      <td>-0.373206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112924</th>\n",
       "      <td>You</td>\n",
       "      <td>16</td>\n",
       "      <td>0.587871</td>\n",
       "      <td>9.669083</td>\n",
       "      <td>1.162361</td>\n",
       "      <td>0.726044</td>\n",
       "      <td>11.412089</td>\n",
       "      <td>1.129761</td>\n",
       "      <td>0.655170</td>\n",
       "      <td>10.942098</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574938</td>\n",
       "      <td>0.538055</td>\n",
       "      <td>0.070751</td>\n",
       "      <td>0.395394</td>\n",
       "      <td>0.452951</td>\n",
       "      <td>-0.300268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112925</th>\n",
       "      <td>You</td>\n",
       "      <td>17</td>\n",
       "      <td>0.337344</td>\n",
       "      <td>21.491173</td>\n",
       "      <td>1.587999</td>\n",
       "      <td>0.362523</td>\n",
       "      <td>25.172693</td>\n",
       "      <td>1.563665</td>\n",
       "      <td>0.306954</td>\n",
       "      <td>24.418745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578150</td>\n",
       "      <td>0.539364</td>\n",
       "      <td>0.051295</td>\n",
       "      <td>0.398031</td>\n",
       "      <td>0.515749</td>\n",
       "      <td>-0.181356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112926</th>\n",
       "      <td>You</td>\n",
       "      <td>18</td>\n",
       "      <td>0.215001</td>\n",
       "      <td>30.405003</td>\n",
       "      <td>1.653764</td>\n",
       "      <td>0.260286</td>\n",
       "      <td>35.272096</td>\n",
       "      <td>1.652273</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>34.866246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580092</td>\n",
       "      <td>0.541042</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.398705</td>\n",
       "      <td>0.534306</td>\n",
       "      <td>-0.237497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112927</th>\n",
       "      <td>You</td>\n",
       "      <td>19</td>\n",
       "      <td>0.182174</td>\n",
       "      <td>30.964133</td>\n",
       "      <td>1.847807</td>\n",
       "      <td>0.224303</td>\n",
       "      <td>36.075314</td>\n",
       "      <td>1.835613</td>\n",
       "      <td>0.095749</td>\n",
       "      <td>35.360101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580864</td>\n",
       "      <td>0.542060</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.398723</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>-0.243124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109440 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Frame       X00        Y00       Z00       X01        Y01  \\\n",
       "0       Boy      1 -3.320268  12.714561  0.223574 -3.320268  12.714561   \n",
       "1       Boy      2 -0.441575 -10.572632  0.370819 -0.500577 -12.161836   \n",
       "2       Boy      3 -0.754394  -7.421648  0.392176 -0.842538  -8.545950   \n",
       "3       Boy      4 -0.678109  -8.186996  0.441856 -0.814776  -9.373079   \n",
       "4       Boy      5 -0.797789 -10.197847  0.429872 -0.955783 -11.699729   \n",
       "...     ...    ...       ...        ...       ...       ...        ...   \n",
       "112923  You     15  0.822056   5.677708  0.710343  1.048670   7.904536   \n",
       "112924  You     16  0.587871   9.669083  1.162361  0.726044  11.412089   \n",
       "112925  You     17  0.337344  21.491173  1.587999  0.362523  25.172693   \n",
       "112926  You     18  0.215001  30.405003  1.653764  0.260286  35.272096   \n",
       "112927  You     19  0.182174  30.964133  1.847807  0.224303  36.075314   \n",
       "\n",
       "             Z01       X02        Y02  ...  Z23  X24  Y24  Z24       X25  \\\n",
       "0       0.223574 -3.320268  12.714561  ...  1.0  0.0  0.0  0.0  0.530313   \n",
       "1       0.379360 -0.622653 -11.623393  ...  1.0  0.0  0.0  0.0  0.531883   \n",
       "2       0.401212 -0.967975  -8.040165  ...  1.0  0.0  0.0  0.0  0.534591   \n",
       "3       0.455979 -0.910327  -8.907041  ...  1.0  0.0  0.0  0.0  0.484453   \n",
       "4       0.451075 -1.066465 -11.020497  ...  1.0  0.0  0.0  0.0  0.474471   \n",
       "...          ...       ...        ...  ...  ...  ...  ...  ...       ...   \n",
       "112923  0.604539  0.998043   5.860801  ...  1.0  0.0  0.0  0.0  0.570543   \n",
       "112924  1.129761  0.655170  10.942098  ...  1.0  0.0  0.0  0.0  0.574938   \n",
       "112925  1.563665  0.306954  24.418745  ...  1.0  0.0  0.0  0.0  0.578150   \n",
       "112926  1.652273  0.141393  34.866246  ...  1.0  0.0  0.0  0.0  0.580092   \n",
       "112927  1.835613  0.095749  35.360101  ...  1.0  0.0  0.0  0.0  0.580864   \n",
       "\n",
       "             Y25       Z25       X26       Y26       Z26  \n",
       "0       0.585678 -0.365724  0.393299  0.607514  0.130718  \n",
       "1       0.588693 -0.381889  0.385701  0.626965  0.241074  \n",
       "2       0.574829 -0.470731  0.376408  0.645435  0.216554  \n",
       "3       0.453059 -0.516997  0.365139  0.629331  0.273374  \n",
       "4       0.342270 -0.453968  0.384628  0.589920  0.266067  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "112923  0.518519  0.108942  0.402942  0.371251 -0.373206  \n",
       "112924  0.538055  0.070751  0.395394  0.452951 -0.300268  \n",
       "112925  0.539364  0.051295  0.398031  0.515749 -0.181356  \n",
       "112926  0.541042  0.027703  0.398705  0.534306 -0.237497  \n",
       "112927  0.542060  0.006164  0.398723  0.538843 -0.243124  \n",
       "\n",
       "[109440 rows x 83 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frame</th>\n",
       "      <th>X00</th>\n",
       "      <th>Y00</th>\n",
       "      <th>Z00</th>\n",
       "      <th>X01</th>\n",
       "      <th>Y01</th>\n",
       "      <th>Z01</th>\n",
       "      <th>X02</th>\n",
       "      <th>Y02</th>\n",
       "      <th>...</th>\n",
       "      <th>Z23</th>\n",
       "      <th>X24</th>\n",
       "      <th>Y24</th>\n",
       "      <th>Z24</th>\n",
       "      <th>X25</th>\n",
       "      <th>Y25</th>\n",
       "      <th>Z25</th>\n",
       "      <th>X26</th>\n",
       "      <th>Y26</th>\n",
       "      <th>Z26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boy</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>0.223574</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>0.223574</td>\n",
       "      <td>-3.320268</td>\n",
       "      <td>12.714561</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530313</td>\n",
       "      <td>0.585678</td>\n",
       "      <td>-0.365724</td>\n",
       "      <td>0.393299</td>\n",
       "      <td>0.607514</td>\n",
       "      <td>0.130718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boy</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.441575</td>\n",
       "      <td>-10.572632</td>\n",
       "      <td>0.370819</td>\n",
       "      <td>-0.500577</td>\n",
       "      <td>-12.161836</td>\n",
       "      <td>0.379360</td>\n",
       "      <td>-0.622653</td>\n",
       "      <td>-11.623393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531883</td>\n",
       "      <td>0.588693</td>\n",
       "      <td>-0.381889</td>\n",
       "      <td>0.385701</td>\n",
       "      <td>0.626965</td>\n",
       "      <td>0.241074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boy</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.754394</td>\n",
       "      <td>-7.421648</td>\n",
       "      <td>0.392176</td>\n",
       "      <td>-0.842538</td>\n",
       "      <td>-8.545950</td>\n",
       "      <td>0.401212</td>\n",
       "      <td>-0.967975</td>\n",
       "      <td>-8.040165</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534591</td>\n",
       "      <td>0.574829</td>\n",
       "      <td>-0.470731</td>\n",
       "      <td>0.376408</td>\n",
       "      <td>0.645435</td>\n",
       "      <td>0.216554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boy</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.678109</td>\n",
       "      <td>-8.186996</td>\n",
       "      <td>0.441856</td>\n",
       "      <td>-0.814776</td>\n",
       "      <td>-9.373079</td>\n",
       "      <td>0.455979</td>\n",
       "      <td>-0.910327</td>\n",
       "      <td>-8.907041</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484453</td>\n",
       "      <td>0.453059</td>\n",
       "      <td>-0.516997</td>\n",
       "      <td>0.365139</td>\n",
       "      <td>0.629331</td>\n",
       "      <td>0.273374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.797789</td>\n",
       "      <td>-10.197847</td>\n",
       "      <td>0.429872</td>\n",
       "      <td>-0.955783</td>\n",
       "      <td>-11.699729</td>\n",
       "      <td>0.451075</td>\n",
       "      <td>-1.066465</td>\n",
       "      <td>-11.020497</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474471</td>\n",
       "      <td>0.342270</td>\n",
       "      <td>-0.453968</td>\n",
       "      <td>0.384628</td>\n",
       "      <td>0.589920</td>\n",
       "      <td>0.266067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109435</th>\n",
       "      <td>You</td>\n",
       "      <td>15</td>\n",
       "      <td>0.822056</td>\n",
       "      <td>5.677708</td>\n",
       "      <td>0.710343</td>\n",
       "      <td>1.048670</td>\n",
       "      <td>7.904536</td>\n",
       "      <td>0.604539</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>5.860801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570543</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.108942</td>\n",
       "      <td>0.402942</td>\n",
       "      <td>0.371251</td>\n",
       "      <td>-0.373206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109436</th>\n",
       "      <td>You</td>\n",
       "      <td>16</td>\n",
       "      <td>0.587871</td>\n",
       "      <td>9.669083</td>\n",
       "      <td>1.162361</td>\n",
       "      <td>0.726044</td>\n",
       "      <td>11.412089</td>\n",
       "      <td>1.129761</td>\n",
       "      <td>0.655170</td>\n",
       "      <td>10.942098</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574938</td>\n",
       "      <td>0.538055</td>\n",
       "      <td>0.070751</td>\n",
       "      <td>0.395394</td>\n",
       "      <td>0.452951</td>\n",
       "      <td>-0.300268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109437</th>\n",
       "      <td>You</td>\n",
       "      <td>17</td>\n",
       "      <td>0.337344</td>\n",
       "      <td>21.491173</td>\n",
       "      <td>1.587999</td>\n",
       "      <td>0.362523</td>\n",
       "      <td>25.172693</td>\n",
       "      <td>1.563665</td>\n",
       "      <td>0.306954</td>\n",
       "      <td>24.418745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578150</td>\n",
       "      <td>0.539364</td>\n",
       "      <td>0.051295</td>\n",
       "      <td>0.398031</td>\n",
       "      <td>0.515749</td>\n",
       "      <td>-0.181356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109438</th>\n",
       "      <td>You</td>\n",
       "      <td>18</td>\n",
       "      <td>0.215001</td>\n",
       "      <td>30.405003</td>\n",
       "      <td>1.653764</td>\n",
       "      <td>0.260286</td>\n",
       "      <td>35.272096</td>\n",
       "      <td>1.652273</td>\n",
       "      <td>0.141393</td>\n",
       "      <td>34.866246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580092</td>\n",
       "      <td>0.541042</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.398705</td>\n",
       "      <td>0.534306</td>\n",
       "      <td>-0.237497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109439</th>\n",
       "      <td>You</td>\n",
       "      <td>19</td>\n",
       "      <td>0.182174</td>\n",
       "      <td>30.964133</td>\n",
       "      <td>1.847807</td>\n",
       "      <td>0.224303</td>\n",
       "      <td>36.075314</td>\n",
       "      <td>1.835613</td>\n",
       "      <td>0.095749</td>\n",
       "      <td>35.360101</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580864</td>\n",
       "      <td>0.542060</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.398723</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>-0.243124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109440 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Frame       X00        Y00       Z00       X01        Y01  \\\n",
       "0       Boy      1 -3.320268  12.714561  0.223574 -3.320268  12.714561   \n",
       "1       Boy      2 -0.441575 -10.572632  0.370819 -0.500577 -12.161836   \n",
       "2       Boy      3 -0.754394  -7.421648  0.392176 -0.842538  -8.545950   \n",
       "3       Boy      4 -0.678109  -8.186996  0.441856 -0.814776  -9.373079   \n",
       "4       Boy      5 -0.797789 -10.197847  0.429872 -0.955783 -11.699729   \n",
       "...     ...    ...       ...        ...       ...       ...        ...   \n",
       "109435  You     15  0.822056   5.677708  0.710343  1.048670   7.904536   \n",
       "109436  You     16  0.587871   9.669083  1.162361  0.726044  11.412089   \n",
       "109437  You     17  0.337344  21.491173  1.587999  0.362523  25.172693   \n",
       "109438  You     18  0.215001  30.405003  1.653764  0.260286  35.272096   \n",
       "109439  You     19  0.182174  30.964133  1.847807  0.224303  36.075314   \n",
       "\n",
       "             Z01       X02        Y02  ...  Z23  X24  Y24  Z24       X25  \\\n",
       "0       0.223574 -3.320268  12.714561  ...  1.0  0.0  0.0  0.0  0.530313   \n",
       "1       0.379360 -0.622653 -11.623393  ...  1.0  0.0  0.0  0.0  0.531883   \n",
       "2       0.401212 -0.967975  -8.040165  ...  1.0  0.0  0.0  0.0  0.534591   \n",
       "3       0.455979 -0.910327  -8.907041  ...  1.0  0.0  0.0  0.0  0.484453   \n",
       "4       0.451075 -1.066465 -11.020497  ...  1.0  0.0  0.0  0.0  0.474471   \n",
       "...          ...       ...        ...  ...  ...  ...  ...  ...       ...   \n",
       "109435  0.604539  0.998043   5.860801  ...  1.0  0.0  0.0  0.0  0.570543   \n",
       "109436  1.129761  0.655170  10.942098  ...  1.0  0.0  0.0  0.0  0.574938   \n",
       "109437  1.563665  0.306954  24.418745  ...  1.0  0.0  0.0  0.0  0.578150   \n",
       "109438  1.652273  0.141393  34.866246  ...  1.0  0.0  0.0  0.0  0.580092   \n",
       "109439  1.835613  0.095749  35.360101  ...  1.0  0.0  0.0  0.0  0.580864   \n",
       "\n",
       "             Y25       Z25       X26       Y26       Z26  \n",
       "0       0.585678 -0.365724  0.393299  0.607514  0.130718  \n",
       "1       0.588693 -0.381889  0.385701  0.626965  0.241074  \n",
       "2       0.574829 -0.470731  0.376408  0.645435  0.216554  \n",
       "3       0.453059 -0.516997  0.365139  0.629331  0.273374  \n",
       "4       0.342270 -0.453968  0.384628  0.589920  0.266067  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "109435  0.518519  0.108942  0.402942  0.371251 -0.373206  \n",
       "109436  0.538055  0.070751  0.395394  0.452951 -0.300268  \n",
       "109437  0.539364  0.051295  0.398031  0.515749 -0.181356  \n",
       "109438  0.541042  0.027703  0.398705  0.534306 -0.237497  \n",
       "109439  0.542060  0.006164  0.398723  0.538843 -0.243124  \n",
       "\n",
       "[109440 rows x 83 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_sequences(group):\n",
    "    # Calculate the number of padding rows needed\n",
    "    padding_rows = max_sequence_length - len(group)\n",
    "    \n",
    "    # Create a DataFrame with padding rows filled with NaN (or any other padding value)\n",
    "    padding_df = pd.DataFrame({\n",
    "        'Word': [group['Word'].iloc[0]] * padding_rows,\n",
    "        'Frame': np.arange(len(group) + 1, max_sequence_length + 1),\n",
    "    })\n",
    "    \n",
    "    # Concatenate the original group with the padding DataFrame\n",
    "    return pd.concat([group, padding_df], ignore_index=True)\n",
    "\n",
    "# Group the DataFrame by 'Word' and apply the padding function\n",
    "padded_df = merged_df.groupby('Word').apply(pad_sequences).reset_index(drop=True)\n",
    "padded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = padded_df.drop('Word', axis=1)\n",
    "target = padded_df['Word']\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "features_scaled = scaler.fit_transform(data)\n",
    "\n",
    "import pickle\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the interval\n",
    "# interval = 20\n",
    "\n",
    "# # Initialize lists to hold the training and testing sets\n",
    "# X_train_list = []\n",
    "# y_train_list = []\n",
    "# X_test_list = []\n",
    "# y_test_list = []\n",
    "\n",
    "# # Iterate over features_scaled with a step of 20\n",
    "# for i in range(0, len(padded_df) - interval, 3*interval):\n",
    "#     # Slice the dataset for the current interval\n",
    "#     X_train = pd.DataFrame(features_scaled[i:i+2*interval])\n",
    "#     y_train = pd.DataFrame(target[i:i+2*interval])\n",
    "\n",
    "#     X_test = pd.DataFrame(features_scaled[i+2*interval:i+3*interval])\n",
    "#     y_test = pd.DataFrame(target[i+2*interval:i+3*interval])\n",
    "\n",
    "#     # Append the sliced DataFrames to the lists\n",
    "#     X_train_list.append(X_train)\n",
    "#     y_train_list.append(y_train)\n",
    "#     X_test_list.append(X_test)\n",
    "#     y_test_list.append(y_test)\n",
    "\n",
    "# # Convert the lists to DataFrames\n",
    "# X_train_df = pd.concat(X_train_list)\n",
    "# y_train_df = pd.concat(y_train_list)\n",
    "# X_test_df = pd.concat(X_test_list)\n",
    "# y_test_df = pd.concat(y_test_list)\n",
    "\n",
    "# X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Initialize the model\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# clf.fit(X_train_df, y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_df)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(classification_report(y_test_df, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('rfmodel.pkl', 'wb') as file:\n",
    "#     pickle.dump(clf, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5760"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of time steps\n",
    "time_steps = 19\n",
    "\n",
    "# Prepare the data\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(features_scaled) - time_steps + 1, time_steps):\n",
    "    X.append(features_scaled[i:i + time_steps])\n",
    "    y.append(target[i])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Reshape X to fit the LSTM input shape: [samples, time steps, features]\n",
    "X = X.reshape((5760, time_steps, 82))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'y_train' is your target variable with categorical values\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mello\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">54,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">867</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m82\u001b[0m)         │        \u001b[38;5;34m54,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m82\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m26,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)             │           \u001b[38;5;34m867\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,587</span> (318.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81,587\u001b[0m (318.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,587</span> (318.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81,587\u001b[0m (318.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Assuming X_train has shape (num_samples, timesteps, features)\n",
    "timesteps = X_train.shape[1]\n",
    "features = X_train.shape[2]\n",
    "num_classes = len(encoder.classes_)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(features, return_sequences=True, input_shape=(timesteps, features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7224 - loss: 0.7918 - val_accuracy: 0.6540 - val_loss: 1.0016\n",
      "Epoch 2/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7071 - loss: 0.8344 - val_accuracy: 0.6551 - val_loss: 1.0319\n",
      "Epoch 3/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7236 - loss: 0.7896 - val_accuracy: 0.6790 - val_loss: 0.9114\n",
      "Epoch 4/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7198 - loss: 0.7739 - val_accuracy: 0.6681 - val_loss: 0.9012\n",
      "Epoch 5/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7280 - loss: 0.7459 - val_accuracy: 0.6627 - val_loss: 0.9737\n",
      "Epoch 6/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7059 - loss: 0.8130 - val_accuracy: 0.6985 - val_loss: 0.8230\n",
      "Epoch 7/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7245 - loss: 0.7640 - val_accuracy: 0.7289 - val_loss: 0.7866\n",
      "Epoch 8/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7320 - loss: 0.7536 - val_accuracy: 0.7299 - val_loss: 0.7597\n",
      "Epoch 9/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7447 - loss: 0.7189 - val_accuracy: 0.6996 - val_loss: 0.8590\n",
      "Epoch 10/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7563 - loss: 0.6984 - val_accuracy: 0.7711 - val_loss: 0.7041\n",
      "Epoch 11/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7729 - loss: 0.6570 - val_accuracy: 0.7419 - val_loss: 0.7562\n",
      "Epoch 12/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7637 - loss: 0.6612 - val_accuracy: 0.7354 - val_loss: 0.7844\n",
      "Epoch 13/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7633 - loss: 0.6807 - val_accuracy: 0.6866 - val_loss: 0.8526\n",
      "Epoch 14/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7470 - loss: 0.7081 - val_accuracy: 0.7560 - val_loss: 0.7167\n",
      "Epoch 15/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7639 - loss: 0.6609 - val_accuracy: 0.7278 - val_loss: 0.8277\n",
      "Epoch 16/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7488 - loss: 0.7216 - val_accuracy: 0.7570 - val_loss: 0.7323\n",
      "Epoch 17/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7467 - loss: 0.7598 - val_accuracy: 0.7549 - val_loss: 0.6885\n",
      "Epoch 18/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7740 - loss: 0.6410 - val_accuracy: 0.7527 - val_loss: 0.6771\n",
      "Epoch 19/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7553 - loss: 0.6800 - val_accuracy: 0.7343 - val_loss: 0.7391\n",
      "Epoch 20/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7300 - loss: 0.7509 - val_accuracy: 0.7386 - val_loss: 0.7507\n",
      "Epoch 21/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7442 - loss: 0.7158 - val_accuracy: 0.7440 - val_loss: 0.7104\n",
      "Epoch 22/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7909 - loss: 0.5949 - val_accuracy: 0.7755 - val_loss: 0.6573\n",
      "Epoch 23/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7999 - loss: 0.5725 - val_accuracy: 0.7310 - val_loss: 0.7455\n",
      "Epoch 24/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7860 - loss: 0.5871 - val_accuracy: 0.7787 - val_loss: 0.6237\n",
      "Epoch 25/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7965 - loss: 0.5793 - val_accuracy: 0.7299 - val_loss: 0.7829\n",
      "Epoch 26/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7727 - loss: 0.5985 - val_accuracy: 0.7278 - val_loss: 0.7390\n",
      "Epoch 27/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8089 - loss: 0.5653 - val_accuracy: 0.7733 - val_loss: 0.6456\n",
      "Epoch 28/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7817 - loss: 0.5988 - val_accuracy: 0.7820 - val_loss: 0.6401\n",
      "Epoch 29/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8040 - loss: 0.5514 - val_accuracy: 0.7430 - val_loss: 0.7406\n",
      "Epoch 30/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7725 - loss: 0.6507 - val_accuracy: 0.7169 - val_loss: 0.7598\n",
      "Epoch 31/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7930 - loss: 0.5908 - val_accuracy: 0.7842 - val_loss: 0.6494\n",
      "Epoch 32/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8216 - loss: 0.5277 - val_accuracy: 0.7299 - val_loss: 0.7922\n",
      "Epoch 33/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7815 - loss: 0.6267 - val_accuracy: 0.7798 - val_loss: 0.6188\n",
      "Epoch 34/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8221 - loss: 0.5292 - val_accuracy: 0.7104 - val_loss: 0.9234\n",
      "Epoch 35/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7985 - loss: 0.5697 - val_accuracy: 0.7148 - val_loss: 0.7785\n",
      "Epoch 36/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7944 - loss: 0.5880 - val_accuracy: 0.7798 - val_loss: 0.6439\n",
      "Epoch 37/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7994 - loss: 0.5776 - val_accuracy: 0.7484 - val_loss: 0.7157\n",
      "Epoch 38/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8159 - loss: 0.5474 - val_accuracy: 0.7907 - val_loss: 0.5848\n",
      "Epoch 39/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8145 - loss: 0.5265 - val_accuracy: 0.7560 - val_loss: 0.7275\n",
      "Epoch 40/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8065 - loss: 0.5362 - val_accuracy: 0.7364 - val_loss: 0.7206\n",
      "Epoch 41/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8097 - loss: 0.5580 - val_accuracy: 0.7733 - val_loss: 0.6471\n",
      "Epoch 42/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8213 - loss: 0.5464 - val_accuracy: 0.7961 - val_loss: 0.6158\n",
      "Epoch 43/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8369 - loss: 0.4814 - val_accuracy: 0.7993 - val_loss: 0.6102\n",
      "Epoch 44/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8290 - loss: 0.4800 - val_accuracy: 0.7972 - val_loss: 0.6146\n",
      "Epoch 45/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8299 - loss: 0.4987 - val_accuracy: 0.7419 - val_loss: 0.7137\n",
      "Epoch 46/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7888 - loss: 0.5945 - val_accuracy: 0.7972 - val_loss: 0.5906\n",
      "Epoch 47/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8177 - loss: 0.5095 - val_accuracy: 0.8004 - val_loss: 0.6129\n",
      "Epoch 48/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8380 - loss: 0.4917 - val_accuracy: 0.7820 - val_loss: 0.6254\n",
      "Epoch 49/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8239 - loss: 0.4928 - val_accuracy: 0.7191 - val_loss: 0.8760\n",
      "Epoch 50/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7803 - loss: 0.6244 - val_accuracy: 0.7419 - val_loss: 0.7680\n",
      "Epoch 51/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8329 - loss: 0.4803 - val_accuracy: 0.7972 - val_loss: 0.5740\n",
      "Epoch 52/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8427 - loss: 0.4641 - val_accuracy: 0.7527 - val_loss: 0.6676\n",
      "Epoch 53/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8462 - loss: 0.4499 - val_accuracy: 0.7191 - val_loss: 0.7971\n",
      "Epoch 54/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7683 - loss: 0.6515 - val_accuracy: 0.7961 - val_loss: 0.6039\n",
      "Epoch 55/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8398 - loss: 0.4639 - val_accuracy: 0.7777 - val_loss: 0.6057\n",
      "Epoch 56/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8332 - loss: 0.4670 - val_accuracy: 0.7842 - val_loss: 0.6366\n",
      "Epoch 57/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8257 - loss: 0.5095 - val_accuracy: 0.7928 - val_loss: 0.6350\n",
      "Epoch 58/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8299 - loss: 0.4986 - val_accuracy: 0.7625 - val_loss: 0.7015\n",
      "Epoch 59/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8110 - loss: 0.5392 - val_accuracy: 0.7874 - val_loss: 0.6506\n",
      "Epoch 60/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8231 - loss: 0.5073 - val_accuracy: 0.8156 - val_loss: 0.5636\n",
      "Epoch 61/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8455 - loss: 0.4502 - val_accuracy: 0.8178 - val_loss: 0.5455\n",
      "Epoch 62/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8587 - loss: 0.4037 - val_accuracy: 0.7213 - val_loss: 0.7617\n",
      "Epoch 63/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8147 - loss: 0.5223 - val_accuracy: 0.8091 - val_loss: 0.5759\n",
      "Epoch 64/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8204 - loss: 0.5278 - val_accuracy: 0.7896 - val_loss: 0.6022\n",
      "Epoch 65/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8753 - loss: 0.3979 - val_accuracy: 0.7983 - val_loss: 0.6029\n",
      "Epoch 66/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8576 - loss: 0.4042 - val_accuracy: 0.7278 - val_loss: 0.8193\n",
      "Epoch 67/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7237 - loss: 0.8858 - val_accuracy: 0.8232 - val_loss: 0.5550\n",
      "Epoch 68/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8631 - loss: 0.4072 - val_accuracy: 0.8004 - val_loss: 0.5704\n",
      "Epoch 69/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8738 - loss: 0.3745 - val_accuracy: 0.7744 - val_loss: 0.6447\n",
      "Epoch 70/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8377 - loss: 0.4494 - val_accuracy: 0.8178 - val_loss: 0.5426\n",
      "Epoch 71/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8623 - loss: 0.3901 - val_accuracy: 0.7646 - val_loss: 0.6659\n",
      "Epoch 72/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8637 - loss: 0.4019 - val_accuracy: 0.7657 - val_loss: 0.6848\n",
      "Epoch 73/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8666 - loss: 0.3937 - val_accuracy: 0.8275 - val_loss: 0.5341\n",
      "Epoch 74/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8809 - loss: 0.3615 - val_accuracy: 0.8026 - val_loss: 0.5950\n",
      "Epoch 75/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8549 - loss: 0.4379 - val_accuracy: 0.8254 - val_loss: 0.5313\n",
      "Epoch 76/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8823 - loss: 0.3401 - val_accuracy: 0.8200 - val_loss: 0.5336\n",
      "Epoch 77/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8529 - loss: 0.4257 - val_accuracy: 0.8037 - val_loss: 0.5663\n",
      "Epoch 78/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7924 - loss: 0.6147 - val_accuracy: 0.7386 - val_loss: 0.7657\n",
      "Epoch 79/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8218 - loss: 0.5246 - val_accuracy: 0.7614 - val_loss: 0.6969\n",
      "Epoch 80/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8714 - loss: 0.3642 - val_accuracy: 0.7972 - val_loss: 0.6090\n",
      "Epoch 81/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8791 - loss: 0.3508 - val_accuracy: 0.7885 - val_loss: 0.6053\n",
      "Epoch 82/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8734 - loss: 0.3626 - val_accuracy: 0.8026 - val_loss: 0.6163\n",
      "Epoch 83/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8639 - loss: 0.3818 - val_accuracy: 0.8265 - val_loss: 0.5122\n",
      "Epoch 84/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8822 - loss: 0.3390 - val_accuracy: 0.7874 - val_loss: 0.6068\n",
      "Epoch 85/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8717 - loss: 0.3735 - val_accuracy: 0.8080 - val_loss: 0.6121\n",
      "Epoch 86/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8834 - loss: 0.3465 - val_accuracy: 0.8113 - val_loss: 0.5542\n",
      "Epoch 87/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8954 - loss: 0.3222 - val_accuracy: 0.7375 - val_loss: 0.7914\n",
      "Epoch 88/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8771 - loss: 0.3645 - val_accuracy: 0.7375 - val_loss: 0.8458\n",
      "Epoch 89/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8430 - loss: 0.4521 - val_accuracy: 0.8362 - val_loss: 0.5142\n",
      "Epoch 90/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8693 - loss: 0.4028 - val_accuracy: 0.8536 - val_loss: 0.4799\n",
      "Epoch 91/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8654 - loss: 0.4193 - val_accuracy: 0.8330 - val_loss: 0.5077\n",
      "Epoch 92/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8758 - loss: 0.3581 - val_accuracy: 0.8373 - val_loss: 0.4937\n",
      "Epoch 93/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9095 - loss: 0.2889 - val_accuracy: 0.8134 - val_loss: 0.5857\n",
      "Epoch 94/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8855 - loss: 0.3418 - val_accuracy: 0.8102 - val_loss: 0.5528\n",
      "Epoch 95/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8727 - loss: 0.3834 - val_accuracy: 0.7852 - val_loss: 0.6093\n",
      "Epoch 96/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8866 - loss: 0.3387 - val_accuracy: 0.7961 - val_loss: 0.6303\n",
      "Epoch 97/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8438 - loss: 0.4458 - val_accuracy: 0.8395 - val_loss: 0.4925\n",
      "Epoch 98/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8965 - loss: 0.3254 - val_accuracy: 0.8134 - val_loss: 0.6128\n",
      "Epoch 99/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8607 - loss: 0.3981 - val_accuracy: 0.8080 - val_loss: 0.5996\n",
      "Epoch 100/100\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8728 - loss: 0.3545 - val_accuracy: 0.8427 - val_loss: 0.4680\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_encoded, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6498 - loss: 1.0094\n",
      "Test Loss: 1.0155057907104492, Test Accuracy: 0.6510416865348816\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.81        90\n",
      "           1       0.82      0.78      0.80        90\n",
      "           2       0.45      0.48      0.46        86\n",
      "           3       0.58      0.34      0.43        83\n",
      "           4       0.61      0.80      0.69        83\n",
      "           5       0.94      0.80      0.86        90\n",
      "           6       0.57      0.66      0.61        35\n",
      "           7       0.50      0.62      0.55        86\n",
      "           8       0.54      0.47      0.50        83\n",
      "           9       1.00      0.36      0.53        22\n",
      "          10       0.68      0.35      0.46        54\n",
      "          11       0.91      0.38      0.54        26\n",
      "          12       0.74      0.88      0.81        26\n",
      "          13       0.61      0.85      0.71        13\n",
      "          14       0.77      0.61      0.68        90\n",
      "          15       0.57      0.88      0.69        93\n",
      "          16       0.64      0.74      0.68       102\n",
      "\n",
      "    accuracy                           0.65      1152\n",
      "   macro avg       0.69      0.64      0.64      1152\n",
      "weighted avg       0.67      0.65      0.64      1152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test) # Replace `model` with your trained LSTM model and `X_test` with your test dataset\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "# Print the classification report\n",
    "print(classification_report(y_test_encoded, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# with open('lstmmodel.pkl', 'wb') as file:\n",
    "#     pickle.dump(model, file)\n",
    "model.save('lstmmodel.h5')\n",
    "tf.saved_model.save(model, 'saved_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
