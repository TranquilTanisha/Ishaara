{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frame</th>\n",
       "      <th>X00</th>\n",
       "      <th>Y00</th>\n",
       "      <th>Z00</th>\n",
       "      <th>X01</th>\n",
       "      <th>Y01</th>\n",
       "      <th>Z01</th>\n",
       "      <th>X02</th>\n",
       "      <th>Y02</th>\n",
       "      <th>...</th>\n",
       "      <th>Z62</th>\n",
       "      <th>X63</th>\n",
       "      <th>Y63</th>\n",
       "      <th>Z63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Y64</th>\n",
       "      <th>Z64</th>\n",
       "      <th>X65</th>\n",
       "      <th>Y65</th>\n",
       "      <th>Z65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boy</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.290488</td>\n",
       "      <td>-75.818914</td>\n",
       "      <td>-3.229877</td>\n",
       "      <td>-0.166410</td>\n",
       "      <td>-77.328566</td>\n",
       "      <td>-3.061451</td>\n",
       "      <td>-0.098528</td>\n",
       "      <td>-82.594196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349284</td>\n",
       "      <td>0.610715</td>\n",
       "      <td>0.973082</td>\n",
       "      <td>-0.303378</td>\n",
       "      <td>0.405078</td>\n",
       "      <td>0.922159</td>\n",
       "      <td>-0.281479</td>\n",
       "      <td>0.559808</td>\n",
       "      <td>0.851646</td>\n",
       "      <td>-0.028510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boy</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.630732</td>\n",
       "      <td>163.577346</td>\n",
       "      <td>-2.202535</td>\n",
       "      <td>-2.630732</td>\n",
       "      <td>163.577346</td>\n",
       "      <td>-2.202535</td>\n",
       "      <td>-2.630732</td>\n",
       "      <td>163.577346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346683</td>\n",
       "      <td>0.613981</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>-0.395646</td>\n",
       "      <td>0.413621</td>\n",
       "      <td>0.845886</td>\n",
       "      <td>-0.267950</td>\n",
       "      <td>0.558445</td>\n",
       "      <td>0.851427</td>\n",
       "      <td>-0.036818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boy</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.649066</td>\n",
       "      <td>62.903229</td>\n",
       "      <td>-2.865200</td>\n",
       "      <td>-2.649066</td>\n",
       "      <td>62.903229</td>\n",
       "      <td>-2.865200</td>\n",
       "      <td>-2.649066</td>\n",
       "      <td>62.903229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.820756</td>\n",
       "      <td>0.612683</td>\n",
       "      <td>0.950004</td>\n",
       "      <td>-0.379825</td>\n",
       "      <td>0.448817</td>\n",
       "      <td>0.581546</td>\n",
       "      <td>-0.748774</td>\n",
       "      <td>0.557367</td>\n",
       "      <td>0.867107</td>\n",
       "      <td>-0.040340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boy</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.641445</td>\n",
       "      <td>73.387394</td>\n",
       "      <td>-6.816939</td>\n",
       "      <td>-2.641445</td>\n",
       "      <td>73.387394</td>\n",
       "      <td>-6.816939</td>\n",
       "      <td>-2.641445</td>\n",
       "      <td>73.387394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.892051</td>\n",
       "      <td>0.607402</td>\n",
       "      <td>0.961182</td>\n",
       "      <td>-0.300694</td>\n",
       "      <td>0.439404</td>\n",
       "      <td>0.449596</td>\n",
       "      <td>-0.823084</td>\n",
       "      <td>0.556838</td>\n",
       "      <td>0.878659</td>\n",
       "      <td>-0.022312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.075973</td>\n",
       "      <td>-2.649841</td>\n",
       "      <td>-1.005892</td>\n",
       "      <td>0.190630</td>\n",
       "      <td>-5.362860</td>\n",
       "      <td>-1.022167</td>\n",
       "      <td>0.243538</td>\n",
       "      <td>-8.214614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829807</td>\n",
       "      <td>0.604378</td>\n",
       "      <td>0.950633</td>\n",
       "      <td>-0.247957</td>\n",
       "      <td>0.445261</td>\n",
       "      <td>0.344964</td>\n",
       "      <td>-0.765876</td>\n",
       "      <td>0.552638</td>\n",
       "      <td>0.877294</td>\n",
       "      <td>-0.045415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14135</th>\n",
       "      <td>You</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.255172</td>\n",
       "      <td>-14.686667</td>\n",
       "      <td>2.176972</td>\n",
       "      <td>-0.137746</td>\n",
       "      <td>-15.407824</td>\n",
       "      <td>3.206680</td>\n",
       "      <td>-0.088495</td>\n",
       "      <td>-16.454638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189617</td>\n",
       "      <td>0.678464</td>\n",
       "      <td>0.430918</td>\n",
       "      <td>-0.998512</td>\n",
       "      <td>0.307135</td>\n",
       "      <td>0.832112</td>\n",
       "      <td>-0.110380</td>\n",
       "      <td>0.559508</td>\n",
       "      <td>0.746648</td>\n",
       "      <td>0.006331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14136</th>\n",
       "      <td>You</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.247349</td>\n",
       "      <td>-18.125843</td>\n",
       "      <td>0.387121</td>\n",
       "      <td>-0.123823</td>\n",
       "      <td>-19.070908</td>\n",
       "      <td>-0.996675</td>\n",
       "      <td>-0.073921</td>\n",
       "      <td>-20.329048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235708</td>\n",
       "      <td>0.673772</td>\n",
       "      <td>0.673639</td>\n",
       "      <td>-0.173289</td>\n",
       "      <td>0.301638</td>\n",
       "      <td>0.830727</td>\n",
       "      <td>-0.135007</td>\n",
       "      <td>0.558916</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>0.016739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14137</th>\n",
       "      <td>You</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.252560</td>\n",
       "      <td>-28.690787</td>\n",
       "      <td>5.913587</td>\n",
       "      <td>-0.133411</td>\n",
       "      <td>-30.150542</td>\n",
       "      <td>5.626362</td>\n",
       "      <td>-0.083474</td>\n",
       "      <td>-32.168021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.643596</td>\n",
       "      <td>0.653561</td>\n",
       "      <td>0.818583</td>\n",
       "      <td>-0.402061</td>\n",
       "      <td>0.293410</td>\n",
       "      <td>0.830436</td>\n",
       "      <td>-0.519518</td>\n",
       "      <td>0.550947</td>\n",
       "      <td>0.735413</td>\n",
       "      <td>0.027168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14138</th>\n",
       "      <td>You</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.263622</td>\n",
       "      <td>-44.649560</td>\n",
       "      <td>6.507309</td>\n",
       "      <td>-0.145083</td>\n",
       "      <td>-46.797549</td>\n",
       "      <td>6.096631</td>\n",
       "      <td>-0.096428</td>\n",
       "      <td>-49.825290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573453</td>\n",
       "      <td>0.627514</td>\n",
       "      <td>0.836671</td>\n",
       "      <td>-0.288298</td>\n",
       "      <td>0.281208</td>\n",
       "      <td>0.831862</td>\n",
       "      <td>-0.455801</td>\n",
       "      <td>0.543025</td>\n",
       "      <td>0.740520</td>\n",
       "      <td>0.026633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14139</th>\n",
       "      <td>You</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.281000</td>\n",
       "      <td>-67.864949</td>\n",
       "      <td>7.771813</td>\n",
       "      <td>-0.160708</td>\n",
       "      <td>-71.308601</td>\n",
       "      <td>7.211858</td>\n",
       "      <td>-0.112549</td>\n",
       "      <td>-76.094353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521230</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>-0.280609</td>\n",
       "      <td>0.273794</td>\n",
       "      <td>0.836519</td>\n",
       "      <td>-0.409446</td>\n",
       "      <td>0.534971</td>\n",
       "      <td>0.747671</td>\n",
       "      <td>0.022982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14140 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Frame       X00         Y00       Z00       X01         Y01  \\\n",
       "0      Boy      1 -0.290488  -75.818914 -3.229877 -0.166410  -77.328566   \n",
       "1      Boy      2 -2.630732  163.577346 -2.202535 -2.630732  163.577346   \n",
       "2      Boy      3 -2.649066   62.903229 -2.865200 -2.649066   62.903229   \n",
       "3      Boy      4 -2.641445   73.387394 -6.816939 -2.641445   73.387394   \n",
       "4      Boy      5  0.075973   -2.649841 -1.005892  0.190630   -5.362860   \n",
       "...    ...    ...       ...         ...       ...       ...         ...   \n",
       "14135  You     16 -0.255172  -14.686667  2.176972 -0.137746  -15.407824   \n",
       "14136  You     17 -0.247349  -18.125843  0.387121 -0.123823  -19.070908   \n",
       "14137  You     18 -0.252560  -28.690787  5.913587 -0.133411  -30.150542   \n",
       "14138  You     19 -0.263622  -44.649560  6.507309 -0.145083  -46.797549   \n",
       "14139  You     20 -0.281000  -67.864949  7.771813 -0.160708  -71.308601   \n",
       "\n",
       "            Z01       X02         Y02  ...       Z62       X63       Y63  \\\n",
       "0     -3.061451 -0.098528  -82.594196  ... -0.349284  0.610715  0.973082   \n",
       "1     -2.202535 -2.630732  163.577346  ... -0.346683  0.613981  0.946346   \n",
       "2     -2.865200 -2.649066   62.903229  ... -0.820756  0.612683  0.950004   \n",
       "3     -6.816939 -2.641445   73.387394  ... -0.892051  0.607402  0.961182   \n",
       "4     -1.022167  0.243538   -8.214614  ... -0.829807  0.604378  0.950633   \n",
       "...         ...       ...         ...  ...       ...       ...       ...   \n",
       "14135  3.206680 -0.088495  -16.454638  ... -0.189617  0.678464  0.430918   \n",
       "14136 -0.996675 -0.073921  -20.329048  ... -0.235708  0.673772  0.673639   \n",
       "14137  5.626362 -0.083474  -32.168021  ... -0.643596  0.653561  0.818583   \n",
       "14138  6.096631 -0.096428  -49.825290  ... -0.573453  0.627514  0.836671   \n",
       "14139  7.211858 -0.112549  -76.094353  ... -0.521230  0.608247  0.844743   \n",
       "\n",
       "            Z63       X64       Y64       Z64       X65       Y65       Z65  \n",
       "0     -0.303378  0.405078  0.922159 -0.281479  0.559808  0.851646 -0.028510  \n",
       "1     -0.395646  0.413621  0.845886 -0.267950  0.558445  0.851427 -0.036818  \n",
       "2     -0.379825  0.448817  0.581546 -0.748774  0.557367  0.867107 -0.040340  \n",
       "3     -0.300694  0.439404  0.449596 -0.823084  0.556838  0.878659 -0.022312  \n",
       "4     -0.247957  0.445261  0.344964 -0.765876  0.552638  0.877294 -0.045415  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "14135 -0.998512  0.307135  0.832112 -0.110380  0.559508  0.746648  0.006331  \n",
       "14136 -0.173289  0.301638  0.830727 -0.135007  0.558916  0.736754  0.016739  \n",
       "14137 -0.402061  0.293410  0.830436 -0.519518  0.550947  0.735413  0.027168  \n",
       "14138 -0.288298  0.281208  0.831862 -0.455801  0.543025  0.740520  0.026633  \n",
       "14139 -0.280609  0.273794  0.836519 -0.409446  0.534971  0.747671  0.022982  \n",
       "\n",
       "[14140 rows x 200 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load each .npy file and convert the list of dictionaries to a DataFrame\n",
    "dataframes = []\n",
    "for file in os.listdir('dataset'):\n",
    "    if file.endswith('.npy'):\n",
    "        data = np.load('dataset/' + file, allow_pickle=True)\n",
    "        dataframes.append(pd.DataFrame.from_records(data))\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length = merged_df['Frame'].max()\n",
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_4844\\2834639197.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  padded_df = merged_df.groupby('Word').apply(pad_sequences).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frame</th>\n",
       "      <th>X00</th>\n",
       "      <th>Y00</th>\n",
       "      <th>Z00</th>\n",
       "      <th>X01</th>\n",
       "      <th>Y01</th>\n",
       "      <th>Z01</th>\n",
       "      <th>X02</th>\n",
       "      <th>Y02</th>\n",
       "      <th>...</th>\n",
       "      <th>Z62</th>\n",
       "      <th>X63</th>\n",
       "      <th>Y63</th>\n",
       "      <th>Z63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Y64</th>\n",
       "      <th>Z64</th>\n",
       "      <th>X65</th>\n",
       "      <th>Y65</th>\n",
       "      <th>Z65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boy</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.290488</td>\n",
       "      <td>-75.818914</td>\n",
       "      <td>-3.229877</td>\n",
       "      <td>-0.166410</td>\n",
       "      <td>-77.328566</td>\n",
       "      <td>-3.061451</td>\n",
       "      <td>-0.098528</td>\n",
       "      <td>-82.594196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349284</td>\n",
       "      <td>0.610715</td>\n",
       "      <td>0.973082</td>\n",
       "      <td>-0.303378</td>\n",
       "      <td>0.405078</td>\n",
       "      <td>0.922159</td>\n",
       "      <td>-0.281479</td>\n",
       "      <td>0.559808</td>\n",
       "      <td>0.851646</td>\n",
       "      <td>-0.028510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boy</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.630732</td>\n",
       "      <td>163.577346</td>\n",
       "      <td>-2.202535</td>\n",
       "      <td>-2.630732</td>\n",
       "      <td>163.577346</td>\n",
       "      <td>-2.202535</td>\n",
       "      <td>-2.630732</td>\n",
       "      <td>163.577346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346683</td>\n",
       "      <td>0.613981</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>-0.395646</td>\n",
       "      <td>0.413621</td>\n",
       "      <td>0.845886</td>\n",
       "      <td>-0.267950</td>\n",
       "      <td>0.558445</td>\n",
       "      <td>0.851427</td>\n",
       "      <td>-0.036818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boy</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.649066</td>\n",
       "      <td>62.903229</td>\n",
       "      <td>-2.865200</td>\n",
       "      <td>-2.649066</td>\n",
       "      <td>62.903229</td>\n",
       "      <td>-2.865200</td>\n",
       "      <td>-2.649066</td>\n",
       "      <td>62.903229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.820756</td>\n",
       "      <td>0.612683</td>\n",
       "      <td>0.950004</td>\n",
       "      <td>-0.379825</td>\n",
       "      <td>0.448817</td>\n",
       "      <td>0.581546</td>\n",
       "      <td>-0.748774</td>\n",
       "      <td>0.557367</td>\n",
       "      <td>0.867107</td>\n",
       "      <td>-0.040340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boy</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.641445</td>\n",
       "      <td>73.387394</td>\n",
       "      <td>-6.816939</td>\n",
       "      <td>-2.641445</td>\n",
       "      <td>73.387394</td>\n",
       "      <td>-6.816939</td>\n",
       "      <td>-2.641445</td>\n",
       "      <td>73.387394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.892051</td>\n",
       "      <td>0.607402</td>\n",
       "      <td>0.961182</td>\n",
       "      <td>-0.300694</td>\n",
       "      <td>0.439404</td>\n",
       "      <td>0.449596</td>\n",
       "      <td>-0.823084</td>\n",
       "      <td>0.556838</td>\n",
       "      <td>0.878659</td>\n",
       "      <td>-0.022312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.075973</td>\n",
       "      <td>-2.649841</td>\n",
       "      <td>-1.005892</td>\n",
       "      <td>0.190630</td>\n",
       "      <td>-5.362860</td>\n",
       "      <td>-1.022167</td>\n",
       "      <td>0.243538</td>\n",
       "      <td>-8.214614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.829807</td>\n",
       "      <td>0.604378</td>\n",
       "      <td>0.950633</td>\n",
       "      <td>-0.247957</td>\n",
       "      <td>0.445261</td>\n",
       "      <td>0.344964</td>\n",
       "      <td>-0.765876</td>\n",
       "      <td>0.552638</td>\n",
       "      <td>0.877294</td>\n",
       "      <td>-0.045415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14135</th>\n",
       "      <td>You</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.255172</td>\n",
       "      <td>-14.686667</td>\n",
       "      <td>2.176972</td>\n",
       "      <td>-0.137746</td>\n",
       "      <td>-15.407824</td>\n",
       "      <td>3.206680</td>\n",
       "      <td>-0.088495</td>\n",
       "      <td>-16.454638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189617</td>\n",
       "      <td>0.678464</td>\n",
       "      <td>0.430918</td>\n",
       "      <td>-0.998512</td>\n",
       "      <td>0.307135</td>\n",
       "      <td>0.832112</td>\n",
       "      <td>-0.110380</td>\n",
       "      <td>0.559508</td>\n",
       "      <td>0.746648</td>\n",
       "      <td>0.006331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14136</th>\n",
       "      <td>You</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.247349</td>\n",
       "      <td>-18.125843</td>\n",
       "      <td>0.387121</td>\n",
       "      <td>-0.123823</td>\n",
       "      <td>-19.070908</td>\n",
       "      <td>-0.996675</td>\n",
       "      <td>-0.073921</td>\n",
       "      <td>-20.329048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235708</td>\n",
       "      <td>0.673772</td>\n",
       "      <td>0.673639</td>\n",
       "      <td>-0.173289</td>\n",
       "      <td>0.301638</td>\n",
       "      <td>0.830727</td>\n",
       "      <td>-0.135007</td>\n",
       "      <td>0.558916</td>\n",
       "      <td>0.736754</td>\n",
       "      <td>0.016739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14137</th>\n",
       "      <td>You</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.252560</td>\n",
       "      <td>-28.690787</td>\n",
       "      <td>5.913587</td>\n",
       "      <td>-0.133411</td>\n",
       "      <td>-30.150542</td>\n",
       "      <td>5.626362</td>\n",
       "      <td>-0.083474</td>\n",
       "      <td>-32.168021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.643596</td>\n",
       "      <td>0.653561</td>\n",
       "      <td>0.818583</td>\n",
       "      <td>-0.402061</td>\n",
       "      <td>0.293410</td>\n",
       "      <td>0.830436</td>\n",
       "      <td>-0.519518</td>\n",
       "      <td>0.550947</td>\n",
       "      <td>0.735413</td>\n",
       "      <td>0.027168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14138</th>\n",
       "      <td>You</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.263622</td>\n",
       "      <td>-44.649560</td>\n",
       "      <td>6.507309</td>\n",
       "      <td>-0.145083</td>\n",
       "      <td>-46.797549</td>\n",
       "      <td>6.096631</td>\n",
       "      <td>-0.096428</td>\n",
       "      <td>-49.825290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573453</td>\n",
       "      <td>0.627514</td>\n",
       "      <td>0.836671</td>\n",
       "      <td>-0.288298</td>\n",
       "      <td>0.281208</td>\n",
       "      <td>0.831862</td>\n",
       "      <td>-0.455801</td>\n",
       "      <td>0.543025</td>\n",
       "      <td>0.740520</td>\n",
       "      <td>0.026633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14139</th>\n",
       "      <td>You</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.281000</td>\n",
       "      <td>-67.864949</td>\n",
       "      <td>7.771813</td>\n",
       "      <td>-0.160708</td>\n",
       "      <td>-71.308601</td>\n",
       "      <td>7.211858</td>\n",
       "      <td>-0.112549</td>\n",
       "      <td>-76.094353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.521230</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>-0.280609</td>\n",
       "      <td>0.273794</td>\n",
       "      <td>0.836519</td>\n",
       "      <td>-0.409446</td>\n",
       "      <td>0.534971</td>\n",
       "      <td>0.747671</td>\n",
       "      <td>0.022982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14140 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Frame       X00         Y00       Z00       X01         Y01  \\\n",
       "0      Boy      1 -0.290488  -75.818914 -3.229877 -0.166410  -77.328566   \n",
       "1      Boy      2 -2.630732  163.577346 -2.202535 -2.630732  163.577346   \n",
       "2      Boy      3 -2.649066   62.903229 -2.865200 -2.649066   62.903229   \n",
       "3      Boy      4 -2.641445   73.387394 -6.816939 -2.641445   73.387394   \n",
       "4      Boy      5  0.075973   -2.649841 -1.005892  0.190630   -5.362860   \n",
       "...    ...    ...       ...         ...       ...       ...         ...   \n",
       "14135  You     16 -0.255172  -14.686667  2.176972 -0.137746  -15.407824   \n",
       "14136  You     17 -0.247349  -18.125843  0.387121 -0.123823  -19.070908   \n",
       "14137  You     18 -0.252560  -28.690787  5.913587 -0.133411  -30.150542   \n",
       "14138  You     19 -0.263622  -44.649560  6.507309 -0.145083  -46.797549   \n",
       "14139  You     20 -0.281000  -67.864949  7.771813 -0.160708  -71.308601   \n",
       "\n",
       "            Z01       X02         Y02  ...       Z62       X63       Y63  \\\n",
       "0     -3.061451 -0.098528  -82.594196  ... -0.349284  0.610715  0.973082   \n",
       "1     -2.202535 -2.630732  163.577346  ... -0.346683  0.613981  0.946346   \n",
       "2     -2.865200 -2.649066   62.903229  ... -0.820756  0.612683  0.950004   \n",
       "3     -6.816939 -2.641445   73.387394  ... -0.892051  0.607402  0.961182   \n",
       "4     -1.022167  0.243538   -8.214614  ... -0.829807  0.604378  0.950633   \n",
       "...         ...       ...         ...  ...       ...       ...       ...   \n",
       "14135  3.206680 -0.088495  -16.454638  ... -0.189617  0.678464  0.430918   \n",
       "14136 -0.996675 -0.073921  -20.329048  ... -0.235708  0.673772  0.673639   \n",
       "14137  5.626362 -0.083474  -32.168021  ... -0.643596  0.653561  0.818583   \n",
       "14138  6.096631 -0.096428  -49.825290  ... -0.573453  0.627514  0.836671   \n",
       "14139  7.211858 -0.112549  -76.094353  ... -0.521230  0.608247  0.844743   \n",
       "\n",
       "            Z63       X64       Y64       Z64       X65       Y65       Z65  \n",
       "0     -0.303378  0.405078  0.922159 -0.281479  0.559808  0.851646 -0.028510  \n",
       "1     -0.395646  0.413621  0.845886 -0.267950  0.558445  0.851427 -0.036818  \n",
       "2     -0.379825  0.448817  0.581546 -0.748774  0.557367  0.867107 -0.040340  \n",
       "3     -0.300694  0.439404  0.449596 -0.823084  0.556838  0.878659 -0.022312  \n",
       "4     -0.247957  0.445261  0.344964 -0.765876  0.552638  0.877294 -0.045415  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "14135 -0.998512  0.307135  0.832112 -0.110380  0.559508  0.746648  0.006331  \n",
       "14136 -0.173289  0.301638  0.830727 -0.135007  0.558916  0.736754  0.016739  \n",
       "14137 -0.402061  0.293410  0.830436 -0.519518  0.550947  0.735413  0.027168  \n",
       "14138 -0.288298  0.281208  0.831862 -0.455801  0.543025  0.740520  0.026633  \n",
       "14139 -0.280609  0.273794  0.836519 -0.409446  0.534971  0.747671  0.022982  \n",
       "\n",
       "[14140 rows x 200 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_sequences(group):\n",
    "    # Calculate the number of padding rows needed\n",
    "    padding_rows = max_sequence_length - len(group)\n",
    "    \n",
    "    # Create a DataFrame with padding rows filled with NaN (or any other padding value)\n",
    "    padding_df = pd.DataFrame({\n",
    "        'Word': [group['Word'].iloc[0]] * padding_rows,\n",
    "        'Frame': np.arange(len(group) + 1, max_sequence_length + 1),\n",
    "    })\n",
    "    \n",
    "    # Concatenate the original group with the padding DataFrame\n",
    "    return pd.concat([group, padding_df], ignore_index=True)\n",
    "\n",
    "# Group the DataFrame by 'Word' and apply the padding function\n",
    "padded_df = merged_df.groupby('Word').apply(pad_sequences).reset_index(drop=True)\n",
    "padded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = padded_df.drop('Word', axis=1)\n",
    "target = padded_df['Word']\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "features_scaled = scaler.fit_transform(data)\n",
    "\n",
    "import pickle\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the interval\n",
    "# interval = 20\n",
    "\n",
    "# # Initialize lists to hold the training and testing sets\n",
    "# X_train_list = []\n",
    "# y_train_list = []\n",
    "# X_test_list = []\n",
    "# y_test_list = []\n",
    "\n",
    "# # Iterate over features_scaled with a step of 20\n",
    "# for i in range(0, len(padded_df) - interval, 3*interval):\n",
    "#     # Slice the dataset for the current interval\n",
    "#     X_train = pd.DataFrame(features_scaled[i:i+2*interval])\n",
    "#     y_train = pd.DataFrame(target[i:i+2*interval])\n",
    "\n",
    "#     X_test = pd.DataFrame(features_scaled[i+2*interval:i+3*interval])\n",
    "#     y_test = pd.DataFrame(target[i+2*interval:i+3*interval])\n",
    "\n",
    "#     # Append the sliced DataFrames to the lists\n",
    "#     X_train_list.append(X_train)\n",
    "#     y_train_list.append(y_train)\n",
    "#     X_test_list.append(X_test)\n",
    "#     y_test_list.append(y_test)\n",
    "\n",
    "# # Convert the lists to DataFrames\n",
    "# X_train_df = pd.concat(X_train_list)\n",
    "# y_train_df = pd.concat(y_train_list)\n",
    "# X_test_df = pd.concat(X_test_list)\n",
    "# y_test_df = pd.concat(y_test_list)\n",
    "\n",
    "# X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Initialize the model\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# clf.fit(X_train_df, y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_df)\n",
    "\n",
    "# # Evaluate the model\n",
    "# print(classification_report(y_test_df, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('rfmodel.pkl', 'wb') as file:\n",
    "#     pickle.dump(clf, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of time steps\n",
    "time_steps = 20\n",
    "\n",
    "# Prepare the data\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(features_scaled) - time_steps, time_steps):\n",
    "    X.append(features_scaled[i:i + time_steps])\n",
    "    y.append(target[i])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Reshape X to fit the LSTM input shape: [samples, time steps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], X.shape[2]))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'y_train' is your target variable with categorical values\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[0;32m      3\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(encoder\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\__init__.py:53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.compat namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon \u001b[38;5;66;03m# line: 125\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.compat namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon \u001b[38;5;66;03m# line: 125\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py:47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lite\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lookup\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\lite\\__init__.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpsSet \u001b[38;5;66;03m# line: 170\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m toco_convert \u001b[38;5;66;03m# line: 1069\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\lite\\experimental\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.lite.experimental namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m authoring\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyzer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelAnalyzer \u001b[38;5;28;01mas\u001b[39;00m Analyzer \u001b[38;5;66;03m# line: 35\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpreter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpResolverType \u001b[38;5;66;03m# line: 303\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\lite\\experimental\\authoring\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.lite.experimental.authoring namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauthoring\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauthoring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compatible \u001b[38;5;66;03m# line: 265\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_wrapper \u001b[38;5;28;01mas\u001b[39;00m _module_wrapper\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;18m__name__\u001b[39m], _module_wrapper\u001b[38;5;241m.\u001b[39mTFModuleWrapper):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\lite\\python\\authoring\\authoring.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lite\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m converter_error_data_pb2\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export \u001b[38;5;28;01mas\u001b[39;00m _tf_export\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\lite\\python\\lite.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlir\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m representative_dataset \u001b[38;5;28;01mas\u001b[39;00m rd\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph_pb2 \u001b[38;5;28;01mas\u001b[39;00m _graph_pb2\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmicrofrontend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio_microfrontend_op  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profiling_info_pb2  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m conversion_metadata_schema_py_generated \u001b[38;5;28;01mas\u001b[39;00m conversion_metadata_fb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\lite\\experimental\\microfrontend\\python\\ops\\audio_microfrontend_op.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_ops\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_loader\n\u001b[1;32m---> 24\u001b[0m _audio_microfrontend_op \u001b[38;5;241m=\u001b[39m \u001b[43mload_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_op_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_path_to_datafile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_audio_microfrontend_op.so\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maudio_microfrontend\u001b[39m(audio,\n\u001b[0;32m     29\u001b[0m                         sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m,\n\u001b[0;32m     30\u001b[0m                         window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m                         out_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     50\u001b[0m                         out_type\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39muint16):\n\u001b[0;32m     51\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Audio Microfrontend Op.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m  This Op converts a sequence of audio data into one or more\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    ValueError: If the audio tensor is not explicitly a vector.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\load_library.py:57\u001b[0m, in \u001b[0;36mload_op_library\u001b[1;34m(library_filename)\u001b[0m\n\u001b[0;32m     54\u001b[0m lib_handle \u001b[38;5;241m=\u001b[39m py_tf\u001b[38;5;241m.\u001b[39mTF_LoadLibrary(library_filename)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m   wrappers \u001b[38;5;241m=\u001b[39m _pywrap_python_op_gen\u001b[38;5;241m.\u001b[39mGetPythonWrappers(\n\u001b[1;32m---> 57\u001b[0m       \u001b[43mpy_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_GetOpList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_handle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m   \u001b[38;5;66;03m# Delete the library handle to release any memory held in C\u001b[39;00m\n\u001b[0;32m     60\u001b[0m   \u001b[38;5;66;03m# that are no longer needed.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m   py_tf\u001b[38;5;241m.\u001b[39mTF_DeleteLibraryHandle(lib_handle)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "num_classes = len(encoder.classes_)\n",
    "print(X_train.shape[1], X_train.shape[2])\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(num_classes, activation='softmax')) # num_classes is the number of unique words you're predicting) # num_classes is the number of unique words you're predicting\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9077 - loss: 0.2966 - val_accuracy: 0.6991 - val_loss: 0.8589\n",
      "Epoch 2/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8873 - loss: 0.3416 - val_accuracy: 0.8319 - val_loss: 0.5554\n",
      "Epoch 3/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9183 - loss: 0.2644 - val_accuracy: 0.8053 - val_loss: 0.5495\n",
      "Epoch 4/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.2251 - val_accuracy: 0.8407 - val_loss: 0.5342\n",
      "Epoch 5/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9371 - loss: 0.2458 - val_accuracy: 0.8319 - val_loss: 0.4981\n",
      "Epoch 6/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9311 - loss: 0.2240 - val_accuracy: 0.7522 - val_loss: 0.6900\n",
      "Epoch 7/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9464 - loss: 0.2403 - val_accuracy: 0.8053 - val_loss: 0.5686\n",
      "Epoch 8/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9389 - loss: 0.1994 - val_accuracy: 0.8142 - val_loss: 0.5503\n",
      "Epoch 9/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9494 - loss: 0.2023 - val_accuracy: 0.7788 - val_loss: 0.6224\n",
      "Epoch 10/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9016 - loss: 0.3090 - val_accuracy: 0.7345 - val_loss: 0.6643\n",
      "Epoch 11/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8766 - loss: 0.3484 - val_accuracy: 0.7876 - val_loss: 0.6698\n",
      "Epoch 12/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8518 - loss: 0.4162 - val_accuracy: 0.7168 - val_loss: 0.8140\n",
      "Epoch 13/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7395 - loss: 0.8071 - val_accuracy: 0.7876 - val_loss: 0.6698\n",
      "Epoch 14/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8308 - loss: 0.4673 - val_accuracy: 0.8319 - val_loss: 0.5955\n",
      "Epoch 15/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8432 - loss: 0.4212 - val_accuracy: 0.7257 - val_loss: 0.6361\n",
      "Epoch 16/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8919 - loss: 0.3330 - val_accuracy: 0.8673 - val_loss: 0.5091\n",
      "Epoch 17/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8615 - loss: 0.4077 - val_accuracy: 0.6903 - val_loss: 0.8125\n",
      "Epoch 18/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8347 - loss: 0.5035 - val_accuracy: 0.5752 - val_loss: 1.1293\n",
      "Epoch 19/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7379 - loss: 0.7179 - val_accuracy: 0.6726 - val_loss: 0.7935\n",
      "Epoch 20/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8651 - loss: 0.4015 - val_accuracy: 0.7699 - val_loss: 0.7050\n",
      "Epoch 21/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9052 - loss: 0.3114 - val_accuracy: 0.7876 - val_loss: 0.6003\n",
      "Epoch 22/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8938 - loss: 0.3028 - val_accuracy: 0.8319 - val_loss: 0.6136\n",
      "Epoch 23/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9114 - loss: 0.2917 - val_accuracy: 0.7876 - val_loss: 0.6168\n",
      "Epoch 24/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8884 - loss: 0.3153 - val_accuracy: 0.8319 - val_loss: 0.5253\n",
      "Epoch 25/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9269 - loss: 0.2578 - val_accuracy: 0.8142 - val_loss: 0.6440\n",
      "Epoch 26/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9117 - loss: 0.2658 - val_accuracy: 0.7876 - val_loss: 0.6776\n",
      "Epoch 27/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9058 - loss: 0.2781 - val_accuracy: 0.7876 - val_loss: 0.6249\n",
      "Epoch 28/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9195 - loss: 0.2665 - val_accuracy: 0.7611 - val_loss: 0.6549\n",
      "Epoch 29/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9301 - loss: 0.2562 - val_accuracy: 0.7699 - val_loss: 0.6452\n",
      "Epoch 30/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9099 - loss: 0.2797 - val_accuracy: 0.7522 - val_loss: 0.7201\n",
      "Epoch 31/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8948 - loss: 0.2903 - val_accuracy: 0.8407 - val_loss: 0.5374\n",
      "Epoch 32/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9502 - loss: 0.2270 - val_accuracy: 0.8053 - val_loss: 0.5728\n",
      "Epoch 33/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9087 - loss: 0.3296 - val_accuracy: 0.8407 - val_loss: 0.4842\n",
      "Epoch 34/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8975 - loss: 0.3005 - val_accuracy: 0.8230 - val_loss: 0.5687\n",
      "Epoch 35/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8665 - loss: 0.3598 - val_accuracy: 0.7788 - val_loss: 0.6584\n",
      "Epoch 36/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8785 - loss: 0.3423 - val_accuracy: 0.8496 - val_loss: 0.4792\n",
      "Epoch 37/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8872 - loss: 0.3397 - val_accuracy: 0.7788 - val_loss: 0.6495\n",
      "Epoch 38/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8511 - loss: 0.4203 - val_accuracy: 0.6106 - val_loss: 1.1256\n",
      "Epoch 39/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7661 - loss: 0.5632 - val_accuracy: 0.7788 - val_loss: 0.6514\n",
      "Epoch 40/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7765 - loss: 0.5811 - val_accuracy: 0.6726 - val_loss: 0.7786\n",
      "Epoch 41/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8401 - loss: 0.4302 - val_accuracy: 0.7434 - val_loss: 0.6136\n",
      "Epoch 42/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8463 - loss: 0.4128 - val_accuracy: 0.7522 - val_loss: 0.6072\n",
      "Epoch 43/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7946 - loss: 0.5229 - val_accuracy: 0.6991 - val_loss: 0.8079\n",
      "Epoch 44/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8456 - loss: 0.4154 - val_accuracy: 0.7080 - val_loss: 0.8410\n",
      "Epoch 45/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6853 - loss: 0.9972 - val_accuracy: 0.6549 - val_loss: 0.8359\n",
      "Epoch 46/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8109 - loss: 0.5010 - val_accuracy: 0.7699 - val_loss: 0.6806\n",
      "Epoch 47/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8406 - loss: 0.4711 - val_accuracy: 0.5841 - val_loss: 1.1461\n",
      "Epoch 48/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6359 - loss: 1.0142 - val_accuracy: 0.7522 - val_loss: 0.7240\n",
      "Epoch 49/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7966 - loss: 0.5246 - val_accuracy: 0.7345 - val_loss: 0.6993\n",
      "Epoch 50/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8077 - loss: 0.5296 - val_accuracy: 0.7434 - val_loss: 0.7687\n",
      "Epoch 51/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8518 - loss: 0.4074 - val_accuracy: 0.7699 - val_loss: 0.6510\n",
      "Epoch 52/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9087 - loss: 0.3189 - val_accuracy: 0.7876 - val_loss: 0.6278\n",
      "Epoch 53/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9189 - loss: 0.2678 - val_accuracy: 0.8230 - val_loss: 0.5514\n",
      "Epoch 54/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9323 - loss: 0.2314 - val_accuracy: 0.8496 - val_loss: 0.5621\n",
      "Epoch 55/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9531 - loss: 0.2102 - val_accuracy: 0.8142 - val_loss: 0.6015\n",
      "Epoch 56/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9273 - loss: 0.2026 - val_accuracy: 0.8142 - val_loss: 0.5598\n",
      "Epoch 57/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9596 - loss: 0.1798 - val_accuracy: 0.8230 - val_loss: 0.5500\n",
      "Epoch 58/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9489 - loss: 0.2012 - val_accuracy: 0.8319 - val_loss: 0.5161\n",
      "Epoch 59/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9402 - loss: 0.2230 - val_accuracy: 0.8053 - val_loss: 0.5632\n",
      "Epoch 60/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9062 - loss: 0.2600 - val_accuracy: 0.8407 - val_loss: 0.6022\n",
      "Epoch 61/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9413 - loss: 0.2031 - val_accuracy: 0.8407 - val_loss: 0.5244\n",
      "Epoch 62/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9209 - loss: 0.2299 - val_accuracy: 0.8319 - val_loss: 0.5223\n",
      "Epoch 63/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9342 - loss: 0.2211 - val_accuracy: 0.8142 - val_loss: 0.6355\n",
      "Epoch 64/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9236 - loss: 0.2189 - val_accuracy: 0.8230 - val_loss: 0.5860\n",
      "Epoch 65/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9665 - loss: 0.1719 - val_accuracy: 0.8407 - val_loss: 0.5299\n",
      "Epoch 66/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9519 - loss: 0.1816 - val_accuracy: 0.8142 - val_loss: 0.5829\n",
      "Epoch 67/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9364 - loss: 0.2137 - val_accuracy: 0.8496 - val_loss: 0.5301\n",
      "Epoch 68/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9488 - loss: 0.1836 - val_accuracy: 0.8053 - val_loss: 0.5900\n",
      "Epoch 69/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9591 - loss: 0.1601 - val_accuracy: 0.7876 - val_loss: 0.5652\n",
      "Epoch 70/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9500 - loss: 0.1814 - val_accuracy: 0.8407 - val_loss: 0.5302\n",
      "Epoch 71/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9596 - loss: 0.1724 - val_accuracy: 0.8142 - val_loss: 0.5302\n",
      "Epoch 72/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9534 - loss: 0.1795 - val_accuracy: 0.8496 - val_loss: 0.4559\n",
      "Epoch 73/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9408 - loss: 0.1882 - val_accuracy: 0.7965 - val_loss: 0.5226\n",
      "Epoch 74/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9590 - loss: 0.1749 - val_accuracy: 0.7876 - val_loss: 0.6172\n",
      "Epoch 75/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9081 - loss: 0.2477 - val_accuracy: 0.6991 - val_loss: 0.9190\n",
      "Epoch 76/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8268 - loss: 0.4513 - val_accuracy: 0.7611 - val_loss: 0.7916\n",
      "Epoch 77/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8507 - loss: 0.3888 - val_accuracy: 0.7965 - val_loss: 0.6122\n",
      "Epoch 78/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9429 - loss: 0.1777 - val_accuracy: 0.8407 - val_loss: 0.5087\n",
      "Epoch 79/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9543 - loss: 0.1657 - val_accuracy: 0.8230 - val_loss: 0.4973\n",
      "Epoch 80/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9606 - loss: 0.1627 - val_accuracy: 0.8496 - val_loss: 0.4474\n",
      "Epoch 81/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9284 - loss: 0.2051 - val_accuracy: 0.8407 - val_loss: 0.6145\n",
      "Epoch 82/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9375 - loss: 0.2099 - val_accuracy: 0.8673 - val_loss: 0.5303\n",
      "Epoch 83/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9472 - loss: 0.1913 - val_accuracy: 0.8230 - val_loss: 0.5704\n",
      "Epoch 84/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9321 - loss: 0.1973 - val_accuracy: 0.8407 - val_loss: 0.5163\n",
      "Epoch 85/85\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9439 - loss: 0.1747 - val_accuracy: 0.7876 - val_loss: 0.6874\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_encoded, epochs=80, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7540 - loss: 0.6974 \n",
      "Test Loss: 0.7209173440933228, Test Accuracy: 0.7464788556098938\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75        10\n",
      "           1       0.65      0.65      0.65        17\n",
      "           2       0.80      0.40      0.53        10\n",
      "           3       0.57      0.67      0.62         6\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       1.00      1.00      1.00         9\n",
      "           6       0.50      0.67      0.57         9\n",
      "           7       0.82      1.00      0.90        14\n",
      "           8       1.00      1.00      1.00         6\n",
      "           9       0.56      1.00      0.71         5\n",
      "          10       0.75      0.75      0.75         4\n",
      "          11       0.25      0.67      0.36         3\n",
      "          12       1.00      0.89      0.94         9\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       0.80      0.67      0.73         6\n",
      "          15       0.69      1.00      0.82         9\n",
      "          16       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.75       142\n",
      "   macro avg       0.73      0.76      0.73       142\n",
      "weighted avg       0.74      0.75      0.73       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test) # Replace `model` with your trained LSTM model and `X_test` with your test dataset\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "# Print the classification report\n",
    "print(classification_report(y_test_encoded, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8438 - loss: 0.4175 - val_accuracy: 0.8000 - val_loss: 0.4964\n",
      "Epoch 2/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8897 - loss: 0.3113 - val_accuracy: 0.8235 - val_loss: 0.5575\n",
      "Epoch 3/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9418 - loss: 0.2281 - val_accuracy: 0.8000 - val_loss: 0.5835\n",
      "Epoch 4/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9248 - loss: 0.2573 - val_accuracy: 0.8235 - val_loss: 0.5342\n",
      "Epoch 5/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9571 - loss: 0.1790 - val_accuracy: 0.8000 - val_loss: 0.6006\n",
      "Epoch 6/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8961 - loss: 0.3235 - val_accuracy: 0.7765 - val_loss: 0.6201\n",
      "Epoch 7/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9129 - loss: 0.2670 - val_accuracy: 0.8235 - val_loss: 0.5030\n",
      "Epoch 8/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9274 - loss: 0.2340 - val_accuracy: 0.8235 - val_loss: 0.5628\n",
      "Epoch 9/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9149 - loss: 0.2511 - val_accuracy: 0.8824 - val_loss: 0.4548\n",
      "Epoch 10/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9465 - loss: 0.1965 - val_accuracy: 0.8235 - val_loss: 0.5558\n",
      "Epoch 11/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9469 - loss: 0.1986 - val_accuracy: 0.8353 - val_loss: 0.4450\n",
      "Epoch 12/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9262 - loss: 0.2146 - val_accuracy: 0.8235 - val_loss: 0.5377\n",
      "Epoch 13/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9524 - loss: 0.2009 - val_accuracy: 0.8353 - val_loss: 0.5257\n",
      "Epoch 14/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9601 - loss: 0.1776 - val_accuracy: 0.8706 - val_loss: 0.4196\n",
      "Epoch 15/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.1634 - val_accuracy: 0.8235 - val_loss: 0.4065\n",
      "Epoch 16/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9570 - loss: 0.1787 - val_accuracy: 0.8118 - val_loss: 0.5230\n",
      "Epoch 17/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9121 - loss: 0.2272 - val_accuracy: 0.8588 - val_loss: 0.3985\n",
      "Epoch 18/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9573 - loss: 0.1714 - val_accuracy: 0.8235 - val_loss: 0.4299\n",
      "Epoch 19/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9549 - loss: 0.1644 - val_accuracy: 0.8588 - val_loss: 0.4684\n",
      "Epoch 20/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9640 - loss: 0.1410 - val_accuracy: 0.8824 - val_loss: 0.3776\n",
      "Epoch 21/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9623 - loss: 0.1440 - val_accuracy: 0.8588 - val_loss: 0.4916\n",
      "Epoch 22/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9620 - loss: 0.1591 - val_accuracy: 0.8588 - val_loss: 0.4429\n",
      "Epoch 23/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7842 - loss: 0.7512 - val_accuracy: 0.4588 - val_loss: 1.6865\n",
      "Epoch 24/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6970 - loss: 0.8205 - val_accuracy: 0.6353 - val_loss: 1.1896\n",
      "Epoch 25/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7508 - loss: 0.7292 - val_accuracy: 0.6588 - val_loss: 0.8424\n",
      "Epoch 26/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8265 - loss: 0.4696 - val_accuracy: 0.8118 - val_loss: 0.4936\n",
      "Epoch 27/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9278 - loss: 0.2824 - val_accuracy: 0.8353 - val_loss: 0.4622\n",
      "Epoch 28/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8860 - loss: 0.2616 - val_accuracy: 0.9294 - val_loss: 0.3457\n",
      "Epoch 29/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9477 - loss: 0.1951 - val_accuracy: 0.8706 - val_loss: 0.5100\n",
      "Epoch 30/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9451 - loss: 0.2049 - val_accuracy: 0.8941 - val_loss: 0.3848\n",
      "Epoch 31/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9740 - loss: 0.1473 - val_accuracy: 0.8706 - val_loss: 0.4478\n",
      "Epoch 32/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.1538 - val_accuracy: 0.8706 - val_loss: 0.3733\n",
      "Epoch 33/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9658 - loss: 0.1376 - val_accuracy: 0.8471 - val_loss: 0.4623\n",
      "Epoch 34/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9743 - loss: 0.1206 - val_accuracy: 0.8824 - val_loss: 0.4415\n",
      "Epoch 35/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9699 - loss: 0.1337 - val_accuracy: 0.8706 - val_loss: 0.4061\n",
      "Epoch 36/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9571 - loss: 0.1652 - val_accuracy: 0.8588 - val_loss: 0.4534\n",
      "Epoch 37/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9506 - loss: 0.1881 - val_accuracy: 0.8588 - val_loss: 0.4743\n",
      "Epoch 38/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9601 - loss: 0.1433 - val_accuracy: 0.8353 - val_loss: 0.4912\n",
      "Epoch 39/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9499 - loss: 0.1795 - val_accuracy: 0.8353 - val_loss: 0.4775\n",
      "Epoch 40/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9595 - loss: 0.1644 - val_accuracy: 0.8941 - val_loss: 0.3867\n",
      "Epoch 41/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9718 - loss: 0.1429 - val_accuracy: 0.8588 - val_loss: 0.4047\n",
      "Epoch 42/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9601 - loss: 0.1434 - val_accuracy: 0.8118 - val_loss: 0.4865\n",
      "Epoch 43/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9590 - loss: 0.1737 - val_accuracy: 0.8706 - val_loss: 0.3769\n",
      "Epoch 44/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.1272 - val_accuracy: 0.8941 - val_loss: 0.4047\n",
      "Epoch 45/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9620 - loss: 0.1440 - val_accuracy: 0.8824 - val_loss: 0.3584\n",
      "Epoch 46/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9628 - loss: 0.1334 - val_accuracy: 0.8588 - val_loss: 0.3740\n",
      "Epoch 47/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9726 - loss: 0.1187 - val_accuracy: 0.9176 - val_loss: 0.3537\n",
      "Epoch 48/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9702 - loss: 0.1258 - val_accuracy: 0.8471 - val_loss: 0.4496\n",
      "Epoch 49/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9786 - loss: 0.1147 - val_accuracy: 0.8588 - val_loss: 0.4735\n",
      "Epoch 50/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9570 - loss: 0.1581 - val_accuracy: 0.8235 - val_loss: 0.4750\n",
      "Epoch 51/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9307 - loss: 0.1987 - val_accuracy: 0.8353 - val_loss: 0.5845\n",
      "Epoch 52/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9277 - loss: 0.2571 - val_accuracy: 0.8353 - val_loss: 0.4368\n",
      "Epoch 53/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.1753 - val_accuracy: 0.7529 - val_loss: 0.6533\n",
      "Epoch 54/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8073 - loss: 0.5721 - val_accuracy: 0.5529 - val_loss: 1.5158\n",
      "Epoch 55/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7430 - loss: 0.7618 - val_accuracy: 0.8118 - val_loss: 0.5113\n",
      "Epoch 56/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9181 - loss: 0.2507 - val_accuracy: 0.8118 - val_loss: 0.6036\n",
      "Epoch 57/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9018 - loss: 0.2685 - val_accuracy: 0.8235 - val_loss: 0.5998\n",
      "Epoch 58/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8885 - loss: 0.2913 - val_accuracy: 0.8471 - val_loss: 0.4816\n",
      "Epoch 59/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8900 - loss: 0.3024 - val_accuracy: 0.7647 - val_loss: 0.7339\n",
      "Epoch 60/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9151 - loss: 0.2442 - val_accuracy: 0.8706 - val_loss: 0.4821\n",
      "Epoch 61/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9365 - loss: 0.2124 - val_accuracy: 0.8353 - val_loss: 0.5284\n",
      "Epoch 62/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9545 - loss: 0.1942 - val_accuracy: 0.8353 - val_loss: 0.4882\n",
      "Epoch 63/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9579 - loss: 0.1621 - val_accuracy: 0.8706 - val_loss: 0.5219\n",
      "Epoch 64/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9685 - loss: 0.1446 - val_accuracy: 0.8824 - val_loss: 0.3828\n",
      "Epoch 65/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9681 - loss: 0.1304 - val_accuracy: 0.8471 - val_loss: 0.4152\n",
      "Epoch 66/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9777 - loss: 0.1183 - val_accuracy: 0.8471 - val_loss: 0.4355\n",
      "Epoch 67/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9668 - loss: 0.1403 - val_accuracy: 0.8706 - val_loss: 0.4300\n",
      "Epoch 68/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9810 - loss: 0.1119 - val_accuracy: 0.8588 - val_loss: 0.4658\n",
      "Epoch 69/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9623 - loss: 0.1301 - val_accuracy: 0.8706 - val_loss: 0.4096\n",
      "Epoch 70/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.1087 - val_accuracy: 0.9059 - val_loss: 0.3574\n",
      "Epoch 71/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.0973 - val_accuracy: 0.8706 - val_loss: 0.4038\n",
      "Epoch 72/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9760 - loss: 0.1177 - val_accuracy: 0.8941 - val_loss: 0.3613\n",
      "Epoch 73/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9641 - loss: 0.1195 - val_accuracy: 0.8706 - val_loss: 0.3846\n",
      "Epoch 74/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9655 - loss: 0.1338 - val_accuracy: 0.8471 - val_loss: 0.5022\n",
      "Epoch 75/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9768 - loss: 0.1167 - val_accuracy: 0.8706 - val_loss: 0.4105\n",
      "Epoch 76/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9774 - loss: 0.1200 - val_accuracy: 0.8235 - val_loss: 0.4473\n",
      "Epoch 77/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9622 - loss: 0.1145 - val_accuracy: 0.8824 - val_loss: 0.3894\n",
      "Epoch 78/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.1077 - val_accuracy: 0.8824 - val_loss: 0.4118\n",
      "Epoch 79/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9722 - loss: 0.1017 - val_accuracy: 0.8353 - val_loss: 0.4623\n",
      "Epoch 80/80\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9758 - loss: 0.1143 - val_accuracy: 0.8706 - val_loss: 0.4067\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_encoded, epochs=80, batch_size=32, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.5300 \n",
      "Test Loss: 0.46493637561798096, Test Accuracy: 0.8450704216957092\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.91      0.59      0.71        17\n",
      "           2       0.88      0.70      0.78        10\n",
      "           3       0.62      0.83      0.71         6\n",
      "           4       0.75      0.60      0.67        10\n",
      "           5       1.00      1.00      1.00         9\n",
      "           6       0.53      0.89      0.67         9\n",
      "           7       1.00      1.00      1.00        14\n",
      "           8       1.00      0.83      0.91         6\n",
      "           9       0.60      0.60      0.60         5\n",
      "          10       0.80      1.00      0.89         4\n",
      "          11       0.60      1.00      0.75         3\n",
      "          12       1.00      0.89      0.94         9\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       0.80      0.67      0.73         6\n",
      "          15       1.00      1.00      1.00         9\n",
      "          16       0.86      1.00      0.92        12\n",
      "\n",
      "    accuracy                           0.85       142\n",
      "   macro avg       0.84      0.86      0.84       142\n",
      "weighted avg       0.87      0.85      0.85       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test) # Replace `model` with your trained LSTM model and `X_test` with your test dataset\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "# Print the classification report\n",
    "print(classification_report(y_test_encoded, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# with open('lstmmodel.pkl', 'wb') as file:\n",
    "#     pickle.dump(model, file)\n",
    "model.save('lstmmodel.h5')\n",
    "tf.saved_model.save(model, 'saved_model')\n",
    "# pip install openvino-dev[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.saving.pickle_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstmmodel.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel):\n\u001b[0;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstmmodel.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.saving.pickle_utils'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('lstmmodel.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "if isinstance(model, tf.keras.Model):\n",
    "    model.save('lstmmodel.h5')\n",
    "    \n",
    "    tf.saved_model.save(model, 'saved_model')\n",
    "    # model.save('path_to_your_model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from openvino.runtime import Core, serialize\n",
    "\n",
    "# Convert to IR (example with quantization)\n",
    "mo_cmd = f\"mo --saved_model_dir saved_model --input_shape '[1, 20, 199]' --output_dir ir --data_type FP16\"\n",
    "import subprocess\n",
    "subprocess.call(mo_cmd, shell=True)\n",
    "\n",
    "# convert a saved model to IR format using the Model Optimizer in python through core\n",
    "core = Core()\n",
    "model = core.read_model(\"saved_model\")\n",
    "compiled_model = core.compile_model(model, \"CPU\")\n",
    "serialize(model, xml_path=\"ir/intel_model.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Output: names[inputs] shape[?,20,199] type: f32>]\n",
      "[<Output: names[output_0] shape[?,17] type: f32>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_xml = \"ir/intel_model.xml\"\n",
    "model = core.read_model(model=model_xml)\n",
    "print(model.inputs)\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IR model and compile for target device\n",
    "core = Core()\n",
    "model_ = core.read_model(\"ir/intel_model.xml\")\n",
    "compiled_model = core.compile_model(model, \"CPU\")\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# for single input models only\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m compiled_model(\u001b[43minput_data\u001b[49m)[output_layer]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# for multiple inputs in a list\u001b[39;00m\n\u001b[0;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m compiled_model([input_data])[output_layer]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_data' is not defined"
     ]
    }
   ],
   "source": [
    "# for single input models only\n",
    "result = compiled_model(input_data)[output_layer]\n",
    "\n",
    "# for multiple inputs in a list\n",
    "result = compiled_model([input_data])[output_layer]\n",
    "\n",
    "# or using a dictionary, where the key is input tensor name or index\n",
    "result = compiled_model({input_layer.any_name: input_data})[output_layer]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
